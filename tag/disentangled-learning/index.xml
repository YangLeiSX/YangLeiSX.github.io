<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Disentangled Learning | YangLeiSX</title>
    <link>https://yangleisx.github.io/tag/disentangled-learning/</link>
      <atom:link href="https://yangleisx.github.io/tag/disentangled-learning/index.xml" rel="self" type="application/rss+xml" />
    <description>Disentangled Learning</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Tue, 02 Apr 2024 11:49:05 +0800</lastBuildDate>
    <image>
      <url>https://yangleisx.github.io/media/icon_hu9d67daea6e408fd17d2331b8d809e90a_61652_512x512_fill_lanczos_center_3.png</url>
      <title>Disentangled Learning</title>
      <link>https://yangleisx.github.io/tag/disentangled-learning/</link>
    </image>
    
    <item>
      <title>【论文】An Effective Mixture-Of-Experts Approach For Code-Switching Speech Recognition Leveraging Encoder Disentanglement</title>
      <link>https://yangleisx.github.io/post/paper-moe-csasr/</link>
      <pubDate>Tue, 02 Apr 2024 11:49:05 +0800</pubDate>
      <guid>https://yangleisx.github.io/post/paper-moe-csasr/</guid>
      <description>&lt;p&gt;论文题目：An Effective Mixture-Of-Experts Approach For Code-Switching Speech Recognition Leveraging Encoder Disentanglement&lt;/p&gt;
&lt;p&gt;作者：Tzu-Ting Yang, Hsin-Wei Wang, Yi-Cheng Wang, Chi-Han Lin, and Berlin Chen
单位：National Taiwan Normal University&lt;/p&gt;
&lt;p&gt;会议/时间：ICASSP 2024&lt;/p&gt;
&lt;p&gt;链接: &lt;a href=&#34;https://doi.org/10.1109/icassp48485.2024.10446652&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;doi&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;tl-dr&#34;&gt;TL; DR&lt;/h2&gt;
&lt;p&gt;采用解耦结合MOE的方式来进行多语言的语音识别。&lt;/p&gt;
&lt;h2 id=&#34;论文目标&#34;&gt;论文目标&lt;/h2&gt;
&lt;p&gt;ASR模型在单语言上有很好的性能，但是在Code-Switch场景下性能不好。&lt;/p&gt;
&lt;p&gt;难点有两部分，一个是高质量数据集缺乏。一个是不同语言之间的差异。
不同的拼音语言之间差异较小，但是中文英文之间差异很大。造成模型会混淆。&lt;/p&gt;
&lt;h2 id=&#34;相关工作&#34;&gt;相关工作&lt;/h2&gt;
&lt;p&gt;一种做法是LID，即language identification，使用语言分类预测头，判别当前位置是什么语言。
一种做法是双编码器，但是可能会损失不同语言上下文之间的关系。
因此常见做法是LAE，就是language-aware encoder，单一的编码器但是具有语言感知能力。&lt;/p&gt;
&lt;h2 id=&#34;本文方法&#34;&gt;本文方法&lt;/h2&gt;
&lt;p&gt;结构比较简单。&lt;/p&gt;
&lt;p&gt;包含共享的编码器，提取完整的特征。语言特定编码器，提取特定语言特征。
语言特定编码器的监督是CTC损失，使用语言mask来指导。
MoE混合的监督也是CTC损失，使用完整的序列来监督。
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;moe-csasr-arch&#34; srcset=&#34;
               /post/paper-moe-csasr/moe-csasr-arch_hu108bc1b05e011fcd5d97021c66ebb369_276762_36054b0052bfe5c138e2e115c41005bf.webp 400w,
               /post/paper-moe-csasr/moe-csasr-arch_hu108bc1b05e011fcd5d97021c66ebb369_276762_d2a241bb655f6580ee27f7526c5d7120.webp 760w,
               /post/paper-moe-csasr/moe-csasr-arch_hu108bc1b05e011fcd5d97021c66ebb369_276762_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://yangleisx.github.io/post/paper-moe-csasr/moe-csasr-arch_hu108bc1b05e011fcd5d97021c66ebb369_276762_36054b0052bfe5c138e2e115c41005bf.webp&#34;
               width=&#34;760&#34;
               height=&#34;403&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;完整的损失包含两部分，一部分是使用目标序列监督的CTC损失，还有一部分是解耦损失。
其中的解耦损失就是对应位置上的特征的Cosine距离。
即



$$\begin{aligned}
L_{lang} &amp;= \frac{1}{2}(L_{ZH} + L_{EN}) \\
L &amp;= \frac{1}{2}(L_{Mix} + L_{Lang}) + \lambda L_{Disen} \\
L_{Disen} &amp;= -\frac{1}{N}\sum_{i=1}^N \frac{1}{|s_i|}\sum_{j=1}^{|s_i|}CD(\mathbf h_{i, j}^{ZH}, \mathbf h_{i, j}^{EN})\\
CD(\mathbf h_{i, j}^{ZH}, \mathbf h_{i, j}^{EN}) &amp;= 1 - \frac{\mathbf h_{i, j}^{ZH}\cdot \mathbf h_{i, j}^{EN}}{||\mathbf h_{i, j}^{ZH}||_2 ||\mathbf h_{i, j}^{EN}||_2}
\end{aligned}$$
&lt;/p&gt;
&lt;h2 id=&#34;结果分析&#34;&gt;结果分析&lt;/h2&gt;
&lt;p&gt;在[[SEAME]]数据集上完成实验。
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;seame-dataset.png&#34; srcset=&#34;
               /post/paper-moe-csasr/seame-dataset_hu7cf206845db5c2d763292047080ffa6c_126973_a7c7e6f4696b3c7bb7a1d31411a57fd0.webp 400w,
               /post/paper-moe-csasr/seame-dataset_hu7cf206845db5c2d763292047080ffa6c_126973_bb97dd9baf5c34ccb5643890780673cc.webp 760w,
               /post/paper-moe-csasr/seame-dataset_hu7cf206845db5c2d763292047080ffa6c_126973_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://yangleisx.github.io/post/paper-moe-csasr/seame-dataset_hu7cf206845db5c2d763292047080ffa6c_126973_a7c7e6f4696b3c7bb7a1d31411a57fd0.webp&#34;
               width=&#34;760&#34;
               height=&#34;283&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;语言的预处理部分，中文字典包含2624个字，英文字典包含3000个BPE。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;moe-csasr-expr.png&#34; srcset=&#34;
               /post/paper-moe-csasr/moe-csasr-expr_hu753f2393aabfb7f6f74c16cd40b47b8a_257963_9d3d1a634baca586f561a5244ee850ff.webp 400w,
               /post/paper-moe-csasr/moe-csasr-expr_hu753f2393aabfb7f6f74c16cd40b47b8a_257963_3bc4e8938a4db2a5bd13f3cd8565e54e.webp 760w,
               /post/paper-moe-csasr/moe-csasr-expr_hu753f2393aabfb7f6f74c16cd40b47b8a_257963_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://yangleisx.github.io/post/paper-moe-csasr/moe-csasr-expr_hu753f2393aabfb7f6f74c16cd40b47b8a_257963_9d3d1a634baca586f561a5244ee850ff.webp&#34;
               width=&#34;760&#34;
               height=&#34;640&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;和简单Concatenate相比，使用MoE的方式在经过解耦之后有所提升。
如果不解耦直接使用MoE，会导致门控网络出现混淆。
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;moe-csasr-abblation.png&#34; srcset=&#34;
               /post/paper-moe-csasr/moe-csasr-abblation_hu5a98067f24fd64e9f9f167e480262985_251697_ffb5876bf458d47b1f38a3203b3d0578.webp 400w,
               /post/paper-moe-csasr/moe-csasr-abblation_hu5a98067f24fd64e9f9f167e480262985_251697_7c2883f4f73a76b10595d1d34d6973a0.webp 760w,
               /post/paper-moe-csasr/moe-csasr-abblation_hu5a98067f24fd64e9f9f167e480262985_251697_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://yangleisx.github.io/post/paper-moe-csasr/moe-csasr-abblation_hu5a98067f24fd64e9f9f167e480262985_251697_ffb5876bf458d47b1f38a3203b3d0578.webp&#34;
               width=&#34;760&#34;
               height=&#34;191&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;进一步可视化了Gating Network的输出。
















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;moe-csasr-compare.png&#34; srcset=&#34;
               /post/paper-moe-csasr/moe-csasr-compare_hueef8c0bd2d6497b5e8f4da3b407c2ff8_451695_619c63b61334acfac9721035a843be30.webp 400w,
               /post/paper-moe-csasr/moe-csasr-compare_hueef8c0bd2d6497b5e8f4da3b407c2ff8_451695_4406e0b151fd818592a55446d6270251.webp 760w,
               /post/paper-moe-csasr/moe-csasr-compare_hueef8c0bd2d6497b5e8f4da3b407c2ff8_451695_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://yangleisx.github.io/post/paper-moe-csasr/moe-csasr-compare_hueef8c0bd2d6497b5e8f4da3b407c2ff8_451695_619c63b61334acfac9721035a843be30.webp&#34;
               width=&#34;760&#34;
               height=&#34;502&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;</description>
    </item>
    
    <item>
      <title>【论文】Improving Semantic Segmentation in Aerial Imagery via Graph Reasoning and Disentangled Learning</title>
      <link>https://yangleisx.github.io/post/paper-pgr/</link>
      <pubDate>Wed, 06 Jul 2022 10:17:43 +0800</pubDate>
      <guid>https://yangleisx.github.io/post/paper-pgr/</guid>
      <description>&lt;p&gt;论文题目： Improving Semantic Segmentation in Aerial Imagery via Graph Reasoning and Disentangled Learning&lt;/p&gt;
&lt;p&gt;作者：Ruigang Niu, Xian Sun, Yu Tian, Wenhui Diao, Yingchao Feng, Kun Fu&lt;/p&gt;
&lt;p&gt;会议/时间：TGRS2021&lt;/p&gt;
&lt;p&gt;链接: &lt;a href=&#34;https://www.researchgate.net/publication/355465205_Improving_Semantic_Segmentation_in_Aerial_Imagery_via_Graph_Reasoning_and_Disentangled_Learning&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ResearchGate&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;论文目标&#34;&gt;论文目标&lt;/h2&gt;
&lt;p&gt;在航空影像分割问题中，由于存在前景背景不平衡，类内数据差异较大以及密集/小目标的存在，性能受到限制。文章通过引入Graph Reasoning 图推理和Disentangled Representation Learning 解耦表示学习的思路，提升在航空影像上分割的效果。&lt;/p&gt;
&lt;p&gt;为了提取丰富的上下文信息，之前的工作使用了FCN、ASPP等方式，也可以使用基于Attention 注意力机制的方式。为了进一步增加上下文信息，可以使用Graph Reasoning 图推理的方式。&lt;/p&gt;
&lt;p&gt;对于密集目标、小目标等容易出现特征含糊不清的问题，引入了解耦的多分支的结构。使用多任务学习的方式来解决分割和边缘检测的问题。&lt;/p&gt;
&lt;h2 id=&#34;相关工作&#34;&gt;相关工作&lt;/h2&gt;
&lt;p&gt;使用GR的算法中，GloRe使用1D卷积在全连接图上实现图卷积，SPyGR直接在像素空间上做图卷积，忽略了像素空间和语义空间之间的语义差异。CDGC引入了从粗检测到精细化的方式（有点类似OCRNet？）DisenGCN将GCN和Disentangled Learning两者相结合。&lt;/p&gt;
&lt;h2 id=&#34;本文方法&#34;&gt;本文方法&lt;/h2&gt;
&lt;p&gt;整体结构图下。首先使用FPN得到层次特征，使用GR模块处理特征。将特征送入双分支解耦学习模块，分别进行前景估计和边缘对齐，最后将所有的特征融合到一起进行预测。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;pgr-disen-structure.png&#34; srcset=&#34;
               /post/paper-pgr/pgr-disen-structure_hu42f8ef22bf07443464a7487f6234e4fa_749556_1b6c4f43f1efdd36f12839363fd2fc3d.webp 400w,
               /post/paper-pgr/pgr-disen-structure_hu42f8ef22bf07443464a7487f6234e4fa_749556_4f1285a31cde5c716561f54ffaa91409.webp 760w,
               /post/paper-pgr/pgr-disen-structure_hu42f8ef22bf07443464a7487f6234e4fa_749556_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://yangleisx.github.io/post/paper-pgr/pgr-disen-structure_hu42f8ef22bf07443464a7487f6234e4fa_749556_1b6c4f43f1efdd36f12839363fd2fc3d.webp&#34;
               width=&#34;760&#34;
               height=&#34;353&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;这里的图卷积模块，吸收了HBP 层次双线性池化的思想，将相邻的三个不同分辨率的特征图进行缩放之后计算Hadamard积然后映射到若干个点，然后进行图卷积，最后使用卷积得到的结果对原本的特征相乘在映射回到原本的像素空间中。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;pgr-disen-gr.png&#34; srcset=&#34;
               /post/paper-pgr/pgr-disen-gr_hu7af98c730b489b2d0f9d0d6f35621975_41429_a08ed3f5d2c397be56ce578b7b000673.webp 400w,
               /post/paper-pgr/pgr-disen-gr_hu7af98c730b489b2d0f9d0d6f35621975_41429_fd1cebc680eb0e5bb3e8913573be0ce0.webp 760w,
               /post/paper-pgr/pgr-disen-gr_hu7af98c730b489b2d0f9d0d6f35621975_41429_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://yangleisx.github.io/post/paper-pgr/pgr-disen-gr_hu7af98c730b489b2d0f9d0d6f35621975_41429_a08ed3f5d2c397be56ce578b7b000673.webp&#34;
               width=&#34;708&#34;
               height=&#34;250&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;使用HBP 层次双线性池化进行映射的时候有如下公式进行池化。
$$G_{proj}(F^2, \mathcal{U}(F^1), \mathcal{U}(F^3)) = \frac{1}{H_2W_2}\sum\limits_{i=1}^{H_2W_2} f^2_i\circ f&amp;rsquo;^1_i\circ f&amp;rsquo;^3_i$$&lt;/p&gt;
&lt;p&gt;最后按通道分成g组，即 $C = g\times d$ ，可以认为分成了g个节点，每一个节点的特征维度为d（可以认为是d个像素空间的点构成了一个图空间的点）。在进行图卷积的时候，令 $H = \sigma(A_g X W_g)$ ，其中 $A_g\in R^{N\times N},X\in R^{N \times C},W_g\in R^{C\times F}$ ，这里的$N$就是上面的$g$，$C$就是上面的$d$。&lt;/p&gt;
&lt;p&gt;在邻接矩阵的设计上，使用了四种不同的策略，分别是固定为一跳邻居、单位阵初始化的可学习参数、正态分布初始化的可学习参数、均匀分布初始化的可学习参数。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;pgr-disen-adj.png&#34; srcset=&#34;
               /post/paper-pgr/pgr-disen-adj_hubce0fc37d4f14e646f179ebf00ee670e_78264_a79abd52f3160dacce050992d11ece86.webp 400w,
               /post/paper-pgr/pgr-disen-adj_hubce0fc37d4f14e646f179ebf00ee670e_78264_17222b45add156dc27f84114a6c75a1a.webp 760w,
               /post/paper-pgr/pgr-disen-adj_hubce0fc37d4f14e646f179ebf00ee670e_78264_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://yangleisx.github.io/post/paper-pgr/pgr-disen-adj_hubce0fc37d4f14e646f179ebf00ee670e_78264_a79abd52f3160dacce050992d11ece86.webp&#34;
               width=&#34;760&#34;
               height=&#34;252&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;最后在反向映射的过程中，采用了类似SE-Net的方式，将图卷积得到的结果作为通道注意力与原始数据相乘。&lt;/p&gt;
&lt;p&gt;在前景估计分支，作者使用了贝叶斯理论, 实际结构是学习得到一个分割图然后concat起来。使用了 $B = \delta(M_{fg} \cdot I\parallel (1-M_{fg}) \cdot I \parallel I)$ 的拼接方式。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;pgr-disen-entimation.png&#34; srcset=&#34;
               /post/paper-pgr/pgr-disen-fg-entimation_hu39e31c122b11baf80fda755c39575483_96734_d7c214f8f9c1a65893de4f0ed376a1b6.webp 400w,
               /post/paper-pgr/pgr-disen-fg-entimation_hu39e31c122b11baf80fda755c39575483_96734_553d67e70d91f4335104636b7bbba46e.webp 760w,
               /post/paper-pgr/pgr-disen-fg-entimation_hu39e31c122b11baf80fda755c39575483_96734_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://yangleisx.github.io/post/paper-pgr/pgr-disen-fg-entimation_hu39e31c122b11baf80fda755c39575483_96734_d7c214f8f9c1a65893de4f0ed376a1b6.webp&#34;
               width=&#34;760&#34;
               height=&#34;288&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;在边界对齐模块，作者号称使用了类似Optical Flow 光流的思想，学习得到一个类似光流的边界检测图然后与原本的特征相结合。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;pgr-disen-bam.png&#34; srcset=&#34;
               /post/paper-pgr/pgr-disen-bam_hu9308b3195789f8350ee447770743ed12_69347_d17ddba4976fef5bd87de8a377c734e1.webp 400w,
               /post/paper-pgr/pgr-disen-bam_hu9308b3195789f8350ee447770743ed12_69347_1002431e9a39250de6d30aa15a451515.webp 760w,
               /post/paper-pgr/pgr-disen-bam_hu9308b3195789f8350ee447770743ed12_69347_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://yangleisx.github.io/post/paper-pgr/pgr-disen-bam_hu9308b3195789f8350ee447770743ed12_69347_d17ddba4976fef5bd87de8a377c734e1.webp&#34;
               width=&#34;760&#34;
               height=&#34;435&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;在最后损失函数设计上，对于最后的分割使用Cross Emtropy 交叉熵，前景使用BCE_Loss和Dice Loss，添加了类似PSPNet中的辅助Loss。&lt;/p&gt;
&lt;h2 id=&#34;结果分析&#34;&gt;结果分析&lt;/h2&gt;
&lt;p&gt;在iSAID数据集和Vaihingen、Cityscapes数据集上测试了性能。
基本模型结构使用预训练的ResNet-50/101。&lt;/p&gt;
&lt;p&gt;简单看一下Ablation Study的效果。&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;pgr-disen-ablation.png&#34; srcset=&#34;
               /post/paper-pgr/pgr-disen-ablation_hu24765524787a58c68c7eace6997cea4b_123171_914aee42f9e522e84faf29050ee657f2.webp 400w,
               /post/paper-pgr/pgr-disen-ablation_hu24765524787a58c68c7eace6997cea4b_123171_dccf4094bbbb4bae7b9225a66c84ebd3.webp 760w,
               /post/paper-pgr/pgr-disen-ablation_hu24765524787a58c68c7eace6997cea4b_123171_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://yangleisx.github.io/post/paper-pgr/pgr-disen-ablation_hu24765524787a58c68c7eace6997cea4b_123171_914aee42f9e522e84faf29050ee657f2.webp&#34;
               width=&#34;659&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;使用了图推理的方式提取上下文信息。这一部分的论文还蛮多的，这里用了一种分组的方式来进行处理。比直接使用像素点的节约时间和空间，用通道注意力的方式进行反向映射的方式也成本比较低。&lt;/p&gt;
&lt;p&gt;使用了多分支的模型，分别学习分割图和边缘检测。利用边缘检测增强分割效果的想法蛮常见的。例如【论文】Boundary-aware Graph Reasoning for Semantic Segmentation或者【论文】Real-time Scene Text Detection with Differentiable Binarization|。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>【论文】Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations</title>
      <link>https://yangleisx.github.io/post/paper-challenge-disentabgle/</link>
      <pubDate>Tue, 20 Oct 2020 22:06:26 +0800</pubDate>
      <guid>https://yangleisx.github.io/post/paper-challenge-disentabgle/</guid>
      <description>&lt;p&gt;论文题目：Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations&lt;/p&gt;
&lt;p&gt;作者：Francesco Locatello, Stefan Bauer, Mario Lucic, Gunnar Rätsch, Sylvain Gelly, Bernhard Schölkopf,  Olivier Bachem&lt;/p&gt;
&lt;p&gt;会议/时间：ICML2019&lt;/p&gt;
&lt;p&gt;链接：&lt;a href=&#34;https://arxiv.org/pdf/1811.12359.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/pdf/1811.12359.pdf&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;论文目标&#34;&gt;论文目标&lt;/h2&gt;
&lt;p&gt;近年来关于disentangled representation 的unsupervised learning相关的研究非常多，其核心观点为现实世界中的数据是通过一些单独的可解释的元素生成的，可以通过无监督学习的方式学习到数据的一种表示。本文通过理论分析，证明在模型和数据不添加归纳偏置的情况下这种无监督学习是不可能实现的，同时文中在多个数据集上训练了近年来的相关模型。最终提出了进一步研究的方向。&lt;/p&gt;
&lt;h2 id=&#34;相关工作&#34;&gt;相关工作&lt;/h2&gt;
&lt;p&gt;目前效果比较好的模型大多是基于变分自编码器（Variational Autoencoder，VAE），即认为现实世界中的数据来源于一个高维隐变量$z \sim P(z)$，实际观察到的数据为$x$，通过建立一个自编码器，包括编码器和解码器学习得到$P(x|z)$和$Q(z|x)$，其中使用$Q(z|x)$近似实际的$P(z|x)$，从而从数据$x$中学到一个表示$r(x)$去寻找隐变量$z$。&lt;/p&gt;
&lt;p&gt;这一领域之前的研究包括独立成分分析（Independent Component Analysis，ICA）等。&lt;/p&gt;
&lt;h2 id=&#34;本文思路解决方案&#34;&gt;本文思路/解决方案&lt;/h2&gt;
&lt;p&gt;给定如下的理论&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;For $d &amp;gt; 1$ , let $z \sim P$ denote any distribution which admits a density $p(z) = \prod_{i=1}^{d}p(z_i)$. Then, there exists an infinite family of bijective functions f : supp(z) → supp(z) such that $\frac {\partial f_i(u)}{\partial u_j}$ almost everywhere for all $i$ and $j$ (i.e., $z$ and $f(z)$ are completely entangled) and $P(z \leq u) = P(f(z) \leq u)$ for all $u \in supp(z)$ (i.e., they have the same marginal distribution).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;可以得到，对于给定的数据$x$，可以找到无限多的$p(z)$满足要求，且这些$p(z)$相互等价并满足disentangled的要求，一个无监督的模型难以区分这些$p(z)$。因此在实际的模型中，需要为模型结构和数据集引入合理的归纳偏置（inductive bias）。&lt;/p&gt;
&lt;p&gt;在实验设计中，使用到的模型为添加了正则项的VAE，包括betaVAE、AnnealedVAE、FactorVAE、beta-TCVAE、DIP-VAE等。在模型的度量标准中，使用了包括BetaVAE Metric、FactorVAE Metric、MIG(Mutual Information Gap)、Modularity、SAP Score等方法。使用到的数据集包括四个3D空间变化的数据集和三个随机的噪声数据集。&lt;/p&gt;
&lt;p&gt;在归纳偏置中，为了控制变量，对于所有的模型使用相同的卷积结构、优化算法、超参数，使用相同的Gaussian Encoder和Bernoulli Decoder，使用相同的隐变量维度（=10），构建模型进行测试。仅使用不同的正则项和不同的正则项权重。&lt;/p&gt;
&lt;h2 id=&#34;结果&#34;&gt;结果&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;当正则化系数增大时，使用拟合高斯的采样得到的相关性减小，使用均值表示的相关性增大。可以证明上述模型可以得到不同维度相关性比较弱的聚合先验，但是并不能表示均值表示也是不相关的。&lt;/li&gt;
&lt;li&gt;在不同的性能度量中，除了Modularity以外的几种都是相关的，只是在不同的数据集上的相关性有差异。&lt;/li&gt;
&lt;li&gt;模型的性能受到随机初始化和超参数的影响比较大，目标函数在其中影响比较小。&lt;/li&gt;
&lt;li&gt;如何选择无监督模型仍然等待得到解决。在不同数据集和度量指标之间的超参数迁移用处不大。&lt;/li&gt;
&lt;li&gt;实验并不能证明这些disentangled表示对于下游的任务有所帮助。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;在将来的研究中可以将重点更多放在如下三个方面：1）归纳偏置和显/隐性监督，2）disentangled representation的实际效益，3）实验设置和数据集的多样性。&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
