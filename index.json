
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":" Lei Yang received the B.Eng. degree from Shanghai Jiao Tong University(SJTU) in 2021. He is currently pursuing the Ph.D. degree with the SEIEE, SJTU, under the supervision of Professor Shilin Wang. His research interests include computer vision, visual speech recognition, and semantics segmentation.\n","date":1713147503,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1713147503,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Lei Yang received the B.Eng. degree from Shanghai Jiao Tong University(SJTU) in 2021. He is currently pursuing the Ph.D. degree with the SEIEE, SJTU, under the supervision of Professor Shilin Wang.","tags":null,"title":"Lei Yang","type":"authors"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文题目：Landmark-Guided Cross-Speaker Lip Reading with Mutual Information Regularization\n作者：Linzhi Wu, Xingyu Zhang, Yakun Zhang, Changyan Zheng, Tiejun Liu, Liang Xie, Ye Yan, Erwei Yin 单位：University of Electronic Science and Technology of China,\n会议/时间：arxiv 2024, COLING 2024\n链接: arxiv.\nTL; DR 前端网络的修改主要两部分： 一方面用landmark提取关键点周围的3D特征 一方面用帧差的时序卷积提取动态特征。\n后端网络添加了一个身份识别模块，做两阶段的对抗训练。 使得前端提取的特征偏向内容而不是身份。\n论文目标 相关工作 本文方法 对抗训练的部分使用互信息的最大最小原则来训练。 最小化互信息的部分，使用CLUB作为互信息上界来最小化，\n$$\\begin{aligned} \\mathcal I_{vCLUB}(X,Y) \u0026amp;:= \\mathbb E_{p(X, Y)}\\left[\\log q_{\\phi}(y|x)\\right] - \\mathbb E_{p(X)}\\mathbb E_{p(Y)}\\left[\\log q_{\\phi}(y|x)\\right] \\\\ \\mathcal L_{\\min MI} \u0026amp;= \\mathcal{I}_{vCLUB} (\\mathbf h^{ID},\\mathbf{H}^{L_b}) \\end{aligned}$$ 最大化互信息的部分，使用JS距离作为互信息下界来最大化。 $$\\begin{aligned} \\hat{\\mathcal{I}}^{(JSD)}_\\theta (X,Y) \u0026amp;:= \\mathbb{E}_{p(X,Y)}\\left[−\\log(1 + e^{-\\mathcal F_\\theta(x, y)})\\right]− \\mathbb{E}_{p(X)p(Y)}\\left[\\log(1 + e^{\\mathcal F_\\theta(x,y))}\\right]\\\\ \\mathcal L_{\\max MI} \u0026amp;= -\\hat{\\mathcal{I}}^{(JSD)}_\\theta (\\mathbf H^{(0)},\\mathbf{H}^{L_b}) \\end{aligned}$$ 结果分析 总结","date":1713147503,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1713147503,"objectID":"c7e75da728eadfa6c79b7339a9de84e9","permalink":"https://yangleisx.github.io/post/paper-land-mir/","publishdate":"2024-04-15T10:18:23+08:00","relpermalink":"/post/paper-land-mir/","section":"post","summary":"论文题目：Landmark-Guided Cross-Speaker Lip Reading with Mutual Information Regularization\n作者：Linzhi Wu, Xingyu Zhang, Yakun Zhang, Changyan Zheng, Tiejun Liu, Liang Xie, Ye Yan, Erwei Yin 单位：University of Electronic Science and Technology of China,\n会议/时间：arxiv 2024, COLING 2024\n链接: arxiv.\n","tags":["Lip Reading","Mutual Information Regularization"],"title":"【论文】Landmark-Guided Cross-Speaker Lip Reading with Mutual Information Regularization","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文题目：An Effective Mixture-Of-Experts Approach For Code-Switching Speech Recognition Leveraging Encoder Disentanglement\n作者：Tzu-Ting Yang, Hsin-Wei Wang, Yi-Cheng Wang, Chi-Han Lin, and Berlin Chen 单位：National Taiwan Normal University\n会议/时间：ICASSP 2024\n链接: doi.\nTL; DR 采用解耦结合MOE的方式来进行多语言的语音识别。\n论文目标 ASR模型在单语言上有很好的性能，但是在Code-Switch场景下性能不好。\n难点有两部分，一个是高质量数据集缺乏。一个是不同语言之间的差异。 不同的拼音语言之间差异较小，但是中文英文之间差异很大。造成模型会混淆。\n相关工作 一种做法是LID，即language identification，使用语言分类预测头，判别当前位置是什么语言。 一种做法是双编码器，但是可能会损失不同语言上下文之间的关系。 因此常见做法是LAE，就是language-aware encoder，单一的编码器但是具有语言感知能力。\n本文方法 结构比较简单。\n包含共享的编码器，提取完整的特征。语言特定编码器，提取特定语言特征。 语言特定编码器的监督是CTC损失，使用语言mask来指导。 MoE混合的监督也是CTC损失，使用完整的序列来监督。 完整的损失包含两部分，一部分是使用目标序列监督的CTC损失，还有一部分是解耦损失。 其中的解耦损失就是对应位置上的特征的Cosine距离。 即 $$\\begin{aligned} L_{lang} \u0026amp;= \\frac{1}{2}(L_{ZH} + L_{EN}) \\\\ L \u0026amp;= \\frac{1}{2}(L_{Mix} + L_{Lang}) + \\lambda L_{Disen} \\\\ L_{Disen} \u0026amp;= -\\frac{1}{N}\\sum_{i=1}^N \\frac{1}{|s_i|}\\sum_{j=1}^{|s_i|}CD(\\mathbf h_{i, j}^{ZH}, \\mathbf h_{i, j}^{EN})\\\\ CD(\\mathbf h_{i, j}^{ZH}, \\mathbf h_{i, j}^{EN}) \u0026amp;= 1 - \\frac{\\mathbf h_{i, j}^{ZH}\\cdot \\mathbf h_{i, j}^{EN}}{||\\mathbf h_{i, j}^{ZH}||_2 ||\\mathbf h_{i, j}^{EN}||_2} \\end{aligned}$$ 结果分析 在[[SEAME]]数据集上完成实验。 语言的预处理部分，中文字典包含2624个字，英文字典包含3000个BPE。\n和简单Concatenate相比，使用MoE的方式在经过解耦之后有所提升。 如果不解耦直接使用MoE，会导致门控网络出现混淆。 进一步可视化了Gating Network的输出。 总结","date":1712029745,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712029745,"objectID":"58219c85a91f8f780fd83da9bc8c4b25","permalink":"https://yangleisx.github.io/post/paper-moe-csasr/","publishdate":"2024-04-02T11:49:05+08:00","relpermalink":"/post/paper-moe-csasr/","section":"post","summary":"论文题目：An Effective Mixture-Of-Experts Approach For Code-Switching Speech Recognition Leveraging Encoder Disentanglement\n作者：Tzu-Ting Yang, Hsin-Wei Wang, Yi-Cheng Wang, Chi-Han Lin, and Berlin Chen 单位：National Taiwan Normal University\n会议/时间：ICASSP 2024\n链接: doi.\n","tags":["Code Switching Speech Recognition","Disentangled Learning","Mixture of Experts"],"title":"【论文】An Effective Mixture-Of-Experts Approach For Code-Switching Speech Recognition Leveraging Encoder Disentanglement","type":"post"},{"authors":["Yi He","Lei Yang","Hanyi Wang","Yun Zhu","Shilin Wang"],"categories":null,"content":" In this paper, we propose a novel speaker-adaptive lipreading model. For front-end network, conv-based LoRA modules are used to adapt to speaker’s space features. For back-end network, a plug-and-play TAWL module is designed to learn temporal characteristics. An Adapter module is finally employed to bridge the adaptation knowledge from front-end and back-end. The experiments show that the proposed method achieve the state-of-the-art performance on both word-level and sentence-level dataset with fewer training parameters.\n","date":1710460800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1710460800,"objectID":"df2a78da2aa4ef86955dcc5be7591d49","permalink":"https://yangleisx.github.io/publication/icassp-udp/","publishdate":"2024-01-19T00:00:00Z","relpermalink":"/publication/icassp-udp/","section":"publication","summary":"A novel speaker-adaptive lipreading model is proposed.","tags":null,"title":"Speaker-Adaptive LipReading via Spatio-Temporal Information Learning","type":"publication"},{"authors":["Lei Yang"],"categories":["基础知识"],"content":"在本科机器学习课程上讲了逻辑回归的相关内容. 感觉有些部分课堂上讲的比较粗,回来补充一些公式的推导和清晰一点的定义.\n符号定义：\n$x_i$表示输入数据的一个样本，${\\hat x_i} = (x_i; 1)$。 $y_i$表示数据的真实类别（$y_i \\in {0, 1}$） $f_\\beta(x_i)$表示模型在给定输入下的输出，其中$\\beta=(w; b)$为模型参数。 logistic regression的公式定义为$$f_{\\beta}(x) = \\sigma(wx+b) =\\frac{1}{1 + e^{-(wx+b)}}$$ 其中$\\sigma(z) = \\frac{1}{1+e^{-z}}$为logistic函数。\n将模型的输出$f_{\\beta}(x)$看作是概率$p(y=1|x, \\beta)$，即回归模型认为输入数据是正例的概率。有 $$\\begin{aligned} p(y=1 | x, \\beta) \u0026amp;= \\frac{e^{(wx+b)}}{1 + e^{(wx+b)}} \\quad(即 f_{\\beta}(x)) \\\\ p(y=0 | x, \\beta) \u0026amp;= \\frac{1}{1 + e^{(wx+b)}} \\quad(即 1 - p(y=1 | x, \\beta)=1-f_\\beta(x))\\\\ \\end{aligned}$$ 在模型优化过程中，我们希望所有的样本被正确分类。 即正例样本被预测为正例的概率增大，反例样本被预测为反例的概率增大。\n使用极大似然原则进行优化时： 对于所有正例样本，$p(y=1|x, \\beta)$表示模型对该样本属于类别1的似然度估计，其对数似然如下 $$\\sum_{y=1} \\log p(y=1| x, \\beta) = \\sum_{y=1} \\log f_{\\beta}(x)$$ 对于所有反例样本，$p(y=0|x, \\beta)$表示模型对该样本属于类别0的似然度估计，其对数似然如下 $$\\sum_{y=0} \\log p(y=0| x, \\beta) = \\sum_{y=0} \\left[ 1- \\log f_{\\beta}(x)\\right]$$\n对于所有的样本进行极大化对数似然，其中对数似然与$y_i$和$(1- y_i)$的乘法用于筛选数据集中的正例和反例。 $$\\begin{aligned} \\mathop{Maximum}\\limits_{\\beta}:\u0026amp;\\quad \\sum_{y=1} \\log p(y=1| x, \\beta) + \\sum_{y=0} \\log p(y=0| x, \\beta) \\\\ = \u0026amp;\\quad \\sum_{i} {\\Huge [} y_i \\log p(y=1| x_i, \\beta)+ (1-y_i) \\log p(y=0| x_i, \\beta) {\\Huge ]} \\\\ = \u0026amp;\\quad \\sum_{i} {\\Huge [} y_i \\log f_\\beta(x_i)+ (1-y_i) \\log (1 - f_\\beta(x_i) ) {\\Huge ]} \\\\ \\end{aligned}$$ 将极大化对数似然转换为最小化对数似然损失的方式，并代入模型的输出，可以得到\n$$\\begin{aligned} \\mathop{Minimum}\\limits_{\\beta}: \u0026amp;\\quad - \\sum_{i} {\\Huge [} y_i \\log f_\\beta(x_i)+ (1-y_i) \\log(1 - f_\\beta(x_i) ) {\\Huge ]}\\\\ = \u0026amp;\\quad -\\sum_i {\\Huge [} y_i \\log \\frac{ f_\\beta(x_i)}{1 - f_\\beta(x_i)}+ \\log(1 - f_\\beta(x_i) ) {\\Huge ]} \\\\ \u0026amp;\\mbox{(代入}f_{\\beta}(x_i)\\mbox{的定义，得到课件 Page15 中的结果)}\\\\ \\mathscr{l}(\\beta) = \u0026amp;\\quad \\sum_i {\\Huge [} - y_i (wx_i+b)+ \\log(1 + e^{wx_i+b}) {\\Huge ]}\\\\ = \u0026amp; \\quad \\sum_{i}\\left[ -y_i(\\beta^T{\\hat x_i}) + \\log(1 + e^{(\\beta^T{\\hat x_i})}) \\right] \\\\ \\end{aligned}$$ 此时可以计算得到梯度$\\frac{\\partial {\\mathscr l}(\\beta)}{\\partial \\beta}$并优化求解。\n","date":1709624238,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1709624238,"objectID":"f9474b9ba686ff8617ad03d0bee39671","permalink":"https://yangleisx.github.io/post/logistic_regression/","publishdate":"2024-03-05T15:37:18+08:00","relpermalink":"/post/logistic_regression/","section":"post","summary":"在本科机器学习课程上讲了逻辑回归的相关内容. 感觉有些部分课堂上讲的比较粗,回来补充一些公式的推导和清晰一点的定义.\n","tags":["Logistic Regression","机器学习"],"title":"逻辑回归原理补充","type":"post"},{"authors":["Lei Yang"],"categories":["实用工具","代码学习","论文阅读"],"content":"CTC(连接主义的时序分类)是一种在长度不同的序列中计算损失的方式。 对于不定长的模型输出和标签，在没有给定对齐的情况下计算概率和梯度，从而进行模型的训练。\n在基于Attention的模型中,使用hybrid ctc+attention的方式训练，在解码过程中，进一步利用训练时CTC头部的信息，可以计算CTC前缀得分，加入到Beam Search解码中。这里前缀得分的计算方式与CTC Loss的前向后向算法的前向部分比较类似。\n首先需要明确两个概念：规整字符串和CTC字符串。\n在使用CTC进行训练的时候，前者表示训练集的标签，后者表示序列模型的输出。 即CTC字符串经过合并重复和去除Blank之后得到的结果。\n在训练过程中，CTC损失计算可以合并得到规整字符串$y = [y_1, y_2, …, y_N]$的所有CTC字符串$z = [z_1, z_2, …, z_T]$的概率。\n在预测的过程中，在每一个时间步$t$，给定之前$t-1$步计算得到的前缀$g = [y_1, y_2, …, y_c]$和预测结果$c = y_p$，计算CTC字符串$z_1, z_2, …, z_t$预测得到给定规整字符串$h=gc$的概率，因此计算过程类似CTC损失的前向部分。\n在时间步$t$增加的时候，需要维护两个中间变量 $p^{b}_{t} \\in {\\mathbb R}^{T}$ 和 $p^{n}_{t} \\in {\\mathbb R}^{T}$。\n其中 $p^{b}_{t}$ 表示 $z[:t]$ 即以空白符号结尾的长度为 $t$ 的CTC字符串规整到目标的概率，$p^{n}_{t}$ 表示 $z[:t]$ 即非空白符号结尾的长度为 $t$ 的CTC字符串的概率。\n这一步的中间变量是为了简化计算的过程，因为在$h=gc$的时候，可以根据 $p_{t-1}^{b}(g)$计算得到 $p^b_{t}(h)$。\n在初始化时，目标前缀字符串为空串。\n$p^{b}_{t}=\\prod_{i=0}^{t} p(z_i=blank)$，即长度为$t$的CTC字符串解析到空串的概率为每一位解析为blank的概率乘积。 $p^{n}_{t}=0$，即任何非空白符号结尾的CTC字符串都不可能解析到空串。 在遍历时，给定前缀为$g = [y_1, y_2, …, y_c]$和预测结果$c = y_p$，计算并返回$h=gc$的概率。\n$y_c \\neq y_p$时，返回值为 $[p^{b}_{t-1}(g)+p^n_{t-1}(g)]p(y_p)$，即$z[:t-1]$可以规整为$g$和$g -$的概率与$z_t = y_p$的概率乘积。两者相乘表示CTC 字符串$z[:t]$可以规整为$h=gc$的概率。 $y_c=y_p$时，返回值为$[p^b_{t-1}(g)]p(y_p)$，由于前缀$g$最后一个字符与预测字符相同，只有以blank结尾的$z[:t-1]$序列可以规整到$h=gc$。 同时需要更新中间变量，即计算$p_{t}^{b}(h)$和$p_{t}^{n}(h)$，需要分情况讨论。\n更新 $p^{b}_{t}(h)$：$p^{b}_{t}(h) = [p^{b}_{t-1}(g) + p^{n}_{t-1}(g)]p(-)$，即$z[:t]$规整为h的概率，可以使用$z[:t-1]$规整为g的概率与当前位置预测为空的概率计算。 更新$p^{n}_{t}(h)$： 如果$y_c = y_p$时：$p_{t}^{n}(h) = \\left[p_{t-1}^{b}(g) + p_{t-1}^{n}(h)\\right]p(y_p)$，第一项表示以blank结尾的前缀，后一项表示重复符号的情况。 如果$y_c \\neq y_p$时：$p_{t}^{n}(h) = \\left[p_{t-1}^{b}(g) + p_{t-1}^{n}(g) + p_{t-1}^{n}(h)\\right]p(y_p)$，分别表示$z[:t-1]$规整到$g$和$h$的情况。 代码 下面结合代码进行分析。\n\u0026#34;\u0026#34;\u0026#34; 一个简单的使用attention+ctc的混合解码的代码实现 \u0026#34;\u0026#34;\u0026#34; import torch from torch import nn, Tensor from datasets import const def ctc_prefix_score( ctc_probs, seq_len, prefix, next_word, prev_state ): assert ctc_probs.shape[0] == 1 assert ctc_probs[0, 0].exp().sum() \u0026gt; 0.99, \\ f\u0026#34;sum up as {ctc_probs[0, 0].exp().sum()}\u0026#34; # 获得前缀的长度 prev_length = prefix.shape[-1] # 获得不同长度CTC字符串得到前缀的概率p^n(g)和p^a(g) gamma_nbk = prev_state[0].clone() gamma_blk = prev_state[1].clone() # 计算前缀的概率,包括结尾为blank和非blank两种情况的概率求和 prev_sum = torch.logaddexp(gamma_nbk, gamma_blk) if prev_length \u0026gt; 0: if prefix[-1] != next_word: log_phi = prev_sum else: log_phi = gamma_blk else: log_phi = prev_sum # 达到EOS的时候直接输出 if next_word == const.EOS: psi = prev_sum[-1] return psi, None, None if prev_length == 0: # 如果前缀为空串，可以直接计算 gamma_nbk[0] = ctc_probs[0, 0, next_word] gamma_blk[0] = -1e10 else: # 对于长度小于n的CTC字符串，无法得到长度为n的规整字符串 # 严格说要将[0 : prev_length-1]都设置为0 # 但是之前的部分不参与迭代的计算 gamma_nbk[prev_length-1] = -1e10 gamma_blk[prev_length-1] = -1e10 # 确认计算开始的位置 start = max(1, prev_length) psi = gamma_nbk[start-1] for t in range(start, seq_len): # 更新p^n_t(h)为p^n_{t-1}(h)和phi的和 # 即上一时刻得到h的概率乘上当前位置重复符号的概率 # 加上上一时刻得到g的概率 gamma_nbk[t] = torch.logaddexp( gamma_nbk[t-1], log_phi[t-1] ) + ctc_probs[0, t, next_word] # 更新p^b_t(h)为p^b_{t-1}(h)和p^n_{t-1}(h)的和 # 即在上一时刻就得到h的概率 # 再乘上当前位置预测得到空串的概率 gamma_blk[t] = torch.logaddexp( gamma_blk[t-1], gamma_nbk[t-1] ) + ctc_probs[0, t, const.PAD] # 输出的序列概率值为上一时刻得到h的概率 # 加上上一时刻得到g，当前位置预测c的概率。 psi = torch.logaddexp( psi, log_phi[t-1] + ctc_probs[0, t, next_word] ) return psi, gamma_nbk, gamma_blk @torch.no_grad() def hybrid_decoder( m_transformer: nn.Module, m_embed: nn.Module, m_mlp: nn.Module, ctc_head: nn.Module, embed_src_seq: Tensor, src_padding_mask: Tensor, mask_list, beam_size: int, max_len: int, device: torch.DeviceObjType, ctc_weight: int = 0.1 ): assert embed_src_seq.shape[0] == 1 assert embed_src_seq.shape[2] == m_embed.emb_size encode_memory = m_transformer.encode( embed_src=embed_src_seq, src_mask=None, src_key_padding_mask=src_padding_mask, ) # 获得输入序列的长度 seq_len = (~src_padding_mask).sum(dim=1)[0] # 计算得到CTC头部的预测结果 ctc_probs = ctc_head.mlp(encode_memory).log_softmax(-1) # 初始化CTC中间变量 gamma_nbk = torch.full((seq_len, ), -1e6, device=device) gamma_blk = torch.full((seq_len, ), -1e6, device=device) for i in range(seq_len): if i == 0: gamma_blk[i] = ctc_probs[0, i, const.PAD] else: gamma_blk[i] = gamma_blk[i-1] + ctc_probs[0, i, const.PAD] # 初始化所有假设 total_hypos = [ ( torch.tensor([const.BOS], dtype=torch.long, device=device), torch.tensor(0, device=device), (gamma_nbk, gamma_blk), ) ] eos_hypos = [] # 限制解码长度 decode_len = min(max_len, seq_len) for decode_idx in range(1, decode_len): # 记录每次迭代得到的K**2个hypos running_hypos = [] for cur_hyp in total_hypos: # 获得前缀开始处理 prefix = cur_hyp[0].unsqueeze(0) # [1, decode_idx] embed_prefix = m_embed(prefix) attn_mask = mask_list[prefix.shape[1] - 1] probs = m_transformer.decode( embed_tgt=embed_prefix, memory=encode_memory, tgt_mask=attn_mask, tgt_key_padding_mask=None, memory_key_padding_mask=src_padding_mask, ) probs = m_mlp(probs[0, -1, :]).log_softmax(dim=-1) best_score, best_idx = probs.topk（ k=beam_size, dim=-1 ) for k_idx, next_word in enumerate(best_idx): # 对于每一种可能的结果打分 attn_score = cur_hyp[1] + best_score[k_idx] ctc_score, …","date":1708846370,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1708846370,"objectID":"3b67f760e99c95fbba2671780f2ef9b4","permalink":"https://yangleisx.github.io/post/ctc_prefix_score/","publishdate":"2024-02-25T15:32:50+08:00","relpermalink":"/post/ctc_prefix_score/","section":"post","summary":"CTC(连接主义的时序分类)是一种在长度不同的序列中计算损失的方式。 对于不定长的模型输出和标签，在没有给定对齐的情况下计算概率和梯度，从而进行模型的训练。\n在基于Attention的模型中,使用hybrid ctc+attention的方式训练，在解码过程中，进一步利用训练时CTC头部的信息，可以计算CTC前缀得分，加入到Beam Search解码中。这里前缀得分的计算方式与CTC Loss的前向后向算法的前向部分比较类似。\n","tags":["Lip Reading","Transformer","Visual Speech Recognition"],"title":"CTC前缀分数计算","type":"post"},{"authors":["Yi He","Lei Yang","Shilin Wang","Alan Wee-Chung Liew"],"categories":null,"content":" In this paper, we proposed a visual speaker authentication system using the random prompt text scheme to meet the requirements of mobile applications. Lip features are disentangled into three parts, i.e. the static identity features, the dynamic identity features and the content features by the proposed TDVSA-Net. The experiment results show that the content features obtained the lowest WER in speaker- independent lip-reading compared with other lipreading models, and the identity features had comparable performance with the state-of-the-art methods on detecting human imposters and DeepFake imposters and exhibits more robustness when facing different image qualities. Therefore, our VSA system can be a feasible solution for today’s widely used mobile applications.\n","date":1704844800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704844800,"objectID":"5fd4b6501903f192356210148aa1e793","permalink":"https://yangleisx.github.io/publication/tcsvt-vsa/","publishdate":"2024-05-27T00:00:00Z","relpermalink":"/publication/tcsvt-vsa/","section":"publication","summary":"Lip features are disentangled into three parts, i.e. the static identity features, the dynamic identity features and the content features by the proposed TDVSA-Net.","tags":[],"title":"Lip Feature Disentanglement for Visual Speaker Authentication in Natural Scenes","type":"publication"},{"authors":["Lei Yang","Shilin Wang","Alan Wee-Chung Liew"],"categories":null,"content":" In this paper, we proposed a new lip segmentation method based on fuzzy convolutional neural network with graph reasoning that can learn high-level semantics. The fuzzy learning module and the fuzzy graph reasoning module help the deep convolutional neural network to handle uncertainties around ambiguous boundaries, capture global information, and improve multi-class lip region segmentation. In addition, a fine-grained lip region dataset is released for multi-class segmentation studies. Our proposed approach achieved satisfactory performance on the test set, with 94.36% pixel accuracy and 74.89% mIoU. The experiment results have demonstrated that the proposed method can be applied in many lip-related applications to obtain accurate and robust lip region segmentation in natural scenes.\nHowever, the proposed network cannot achieve satisfactory results in certain scenarios, specifically in cases of occlusion or extreme lighting conditions. This limitation can be attributed to the FLRSeg dataset, which is derived from the VSA dataset that was collected for speaker authentication and thus required unobstructed lip movements. In our future work, we will further improve the segmentation performance in various situations and explore the potential of leveraging the segmentation results in downstream tasks, such as lip reading and visual speaker authentication, to enhance performance and accelerate converge.\n","date":1690156800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690156800,"objectID":"94f8e2e9184f2654bf74ce49a32462c5","permalink":"https://yangleisx.github.io/publication/tfs-lip-seg/","publishdate":"2024-01-20T00:00:00Z","relpermalink":"/publication/tfs-lip-seg/","section":"publication","summary":"A new lip segmentation method based on fuzzy convolutional neural network with graph reasoning that can learn high-level semantics is proposed.","tags":[],"title":"Fine-Grained Lip Image Segmentation using Fuzzy Logic and Graph Reasoning","type":"publication"},{"authors":["Lei Yang"],"categories":[],"content":"Weight Decay权重衰减机制是一个比较常用的训练策略。 但是在某些场景下，需要在训练的时候关闭WeightDecay。\n例如在训练ViT的时候，对于position embedding和class token都是不需要添加WeightDecay的，在训练卷积网络的时候，对于卷积层的bias参数也是可以不添加WeightDecay的。因此需要在创建优化器的时候指明。\n# models.py class ViT(nn.Module): ... def no_weight_decay(self): return {\u0026#34;pos_embed\u0026#34;, \u0026#34;cls_token\u0026#34;} ... class Model(nn.Module): def __init__(self): self.encoder = ViT() def no_weight_decay(self): def append_prefix_no_weight_decay(prefix, module): return set(map(lambda x: prefix + x, module.no_weight_decay())) nwd_params = append_prefix_no_weight_decay(\u0026#34;encoder\u0026#34;, self.encoder) return nwd_params # train.py def train(): ... net = Model() # 获得不需要添加weightdecay的列表 no_weight_decay_list = set(net.no_weight_decay()) decay = [] no_decay = [] # 遍历并区分参数 for name, param in net.named_parameters(): if not param.requires_grad: continue # 对于卷积层中的bias不需要weight decay # 对于模型中指明不需要weight decay的部分 if param.ndim \u0026lt;= 1 or name.endswith(\u0026#34;.bias\u0026#34;) or name in no_weight_decay_list: no_decay.append(param) else: decay.append(param) # 获得多个param_group，指定不同的weightdecay参数 parameters = [ {\u0026#39;params\u0026#39;: no_decay, \u0026#39;weight_decay\u0026#39;: 0.}, {\u0026#39;params\u0026#39;: decay, \u0026#39;weight_decay\u0026#39;: 1e-5} ] # pytorch的优化器允许输入多组参数 optimizer = optim.Adam(parameters, lr=config[\u0026#39;learning_rate\u0026#39;]) ","date":1666665297,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666665297,"objectID":"21ceb3b2bb6f7aab38557cb29ea7b995","permalink":"https://yangleisx.github.io/post/no-weight-decay/","publishdate":"2022-10-25T10:34:57+08:00","relpermalink":"/post/no-weight-decay/","section":"post","summary":"Weight Decay权重衰减机制是一个比较常用的训练策略。 但是在某些场景下，需要在训练的时候关闭WeightDecay。\n","tags":[],"title":"PyTorch中No Weight Decay策略","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文题目：Class-wise Dynamic Graph Convolution for Semantic Segmentation\n作者：Hanzhe Hu, Deyi Ji, Weihao Gan, Shuai Bai, Wei Wu, and Junjie Yan\n会议/时间：ECCV2020\n链接: Springer\n论文目标 使用GCN的方式来增强图像分割模型的感受野，提取丰富的上下文信息。使用由粗到细的方式，在GR中只引入同类型像素的特征进行增强。\n使用膨胀卷积等方式增大感受野不适用于像素级预测的密集任务，会出现信息丢失。因此可以使用GCN或者基于Attention 注意力机制的方法。但是使用注意力的算法往往使用全部像素特征聚合进行分类，很难得到具有判别力的像素特征。因此采用了只关注同类别像素特征和关注难正例、难反例的方式加强特征提取。同时也进一步减小全连接图带来的计算成本。\n相关工作 语义分割相关的工作包括UNet、SegNet、RefineNet、PSPNet、Deeplab等。都是采用了增加层数、膨胀卷积的方式增加感受野。\n在聚合上下文信息方面的工作包括DeepLab 系列、DANet、PSPNet、Non-Local Block等，包括使用Multi-Grid或者Attention 注意力机制的方式增强感受野。\n在Graph Reasoning 图推理相关的工作包括DeepLab引入的CRF 条件随机场、GloRe等。基本都是建立全连接图进行处理和分析。综合考虑了所有像素的特征。\n本文方法 整体结构如下，首先进行粗检测结果，得到$M$个类别的Mask图，接着将原本的图像特征重复$M$次分别用对应的Mask进行掩码处理，得到类别有关的特征。接着进行图卷积。\n图卷积的关键是建立邻接矩阵，这里关键的两点设计为相似度邻接矩阵和难例筛选。\n在构建图的时候，一种方法（Basic-GCN）使用相似度和Softmax操作得到行归一化之后的邻接矩阵。 $$\\begin{aligned} F(x_i, x_j) \u0026amp;= \\phi(x_i)^T \\phi\u0026#39;(x_j) \\\\ A_{ij} \u0026amp;= \\frac{exp(F(x_i, x_j))}{\\sum_j exp(F(x_i, x_j))} \\end{aligned}$$ 另一种方法（Dynamic Sampling GCN）是使用难例筛选，令 $C$ 为预测得到的Mask，$G$ 为Ground Truth。可以得到 $Easy Positive = C \\cap G$，$HardNegative = C - C\\cap G$，$Hard Positive = G - C \\cap G$。\n于是采样点为 $$\\begin{aligned} Sampled \u0026amp;= C-C\\cap G + G - C\\cap G + ratio \\cdot C\\cap G\\\\ \u0026amp;= C\\cup G - (1-ratio)\\cdot C \\cap G \\end{aligned}$$ 这里在训练的时候使用Ground Truth进行难例筛选，在推断的时候使用全部预测mask进行推断。\n在GCN的部分使用M组参数分别进行卷积。最后通过1x1的卷积得到与原本特征形式相同的特征。\n训练的损失函数包括粗检测结果和最终检测结果的监督。同时在Backbone中间也加入了辅助损失加快收敛。\n结果分析 ablation study做的比较多。 最后比了一下SOTA。 总结 在图卷积的部分就设计了难例筛选，而不是像OHEM那样在最后的分割图上做mining。\n从coarse-to-fine的思路出发。\n个人觉得有点类似OCRNet。\n","date":1657075527,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657075527,"objectID":"ca72601b226244ec58caeff47e1b8a41","permalink":"https://yangleisx.github.io/post/paper-cdgc/","publishdate":"2022-07-06T10:45:27+08:00","relpermalink":"/post/paper-cdgc/","section":"post","summary":"论文题目：Class-wise Dynamic Graph Convolution for Semantic Segmentation\n作者：Hanzhe Hu, Deyi Ji, Weihao Gan, Shuai Bai, Wei Wu, and Junjie Yan\n会议/时间：ECCV2020\n链接: Springer\n","tags":["Graph Convolutional Network","Graph Reasoning","Semantic Segmentation"],"title":"【论文】Class-wise Dynamic Graph Convolution for Semantic Segmentation","type":"post"},{"authors":[],"categories":[],"content":"HRNet是CVPR2019提出的一种非常强的Backbone，论文参考arXiv，代码已经开源github（用于分割的代码还没有全部开源）。\n在分割任务中通常需要得到与原始图像类似的高分辨率的图像输出。常用的办法包括U-Net U型网络和FCN 全卷积网络，FPN 特征金字塔网络等。这些模型中基本都涉及到分辨率由大变小再重建。如图所示。\nHRNet中将不同分辨率的路径进行并联，在通道维度上保持了多种不同大小的分辨率。 在不同分辨率的特征图之间添加了信息的交互，分别使用stride3x3的卷积、上采样+1x1卷积实现。最后将三个部分的特征加到一起。\n当充分提取到模型的特征之后，将不同维度的特征融合起来用于最后的任务。 其中V2版本将小的特征图上采样，适用于语义分割和面部关键点检测，V2p版本使用的特征金字塔适用于目标检测任务。\n特别地，使用分类任务预训练的时候，采用了如下的方式进行特征的融合。\nHRNet可以应用在人体语义解析、语义分割、Object Detection 目标检测、图像分类等多种任务中，是一种比较强的Backbone。\n但是吧据说这东西训练速度和计算量都不小。\nSE-HRNet 后面有人在HRNet的基础上提出了SE-HRNet，实际上只是将每一阶段的卷积引入了SE-Net模块。\n","date":1657075213,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657075213,"objectID":"5cf129240ac9274c4d6affbb1d2c46a8","permalink":"https://yangleisx.github.io/post/paper-hrnet/","publishdate":"2022-07-06T10:40:13+08:00","relpermalink":"/post/paper-hrnet/","section":"post","summary":"HRNet是CVPR2019提出的一种非常强的Backbone，论文参考arXiv，代码已经开源github（用于分割的代码还没有全部开源）。\n","tags":["Semantics Segmentation"],"title":"HRNet","type":"post"},{"authors":["Lei Yang"],"categories":[],"content":"扫了一些分割方面论文，截止日期2021-12-29\n针对结构的修改 专注于设计新的模块和现有网络结构的扩展。\nCNN Lanyun Zhu在CVPR2021提出的“Learning Statistical Texture for Semantic Segmentation”。基本骨架是普通的CNN提取网络加上[[DeepLab 系列]]中的ASPP。同时引入了两个新的模块TEM和PTFEM，从CNN最底层的特征图中学习纹理特征，TEM进行纹理增强，PTFEM利用计数算子QCO学习金字塔纹理特征。最后上采样得到分类，得到STLNet。\nXing Shen在CVPR2021提出的“DCT-Mask: Discrete Cosine Transform Mask Representation for Instance Segmentation”。使用了基于DCT变换的Mask表示，相比基于像素的表示降低了复杂度和计算量。\nFCN/UNet Chen Guan学长在ITFS2020年发的“Lip image segmentation based on a fuzzy convolutional neural network”。主要是还是在FCN的基础上，在特征融合的部分添加了一个Fuzzy Block进行特征的融合。\nRuigang Niu在ITGRS上发的“Improving Semantic Segmentation in Aerial Imagery via Graph Reasoning and Disentangled Learning”在特征backbone的基础上，不同大小的特征图使用图推断+上采样，进行concate，用双流的结构分别进行前景先验估计和边缘对齐，然后合并进行分割预测。\nXia Li在CVPR2020上发的“Spatial Pyramid Based Graph Reasoning for Semantic Segmentation”也是利用了U-Net和图卷积的方式\nYunpeng Chen在CVPR2019上发的“Graph-Based Global Reasoning Networks”设计了一个图推断模块，将特征映射到图空间，使用GCN进行推断然后再映射回到原本的坐标空间中，可以插在FCN模型之后的位置，提升模型性能。\nZilong Zhong在CVPR2020上发的“Squeeze-and-Attention Networks for Semantic Segmentation”对SE-Net中的SE模块进行改进，使得在分割任务中的效果更好。\nYanwei Li在CVPR2020上发的“Learning Dynamic Routing for Semantic Segmentation”使用了动态路径选择的方法，\nTransformer Sixiao Zheng在CVPR2021发的“Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers”提出了SETR，将transformer应用到了图像分割中。首先进行划分patch和linear projection，然后通过24个transformer，最后通过reshape和卷积上采样得到像素级分类结果。\n针对目标场景 3D点云数据 Na Zhao在CVPR2021发的“Few-shot 3D Point Cloud Semantic Segmentation”提出一种Few-Shot的学习方法，结合Attention Learner和Metric Learner得到特征，然后使用图构造进行预测。\n多光谱数据 RGB-T数据，包含可见光和热成像数据，属于多模态学习。\nQiang Zhang在CVPR2021发的“ABMDRNet: Adaptive-weighted Bi-directional Modality Difference Reduction Network for RGB-T Semantic Segmentation”使用双流的方式，首先使用MDRF（Modality Difference Reduction and Fusion）进行Image2Image的转换，减少两个模态数据的差异，然后使用CWF，MSC，MCC三个模块进行合并再解码得到分类结果。MSC（Spatial Context）中使用了ASPP和Non-Local的结构。MCC利用了Channel Context。\n人体语义解析 Tianfei Zhou在CVPR2021发的：“Differentiable Multi-Granularity Human Representation Learning for Instance-Aware Human Semantic Parsing”进行多粒度的人体结构解析。使用自下而上的方式，实现Instance级别的结果。\n视频解析 由于我们的目标是视频数据，传统的做法是使用降采样然后对每一帧进行单独的处理，但是直觉上来看，时序上下文信息应该对于分割有一定的帮助，例如相邻帧的变化比较小的时候，上一帧中嘴唇的位置，在下一帧也大概率是嘴唇。\nPing Hu在CVPR2020发的“Temporally Distributed Networks for Fast Video Semantic Segmentation”提出了一种视频语义分割的快速网络，对每一帧使用轻量级网络提取特征然后在时序上聚合得到完整的特征进行语义分割。\nSi Liu在CVPR2017发的“Surveillance Video Parsing with Single Frame Supervision”也使用了多帧的光流等信息进行分割性能的增强。\nHaochen Wang在CVPR2021发的“SwiftNet: Real-time Video Object Segmentation”使用多帧信息解决VOS（Video Object Segmentation）问题。但是实际上VOS问题的定义是，对于一个视频流，在最开始的一帧分割得到目标，然后自动在后面的t帧中将相同目标检测并分割出来。\n针对训练方法 持续学习 模型训练好之后，增加了新的分类类别，称为持续学习。分割领域中称为CSS（Continual Semantics Segmentation）。\nArthur等人在CVPR2021发的“PLOP: Learning without Forgetting for Continual Semantic Segmentation”设计了一种新的蒸馏机制POD，保留了空间信息，在CSS过程中能够不忘记旧数据中的特征。\n元学习/无监督域适应 无监督域适应（Unsupervised Domain Adaption）\nXiaoqing Guo在CVPR2021发的“MetaCorrection: Domain-aware Meta Loss Correction for Unsupervised Domain Adaptation in Semantic Segmentation”设计了一种元学习框架。\nFew-Shot 弱监督半监督 Xun Xu等在CVPR2020上提出的“Weakly Supervised Semantic Point Cloud Segmentation: Towards 10x Fewer Labels”可以只使用几个像素的大致标注信息进行训练。\n损失函数优化 Xiaofeng Liu在CVPR2020上提出的“Severity-Aware Semantic Segmentation with Reinforced Wasserstein Training”为分割过程中的不同类型的误分类指定不同的代价。这个代价矩阵是通过强化学习的方式和Wasserstein距离的定义来导出的。\n","date":1657074755,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657074755,"objectID":"7d07b2317f3793e5742896ee4fa543c3","permalink":"https://yangleisx.github.io/post/survey-segment-2021/","publishdate":"2022-07-06T10:32:35+08:00","relpermalink":"/post/survey-segment-2021/","section":"post","summary":"扫了一些分割方面论文，截止日期2021-12-29\n","tags":["Semantics Segmentation"],"title":"2021分割新进展","type":"post"},{"authors":["Lei Yang"],"categories":[],"content":"Anaconda中的cudatoolkit是什么。\n在使用anaconda安装配置pytorch环境的时候，常常需要安装cudatoolkit。这里的cudatoolkit与CUDA Toolkit\nNVIDIA官网上下载安装的CUDA环境，包含了nvidia驱动程序、CUDA开发环境（包括NVCC编译器、调试器、相关的头文件等）、CUDA文档、CUDA示例等一系列资源。\n而Anaconda提供的cudatoolkit是一系列编译好的动态库文件。将pytorch常用的各种cuda函数编译好提供出来，只要显卡驱动版本适合，就可以直接调用其中的API。\n通常情况下，只需要安装cudatoolkit就可以正常使用。但是如果需要编写Pytorch的CUDA/C++ Extension，即手动通过CUDA实现新的功能（Layer/Operator）等，就必须保证机器上安装了官方的CUDA环境，从而实现动态的编译。\n","date":1657074628,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657074628,"objectID":"7dd9d0ab9fc8c213a42c77c5205554b3","permalink":"https://yangleisx.github.io/post/cudatoolkit/","publishdate":"2022-07-06T10:30:28+08:00","relpermalink":"/post/cudatoolkit/","section":"post","summary":"Anaconda中的cudatoolkit是什么。\n","tags":[],"title":"Anaconda中的cudatoolkit是什么","type":"post"},{"authors":[],"categories":[],"content":"对于离散信号，当所有信源符号出现的概率相等的时候取到最大的熵。\n二元离散信号 对于二元离散信号的证明如下。\n已知二元离散信号，概率为$(p,1-p)$。 信源熵为 $$ H(p) = -p\\log p - (1-p)\\log(1-p) $$\n求导可以得到 $$\\begin{align} \\frac{\\partial H(p)}{\\partial p} =\u0026amp; -(1+\\log p) + (1+\\log(1-p)) \\\\ =\u0026amp; \\log \\frac{(1-p)}{p} \u0026gt; 0 \\end{align}$$ 可以得到在$p \u0026lt; \\frac{1}{2}$时梯度为正，在$p \u0026gt; \\frac{1}{2}$时梯度为负。\n多元离散信号 对于多元离散信号的证明如下。 首先证明信息熵是一个凸函数，然后求解信息熵的最大值。\n严格凸函数 要想证明信息熵是凸函数，相当于证明$H(\\alpha P_1 + (1-\\alpha)P_2) \\geq \\alpha H(P_1) + (1-\\alpha)H(P_2)$\n构建 $$\\begin{align} \u0026amp; \\alpha H(P_1) + (1-\\alpha)H(P_2) - H(\\alpha P_1 + (1-\\alpha)P_2) \\\\ = \u0026amp; - \\alpha\\sum\\limits_{i}p_1(x_i)\\log p_1(x_i) - (1-\\alpha)\\sum\\limits_{i}p_2(x_i)\\log p_2(x_i) \\\\ \u0026amp; + \\sum\\limits_{i}(\\alpha p_1(x_i)+(1-\\alpha)p_2(x_i))\\log (\\alpha p_1(x_i)+(1-\\alpha)p_2(x_i))\\\\ = \u0026amp; \\alpha\\sum\\limits_{i}p_1(x_i)\\log\\frac{\\alpha p_1(x_i)+(1-\\alpha)p_2(x_i)}{p_1(x_i)} \\\\ \u0026amp; + (1-\\alpha)\\sum\\limits_{i}p_2(x_i)\\log\\frac{\\alpha p_1(x_i)+(1-\\alpha)p_2(x_i)}{p_2(x_i)} \\\\ \\leq \u0026amp; \\alpha\\log \\sum\\limits_{i}p_1(x_i)\\frac{\\alpha p_1(x_i)+(1-\\alpha)p_2(x_i)}{p_1(x_i)} \\\\ \u0026amp; + (1-\\alpha)\\log \\sum\\limits_{i}p_2(x_i)\\frac{\\alpha p_1(x_i)+(1-\\alpha)p_2(x_i)}{p_2(x_i)} \\\\ = \u0026amp; 0 \\end{align}$$ 所以 $\\alpha H(P_1) + (1-\\alpha)H(P_2) \\leq H(\\alpha P_1 + (1-\\alpha)P_2)$ 得证。\n考虑到Jensen不等式成立的条件为 $\\forall i, \\frac{\\alpha p_1(x_i)+(1-\\alpha)p_2(x_i)}{p_1(x_i)} = k$ 。 满足等号成立条件的有两种情况，即 $\\alpha=1$ 或者 $p_1(X)=p_2(X)$ ，这与我们 $p_1(X) \\neq p_2(X),0\u0026lt;\\alpha\u0026lt;1$ 的假设不符合。\n最大熵 已知多元离散信号，概率为 $p(x_i)$ ，并且满足约束条件 $\\sum\\limits_{i} p(x_i) = 1$ 。 使用Lagrange Multiplier方法，构建 $$ F = \\sum\\limits_{i}-p(x_i)\\log p(x_i) - \\lambda\\left( \\sum\\limits_{i} p(x_i) - 1\\right) $$\n求导可以得到 $$\\begin{align} \\frac{\\partial F}{\\partial p(x_i)} =\u0026amp; -\\log p(x_i) - 1 - \\lambda = 0 \\\\ p(x_i) =\u0026amp; e^{ -\\lambda - 1} \\end{align}$$ 已知$\\sum\\limits_{i} p(x_i) = 1$和$p(x_i) = e^{ -\\lambda - 1}$可的$p(x_i) = \\frac{1}{N}$。\n","date":1657074363,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657074363,"objectID":"d66cce8ebac113b4c61c31da77dc9770","permalink":"https://yangleisx.github.io/post/max-entropy/","publishdate":"2022-07-06T10:26:03+08:00","relpermalink":"/post/max-entropy/","section":"post","summary":"对于离散信号，当所有信源符号出现的概率相等的时候取到最大的熵。\n","tags":[],"title":"离散信号最大熵定理","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文题目： Improving Semantic Segmentation in Aerial Imagery via Graph Reasoning and Disentangled Learning\n作者：Ruigang Niu, Xian Sun, Yu Tian, Wenhui Diao, Yingchao Feng, Kun Fu\n会议/时间：TGRS2021\n链接: ResearchGate\n论文目标 在航空影像分割问题中，由于存在前景背景不平衡，类内数据差异较大以及密集/小目标的存在，性能受到限制。文章通过引入Graph Reasoning 图推理和Disentangled Representation Learning 解耦表示学习的思路，提升在航空影像上分割的效果。\n为了提取丰富的上下文信息，之前的工作使用了FCN、ASPP等方式，也可以使用基于Attention 注意力机制的方式。为了进一步增加上下文信息，可以使用Graph Reasoning 图推理的方式。\n对于密集目标、小目标等容易出现特征含糊不清的问题，引入了解耦的多分支的结构。使用多任务学习的方式来解决分割和边缘检测的问题。\n相关工作 使用GR的算法中，GloRe使用1D卷积在全连接图上实现图卷积，SPyGR直接在像素空间上做图卷积，忽略了像素空间和语义空间之间的语义差异。CDGC引入了从粗检测到精细化的方式（有点类似OCRNet？）DisenGCN将GCN和Disentangled Learning两者相结合。\n本文方法 整体结构图下。首先使用FPN得到层次特征，使用GR模块处理特征。将特征送入双分支解耦学习模块，分别进行前景估计和边缘对齐，最后将所有的特征融合到一起进行预测。\n这里的图卷积模块，吸收了HBP 层次双线性池化的思想，将相邻的三个不同分辨率的特征图进行缩放之后计算Hadamard积然后映射到若干个点，然后进行图卷积，最后使用卷积得到的结果对原本的特征相乘在映射回到原本的像素空间中。\n使用HBP 层次双线性池化进行映射的时候有如下公式进行池化。 $$G_{proj}(F^2, \\mathcal{U}(F^1), \\mathcal{U}(F^3)) = \\frac{1}{H_2W_2}\\sum\\limits_{i=1}^{H_2W_2} f^2_i\\circ f’^1_i\\circ f’^3_i$$\n最后按通道分成g组，即 $C = g\\times d$ ，可以认为分成了g个节点，每一个节点的特征维度为d（可以认为是d个像素空间的点构成了一个图空间的点）。在进行图卷积的时候，令 $H = \\sigma(A_g X W_g)$ ，其中 $A_g\\in R^{N\\times N},X\\in R^{N \\times C},W_g\\in R^{C\\times F}$ ，这里的$N$就是上面的$g$，$C$就是上面的$d$。\n在邻接矩阵的设计上，使用了四种不同的策略，分别是固定为一跳邻居、单位阵初始化的可学习参数、正态分布初始化的可学习参数、均匀分布初始化的可学习参数。\n最后在反向映射的过程中，采用了类似SE-Net的方式，将图卷积得到的结果作为通道注意力与原始数据相乘。\n在前景估计分支，作者使用了贝叶斯理论, 实际结构是学习得到一个分割图然后concat起来。使用了 $B = \\delta(M_{fg} \\cdot I\\parallel (1-M_{fg}) \\cdot I \\parallel I)$ 的拼接方式。\n在边界对齐模块，作者号称使用了类似Optical Flow 光流的思想，学习得到一个类似光流的边界检测图然后与原本的特征相结合。\n在最后损失函数设计上，对于最后的分割使用Cross Emtropy 交叉熵，前景使用BCE_Loss和Dice Loss，添加了类似PSPNet中的辅助Loss。\n结果分析 在iSAID数据集和Vaihingen、Cityscapes数据集上测试了性能。 基本模型结构使用预训练的ResNet-50/101。\n简单看一下Ablation Study的效果。\n总结 使用了图推理的方式提取上下文信息。这一部分的论文还蛮多的，这里用了一种分组的方式来进行处理。比直接使用像素点的节约时间和空间，用通道注意力的方式进行反向映射的方式也成本比较低。\n使用了多分支的模型，分别学习分割图和边缘检测。利用边缘检测增强分割效果的想法蛮常见的。例如【论文】Boundary-aware Graph Reasoning for Semantic Segmentation或者【论文】Real-time Scene Text Detection with Differentiable Binarization|。\n","date":1657073863,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657073863,"objectID":"00ab540ea76a9b07f28b66c5eebb6813","permalink":"https://yangleisx.github.io/post/paper-pgr/","publishdate":"2022-07-06T10:17:43+08:00","relpermalink":"/post/paper-pgr/","section":"post","summary":"论文题目： Improving Semantic Segmentation in Aerial Imagery via Graph Reasoning and Disentangled Learning\n作者：Ruigang Niu, Xian Sun, Yu Tian, Wenhui Diao, Yingchao Feng, Kun Fu\n会议/时间：TGRS2021\n链接: ResearchGate\n","tags":["Semantic Segmentation","Graph Reasoning","Disentangled Learning"],"title":"【论文】Improving Semantic Segmentation in Aerial Imagery via Graph Reasoning and Disentangled Learning","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文题目：Tensor Low-Rank Reconstruction for Semantic Segmentation\n作者：Wanli Chen, Xinge Zhu, Ruoqi Sun, Junjun He, Ruiyu Li, Xiaoyong Shen, Bei Yu\n会议/时间：ECCV 2020\n链接: springer\n本文方法 整体结构如下。\n低秩分解可以形式化为 $$A = \\sum\\limits_{i=1}^{r} \\lambda_i v_{ci}\\otimes v_{hi}\\otimes v_{wi}$$\n特征分解模块的定义如下。\n特征重构模块的定义如下。\n论文里面给了矩阵分解和一些传统方法之间的差异。\n","date":1657073530,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657073530,"objectID":"e4bed64e34740be8db9ccebb5126f9d0","permalink":"https://yangleisx.github.io/post/paper-low-rank-sep/","publishdate":"2022-07-06T10:12:10+08:00","relpermalink":"/post/paper-low-rank-sep/","section":"post","summary":"论文题目：Tensor Low-Rank Reconstruction for Semantic Segmentation\n作者：Wanli Chen, Xinge Zhu, Ruoqi Sun, Junjun He, Ruiyu Li, Xiaoyong Shen, Bei Yu\n会议/时间：ECCV 2020\n链接: springer\n","tags":[],"title":"【论文】Tensor Low-Rank Reconstruction for Semantic Segmentation","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文题目：Spatial Pyramid Based Graph Reasoning for Semantic Segmentation\n作者：Xia Li,Yibo Yang, Qijie Zhao, Tiancheng Shen, Zhouchen Lin, Hong Liu\n会议/时间：CVPR2020\n链接: arXiv\n论文目标 通过在基于GCN/UNet的结构中添加Graph Reasoning 图推理来引入长距离的上下文信息依赖。使用Non-Local Block等Attention 注意力机制的解决方案计算复杂度比较高。使用图卷积网络的解决方案通常需要首先将网格状的图像数据转换/映射到图网络数据，这个映射过程的成本比较高，而且可学习的映射可能会损失数据中在空间上的关系。\n通常的图卷积网络定义在非欧式空间中，不能直接添加到现有的CNN结构中，因此论文作者设计了一个数据有关的相似度矩阵作为图卷积中的Laplacian矩阵进行图卷积的计算。\n本文方法 整体结构如下，在FCN特征融合的部分添加GR模块，进行长距离依赖的学习。 $$\\begin{align} Y^{(s+1)} \u0026amp;= GR(X^{(s+1)}) + \\Pi_{up}(Y^{(s)}) \\\\ Y^{(0)} \u0026amp;= GR(X^{(0)}) \\\\ X^{(s)} \u0026amp;= \\Pi_{down}(X^{(s+1)}) \\end{align}$$ 考虑到 $H^{l+1} = \\sigma(\\tilde L H^lW^l)$ 的图卷积网络通用格式，其中 $\\tilde L = I - \\tilde D^{-\\frac{1}{2}} \\tilde A \\tilde D^{-\\frac{1}{2}}$,$\\tilde A = A + I$ ，有 $\\tilde D_{ii} = \\sum_j \\tilde A_{ij}$ 。如果不使用欧式空间到图网络空间的映射，直接在特征图上进行图卷积。需要对模型做相应的修改。\n上式中的 $\\tilde A$ 表示正规化之后的邻接矩阵，或者称为相似度矩阵，在这个论文中使用 $\\tilde A_{ij} = \\phi(X)_i \\tilde\\Lambda(X) \\phi(X)_j^T$ 计算，即使用位置无关但是数据有关的点乘注意力实现。而不是使用训练得到的固定的邻接矩阵。这里的 $\\tilde \\Lambda$ 的计算方式采用类似通道注意力的方式实现，即先进行GAP然后卷积，最后得到对角矩阵。\n使用 $\\tilde D$ 提供了正则化，不需要再进行Softmax操作。\n在之前的图推理方法中，将像素数据映射到Interspace中，得到图结构的节点数量远少于原本的像素数量，本文中直接实现的在像素域上的计算方法计算量比较大，因此引入了简化方法。即在计算 $\\tilde D$ 的时候并不是直接计算 $\\tilde A \\in R^{HW \\times HW}$ ，而是引入一个全1的向量，得到 $\\tilde D = diag(\\tilde A \\cdot \\vec 1) = diag(\\phi(\\tilde\\Lambda(\\phi^T \\cdot \\vec 1)))$ ，将所有的矩阵计算变为和一个向量的运算。计算左乘 $\\tilde L X$ 的时候使用 $\\tilde LX = X - \\tilde D^{-\\frac{1}{2}} \\phi\\tilde\\Lambda\\phi^T\\tilde D^{-\\frac{1}{2}}X = X - P(\\tilde\\Lambda(P^TX))$ ，其中 $P = \\tilde D^{-\\frac{1}{2}}\\phi$ 。\n结果分析 首先进行Ablation Study。对于GR模块提出的Laplacian各个部分进行对比。可以看到效果提升。\n在Cityscapes、Pascal VOC和MS COCO数据集上做了实验。\n","date":1657072905,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657072905,"objectID":"2ff1dda870eaf8034bcc6dea8f8922d8","permalink":"https://yangleisx.github.io/post/paper-spygr/","publishdate":"2022-07-06T10:01:45+08:00","relpermalink":"/post/paper-spygr/","section":"post","summary":"论文题目：Spatial Pyramid Based Graph Reasoning for Semantic Segmentation\n作者：Xia Li,Yibo Yang, Qijie Zhao, Tiancheng Shen, Zhouchen Lin, Hong Liu\n会议/时间：CVPR2020\n链接: arXiv\n","tags":["Semantic Segmentation"],"title":"【论文】Spatial Pyramid Based Graph Reasoning for Semantic Segmentation","type":"post"},{"authors":["Lei Yang"],"categories":[],"content":"ECCV2020提出的一种上下文信息融合方式。\n主要是使用与当前位置类别相同的区域的特征来增强当前位置的表示。与DeepLab中的ASPP相比效果更好。\n在论文中指出这样的方法和使用Transformer 模块的结构相似，都使用了Self-Attention 自注意力。\n图中Soft Object Regions是利用分割Loss监督的K通道粗分割结果，Pixel Representation是Backbone得到的C通道特征，使用矩阵相乘直接得到$B\\times C \\times K$的关系矩阵，使用特征作为Q，关系矩阵作为K和V，通过$softmax(\\frac{Q^TK}{\\sqrt{d_k}})V$计算得到增强后的特征，与原本的特征相连接用于分割。\n这篇论文和HRNet是同一个团队做的，因此HRNet+OCR已经称为一种非常强分割Backbone。代码放到了github。\n在文章中，作者提出了一种改进Segmentation Transformer，同时被NVIDIA的团队改进，提出了《HIERARCHICAL MULTI-SCALE ATTENTION FOR SEMANTIC SEGMENTATION》。\n当SegFix出现之后，也经常使用HRNet+OCR+SegFix作为比赛中常用的分割Backbone。\n","date":1657072719,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657072719,"objectID":"6afaf6d7eeeacea3a3f0754d56c4ca5c","permalink":"https://yangleisx.github.io/post/paper-ocrnet/","publishdate":"2022-07-06T09:58:39+08:00","relpermalink":"/post/paper-ocrnet/","section":"post","summary":"ECCV2020提出的一种上下文信息融合方式。\n主要是使用与当前位置类别相同的区域的特征来增强当前位置的表示。与DeepLab中的ASPP相比效果更好。\n","tags":["Semantics Segmentation"],"title":"OCRNet","type":"post"},{"authors":["Lei Yang"],"categories":[],"content":"一种在分割任务中常用的损失函数。\n公式如下， $$\\begin{aligned} L_{Dice} \u0026amp;= 1 - \\frac{2 \\times |A \\cap B|}{|A| + |B|} \\quad\u0026amp; Standard \\\\ L_{Dice} \u0026amp;= 1 - \\frac{2 \\times |A \\cap B| + 1}{|A| + |B| + 1} \\quad\u0026amp; Laplace\\ Smooothing \\\\ L_{Dice} \u0026amp;= 1 - \\frac{2 \\times |A \\cap B|}{|A|^2 + |B|^2} \\quad\u0026amp; Square \\\\ \\end{aligned}$$ 如果使用集合的角度来看，Dice Loss可以写作 $\\frac{2TP}{2TP+FP+FN}$，也就是类似F1-Value的表示。\nDice Loss的好处是可以解决正负样本类别不平衡的现象。表现在图像分割任务中，通常前景占据的面积比较少，背景占据的面积比较大。Dice Loss在训练前期会对正样本比较敏感（较大的梯度），因而倾向于挖掘前景区域。而CrossEntropy比较公平的对待前景和背景，因此容易被负样本淹没。\n一种pytorch的实现代码如下，其中pred和gt是基于分割的模型输出，即输出与原图像等比例缩放的取值0-1的分割图，因此可以直接使用乘法和求和函数计算。\nclass DiceLoss(nn.Module): def __init__(self, eps=1e-6): super(DiceLoss, self).__init__() self.eps = eps def forward(self, pred, gt): intersection = (pred * gt).sum() union = pred.sum() + gt.sum() + self.eps loss = 1 - 2.0 * intersection / union return loss ","date":1657072509,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657072509,"objectID":"9f24b126d0371662a1d767543ede0b16","permalink":"https://yangleisx.github.io/post/diceloss/","publishdate":"2022-07-06T09:55:09+08:00","relpermalink":"/post/diceloss/","section":"post","summary":"一种在分割任务中常用的损失函数。\n","tags":[],"title":"Dice Loss损失函数","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文题目：A Hierarchical Fused Fuzzy Deep Neural Network for Data Classification\n作者：Yue Deng, Zhiquan Ren, Youyong Kong, Feng Bao, and Qionghai Dai\n会议/时间：IEEE TRANSACTIONS ON FUZZY SYSTEMS, 2017\n链接: ieeexplore\n论文目标 在深度神经网络中引入模糊逻辑从而应对数据中的噪声和不确定度。\n之前的工作大多是使用模糊逻辑处理模型的输入（Fuzzier）或者输出（Defuzzier），论文中将模糊逻辑和神经网络并行处理得到的特征融合在一起。\n本文方法 整体结构如图。模糊逻辑部分使用高斯隶属度，神经网络部分使用MLP，最后使用线性组合的方式得到融合后的模型，再通过全链接得到任务所需要的输出结果。\n在训练的时候，考虑到模型对初始化比较敏感，使用了$w \\sim U[-\\frac{1}{\\sqrt{n^{l-1}}}, \\frac{1}{\\sqrt{n^{l-1}}}]$初始化神经网络部分的参数，使用[[K-means 算法]]得到的聚类结果作为fuzzy部分的初始化。\nWe follow the method in [16] to initialize the fuzzy member-ship nodes according to k-means results on the input data, where k is suggested the same as the class number to be classified. [16] N.KasabovandQ.Song,“Denfis:Dynamic evolving neural-fuzzy inference system and its application for time-series prediction,” IEEE Trans. Fuzzy Syst., vol. 10, no. 2, pp. 144–154, Apr. 2002.\n结果分析 在三个任务上进行了实验：1）data classification tasks of image categorization, 2）brain magnetic reso- nance imaging (MRI) segmentation and 3）high-frequency financial tick prediction。取得了不错的效果。\n","date":1657072255,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657072255,"objectID":"3bb8a2d0616dda86f9ce03114d852593","permalink":"https://yangleisx.github.io/post/paper-fdnn/","publishdate":"2022-07-06T09:50:55+08:00","relpermalink":"/post/paper-fdnn/","section":"post","summary":"论文题目：A Hierarchical Fused Fuzzy Deep Neural Network for Data Classification\n作者：Yue Deng, Zhiquan Ren, Youyong Kong, Feng Bao, and Qionghai Dai\n会议/时间：IEEE TRANSACTIONS ON FUZZY SYSTEMS, 2017\n链接: ieeexplore\n","tags":["Fuzzy System"],"title":"【论文】A Hierarchical Fused Fuzzy Deep Neural Network for Data Classification","type":"post"},{"authors":["Fangqi Li","Lei Yang","Shilin Wang","Alan Wee-Chung Liew"],"categories":null,"content":" This paper presents MTLSign, an MTL-based DNN watermarking scheme. We examine the basic security requirements for the DNN watermark, especially the unambiguity, and propose to embed the watermark as an additional task.\nThe proposed scheme explicitly meets security requirements by corresponding regularizers. With a decentralized consensus protocol, MTLSign is secure against adaptive attacks. It is true that like any other white-box DNN watermarking scheme, MTLSign remains vulnerable to functionality equivalence attacks such as the neuron permutation. This is one of the aspects that require further effort to increase the applicability of DNN watermarks.\n","date":1646006400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646006400,"objectID":"4ef88e8dc053666bc23b5353aadd54ff","permalink":"https://yangleisx.github.io/publication/aaaiw-mtl-watermark/","publishdate":"2024-01-20T00:00:00Z","relpermalink":"/publication/aaaiw-mtl-watermark/","section":"publication","summary":"MTLSign, an MTL-based DNN watermarking scheme","tags":null,"title":"Leveraging Multi-task Learning for Unambiguous and Flexible Deep Neural Network Watermarking","type":"publication"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文题目：【论文】Towards Deep Learning Models Resistant to Adversarial Attacks\n作者：Aleksander Madry，Aleksandar Makelov，Ludwig Schmidt，Dimitris Tsipras，Adrian Vladu\n会议/时间：ICLR2018\n链接: arXiv\n论文目标 很多模型对 Adversarial Examples 对抗样本 比较敏感，特别是计算机视觉任务中，输入图片添加微小扰动就可能使模型输出错误的结果。文章中通过对抗训练的方式得到一个对对抗样本不敏感的模型，从而使得模型具有较高的鲁棒性。\n相关工作 现有的对抗样本算法，主要专注解决两个问题，一个是如何用更小的扰动对结果造成更大的影响，另一个是如何训练一个鲁棒性较强的模型，或者是对抗样本较难获得的模型。\n对抗样本的生成方面，主要是 FGSM 快速梯度下降法 算法及其各种变种，以及 PGD 算法。\n在防御端，主要是采用 Adversarial Training 对抗训练 的思路，利用FGSM生成的对抗样本参与训练。\n本文方法 考虑到对抗样本攻击通常在输入数据上添加一个扰动，因此针对对抗样本提高模型鲁棒性的方式可以表示为一个 Min-Max优化问题 ，或者称为 对抗优化 问题，表示如下。其中$L(\\theta, x, y)$为经验损失。\n$$ \\min_{\\theta} \\rho(\\theta), where\\quad \\rho(\\theta) = \\mathbb{E}_{(x,y)\\sim \\mathcal{D}}\\left[\\max_{\\delta \\in S} L(\\theta,x+\\delta,y) \\right] $$\n解决这样的对抗优化问题需要解决非凸的优化问题，包括内部的最大化问题和外部的最小化问题。\n文中通过实验发现，在选定数据的 $l_{\\infty}-Ball$内部（参考 无穷范数 ）存在非常多的局部最优点，并且具有很小的损失值。在实验中通过使用 PGD 算法 生成对抗数据并测试可以得到，PGD可以作为一种通用的攻击方式，在选定数据附近得到一个局部最优。因此能对抗PGD的算法也能比较好的对抗一阶攻击（First-Order Adversarial，只利用一阶梯度值生成对抗样本的攻击）。因此使用PGD生成的对抗样本作为内部最大化问题的解。\n对于外部的最小化问题，可以直接使用SGD优化器进行优化，即计算 $\\nabla_{\\theta}\\ \\rho(\\theta)$。假设Danskin’s定理在当前问题上成立，可推出可以使用SGD优化器优化外部最小化问题求解，实验结果也证明这一点。\n上图说明，对于使用对抗训练的模型，由于模型对于数据的微小扰动不敏感，模型就需要学习到更加复杂的决策边界，这也需要模型具有更大的 模型容量|容量 。因此需要换用容量更大更复杂的模型。\n结果分析 使用不同的对抗样本进行对抗训练并测试的结果如下，一方面增加模型容量能提升对抗攻击下的模型性能，使得最终学到的损失函数鞍点更小，另一方面使用PGD 算法作为对抗目标的效果比使用FGSM 快速梯度下降法更好。 总结 通过对抗样本参与训练可以增强模型的鲁棒性。\n","date":1638689213,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1638689213,"objectID":"517f21288d7487660bd26e864810494e","permalink":"https://yangleisx.github.io/post/paper-adver-attack/","publishdate":"2021-12-05T15:26:53+08:00","relpermalink":"/post/paper-adver-attack/","section":"post","summary":"论文题目：【论文】Towards Deep Learning Models Resistant to Adversarial Attacks\n作者：Aleksander Madry，Aleksandar Makelov，Ludwig Schmidt，Dimitris Tsipras，Adrian Vladu\n会议/时间：ICLR2018\n链接: arXiv\n","tags":["Watermarking","Adversarial Training"],"title":"【论文】Towards Deep Learning Models Resistant to Adversarial Attacks","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文题目：Learning to Segment Every Thing\n作者：Ronghang Hu，Piotr Dollar， Kaiming He，Trevor Darrell， Ross Girshick\n会议/时间：CVPR2018\n链接: arXiv\n论文目标 现有的Instance Segmentation 实例分割任务受到了数据集的限制，只能解决很少的几类目标的检测。由于像素级的分割标注成本非常高，因此文章提出了一种部分监督的训练方式，使用给定边界框的目标检测数据集训练实例分割模型。因此将实例分割扩展到几千类不同的目标，即题目中的“Segment Everything”。\n这里的部分监督表示，在训练过程中，一小部分训练数据给定了分割Mask作为强监督，其他的数据只给定了目标的Bounding Box作为弱监督。\n相关工作 Instance Segmentation 实例分割任务近年来受到关注，RCNN 系列#Mask R-CNN在实例分割任务中取得了很好的效果。缺点是需要大量的强监督，即“Fully Supervised Learning”。\n目前有一些通过预测得到模型参数的方式，例如Model Regression Network等方式通过模型预测的方式得到分类模型权重从而实现Zero-Shot Learning，LSDA模型通过一个图像分类模型的权重预测得到一个目标检测模型的权重。本论文中就使用一个预测模型得到分割头部的权重。\n目前也有一些弱监督学习实现Image Segmentation 图像分割的方法，例如使用边框标注、图像分类信息、目标大小等信息进行监督，但是大多只能解决Semantic Segmentation 语义分割任务。\n视觉嵌入类似Word Embedding 词嵌入的方式，将图像映射到空间中，其中语义信息相类似或者图像相似度比较高的被映射到相近的位置。在本文中认为Mask R-CNN的目标检测头部的参数可以认为是一种视觉嵌入的形式，蕴含了目标类别和位置的信息。\n本文方法 模型建立在RCNN 系列#Mask R-CNN的基础上，考虑到Mask R-CNN在边界框回归的目标检测模型（即RCNN 系列#Faster R-CNN）上添加了一个分割头部，因此可以直接应用在本文中。\n模型中设计了一个转移函数$\\mathcal{T}(\\cdot)$实现了从检测模型参数到分割模型参数的转移，即$\\omega_{seg}^c = \\mathcal{T}(\\omega_{det}^c; \\theta)$。其中$c$表示对于指定的类型。这里的函数$\\mathcal{T}$可以使用一个简单的全连接网络实现。\n在训练时，对于给定了Bounding Box和分割Mask的类别数据，同时使用Mask Loss和Box Loss监督。对于没有分割Mask监督的数据只使用Box Loss监督。\n具体训练包含两种不同的策略，一种是分级处理的训练方式，先训练一个目标检测模型，再固定Backbone和检测模型的参数，训练转移函数进行分割。另一种是端到端的训练，考虑到通常情况使用端到端的训练可以是模型综合不同的监督信号学习的更好，建议使用端到端的联合训练的方式。\n由于数据中一部分包含Mask监督，另一部分不包含，在训练的时候，对于检测参数$\\omega_{det}$阻断梯度传播，即Mask Loss只参与了$\\mathcal{T}(\\cdot)$的参数更新。从而防止上述数据的不一致性影响到Backbone的训练。\n在Mask R-CNN中，分割头部使用FCN取得了更好的效果，考虑到在DeepMask中，使用MLP进行分割的效果也很好，因此在上述转移函数$\\mathcal{T}(\\cdot)$的基础上添加一个新的类型无关（Class-Agnostic）的MLP分支。\n结果分析 在MS COCO数据集上进行了比较详细的Ablation Study。 在Visual Genome数据集上使用3000种不同类型的数据进行训练，由于没有Mask标注，只能给出直观的结果。 相比之前的结果，模型可以检测到更加抽象的概念，而且可以检测到组成一个目标的各个部分。\n总结 提出了一种部分监督的方式，可以根据部分给定分割图和部分只给定边界框的数据训练实例分割模型。\n","date":1636290031,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1636290031,"objectID":"d80cc124d7dae34268547e67d7da96e8","permalink":"https://yangleisx.github.io/post/paper-seg-every/","publishdate":"2021-11-07T21:00:31+08:00","relpermalink":"/post/paper-seg-every/","section":"post","summary":"论文题目：Learning to Segment Every Thing\n作者：Ronghang Hu，Piotr Dollar， Kaiming He，Trevor Darrell， Ross Girshick\n会议/时间：CVPR2018\n链接: arXiv\n","tags":["Instance Segmentation","Partially Supervised"],"title":"【论文】Learning to Segment Every Thing","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文题目： Embedding Watermarks into Deep Neural Networks\n作者： Yusuke Uchida, Yuki Nagai, Shigeyuki Sakazawa\n会议/时间：ICMR 2017\n链接: arXiv\n论文目标 目前预训练深度神经网络的应用越来越广，需要一种数字水印技术来保护预训练深度神经网络的知识产权，避免被滥用。论文首先定义了水印技术的场景，并提出了一种水印嵌入技术，可以在模型训练、精调或者蒸馏过程中嵌入到目标模型中且不影响模型性能。并且面对攻击者的精调和剪枝等行为时仍能保留在模型中。\n问题定义 模型水印要求 要求 解释 Fidelity 添加水印之后模型的性能没有明显下降 Robustness 模型经过修改后水印仍存在 Capacity 水印技术应该能够嵌入大量信息 Security 水印应该难以被他人读写和修改 Efficiency 嵌入和提取水印的过程应该足够快 模型水印嵌入方法 在训练过程中嵌入（Train From Scratch） 在精调过程中嵌入（Fine-Tuning） 在蒸馏过程中嵌入（Model Distillation） 攻击方法 精调（Fine Tuning） 模型压缩（Model Compression） 本文方法 主要考虑卷积神经网络中卷积层的参数。对于一个$Kernel-Size=S$，输入通道数为$D$，输出通道数（卷积核数量）为$L$的卷积层，不考虑偏置，其参数为$W \\in \\mathbb{R}^{S\\times S\\times D\\times L}$。计算多个卷积核的均值 $ {\\bar W}_{i,j,k}=\\frac{1}{L}\\sum_l W_{i,j,k,l} $，并展平得到$w \\in \\mathbb{R}^M(M = S\\times S\\times D)$作为嵌入的目标。将$T$-bit的信息$b\\in {0,1}^T$嵌入其中。\n在提取时，使用$b_j = s(\\sum_i X_{ji}\\omega_i)$计算嵌入的信息。其中$\\omega$表示卷积核均值，$X \\in \\mathbb{R}^{T \\times M}$表示嵌入密钥，$s(\\cdot)$为阶跃函数。\n在训练时，为了将信息嵌入模型中，在原本的损失函数上添加了一个权重参数正则项$E(\\omega)=E_0(\\omega)+\\lambda E_R(\\omega)$。\n考虑到上述的模型提取方式类似二分类方法，因此添加的权重参数正则项使用BCE损失，使用训练过程中的参数提取结果作为监督。\n$$\\begin{aligned} E_R(\\omega)=\u0026amp; -\\sum\\limits_{j=1}^{T}(b_j \\log(y_j)+(1-b_j)\\log(1-y_j)) \\\\ y_j =\u0026amp; \\sigma(\\sum_i X_{ji}\\omega_i)\\\\ \\sigma(x) =\u0026amp; \\frac{1}{1+\\exp(-x)} \\end{aligned}$$ 关于密钥$X$的设计，考虑到水印的性能，有三种设计形式：$X^{direct}$的每一行为独热码，直接将信息映射到参数中。$X^{diff}$的每一行包含一个1和一个-1，其他的为0，将信息映射到参数的差值中。$X^{random}$的数字采样于标准正态分布。\n结果分析 Ablation Study 关于密钥$W$的设计，实验证明使用$X^{direct}$和$X^{diff}$嵌入都会造成较大的性能下降。 而且可以看到$X^{random}$不仅不造成性能下降，而且对原始的参数分布影响不大。 经过实验发现，当嵌入的信息量超过卷积层参数数量的时候，嵌入损失和性能下降会变得明显。而且采用直接嵌入的方式会难以在性能下降和嵌入损失之间达到均衡。\nRobustness 实验证实这一方法可以应对Fine-Tuning和迁移学习。 面对剪枝操作时，特别是按照权重升序的剪枝方法时仍然能保留水印。 总结 提出了一种，为权重参数添加正则项的水印嵌入方法，其水印提取是通过矩阵映射的方式实现的。具有一定的鲁棒性。\n","date":1634618181,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1634618181,"objectID":"f036caa6627703d4635b69425b969d4e","permalink":"https://yangleisx.github.io/post/paper-uchida/","publishdate":"2021-10-19T12:36:21+08:00","relpermalink":"/post/paper-uchida/","section":"post","summary":"论文题目： Embedding Watermarks into Deep Neural Networks\n作者： Yusuke Uchida, Yuki Nagai, Shigeyuki Sakazawa\n会议/时间：ICMR 2017\n链接: arXiv\n","tags":["Watermarks"],"title":"【论文】Embedding Watermarks into Deep Neural Networks","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文题目：Look More Than Once: An Accurate Detector for Text of Arbitrary Shapes\n作者：Chengquan Zhang， Borong Liang， Zuming Huang， Mengyi En，Junyu Han，Errui Ding， Xinghao Ding\n会议/时间：CVPR2019\n链接: ieeexplore\n论文目标 现有模型受到感受野的限制，很难实现对于长文本和弯曲文本的准确识别。论文中设计实现了一个LOMO网络，首先通过DR获得粗检测结果，再使用IRM迭代优化结果，最后使用SEM得到任意多边形的文本检测结果。\n相关工作 目前的文本检测有三种思路：\n基于Component，检测到文本部分然后通过后处理合并。例如CTPN、SegLink、WordSup等。 基于Detection，类似通用的目标检测。例如TextBoxes、RRD、RRPN、EAST等。 基于Segmentation，类似语义分割。例如TextSnake、PSENet等。 本文方法 整体的模型结构如下。基本的特征提取部分使用ResNet50和FPN实现。最终得到1/4大小的128通道的特征图。 提取到的图像特征首先经过Direct Regressor得到粗检测结果。这里DR的设计与EAST基本相同，包括test/non-text分类结果和四个边界点的偏移值。在训练分类结果时使用了一种改进的Dice-Loss。其中的权重$w$被设置为与文本框的短边长度称反比。 $$L_{cls} = 1 - \\frac{2 * sum(y * \\hat{y} * w)}{sum(y*w) + sum(\\hat{y} * w)}$$\nIRM的结构如下。首先根据DR的结果，从FPN的特征中使用ROI Transform提取特征，并使用卷积和Sigmoid激活得到四个通道的注意力图（分别为四个边角）。通过Reduce-Sum和卷积得到四个边角的偏移量。对DR的结果进行修正。 IRM部分的损失函数为使用Smoothed-L1来监督。 $$L_{irm} = \\frac{1}{K*8}\\sum\\limits_{k=1}^{K}\\sum\\limits_{j=1}^{8}smooth_{L1}(c_k^j - \\hat{c}_k^j)$$\nSEM的结构如下。根据IRM修正之后的结果，进一步得到多边形框的结果。除去上述检测框中的背景部分。首先同样是使用ROI Transform提取特征，然后经过两次上采样之后，再生成预测结果，包括文本区域、文本中心线（收缩后的文本区域）、边界偏置。 要想得到文本检测结果，需要首先在文本中心线上采样N个点，然后根据边界偏置得到文本行的上下边界上的控制点，相连接得到多边形框。\n在训练时，首先使用生成数据对DR部分进行训练，然后才使用真实数据同时训练三个分支。为了防止训练时DR产生的错误结果影响另外两分支的训练，将DR结果中的50%随机替换为GT。在预测的时候DR的结果经过NMS之后再经过多次IRM，最后通过SEM得到结果。\n结果分析 ablation study显示，IRM迭代次数增加可以提升模型性能，但是相应的处理时间增加，因此权衡之后设置为2。在IRM中，添加四个角点的注意力图也可以提升模型性能。\nablation study显示，添加SEM可以显著提升模型性能（7.17%）。对于SEM结果的处理中，采样点数量增加效果提升并逐渐收敛，因此选择为7。\n在长文本数据集ICDAR2017-RCTW上的效果如下。 在弯曲文本数据集ICDAR2015上的效果如下。 在多语言数据集ICDAR2017-MLT上的效果如下。 总结 设计了IRM在粗检测结果上精调。 设计了SEM实现文本框形状的优化，从四边形变换为任意形状。\n","date":1634285966,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1634285966,"objectID":"533156cf8dcb0763a01451b0f5d9fbe8","permalink":"https://yangleisx.github.io/post/paper-lomo/","publishdate":"2021-10-15T16:19:26+08:00","relpermalink":"/post/paper-lomo/","section":"post","summary":"论文题目：Look More Than Once: An Accurate Detector for Text of Arbitrary Shapes\n作者：Chengquan Zhang， Borong Liang， Zuming Huang， Mengyi En，Junyu Han，Errui Ding， Xinghao Ding\n会议/时间：CVPR2019\n链接: ieeexplore\n","tags":["Text Detection"],"title":"【论文】Look More Than Once: An Accurate Detector for Text of Arbitrary Shapes","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文题目：DE-GAN： A Conditional Generative Adversarial Network for Document Enhancement\n作者：Mohamed Ali Souibgui and Yousri Kessentini\n会议/时间：arXiv\n链接: arXiv\n论文目标 文档图像中通常会拥有比较多的退化（Degradation），因此在使用OCR系统处理文档图像的时候效果比较差，论文通过生成对抗网络（GAN）实现了一个文本增强模型，在例如去除模糊、去除污渍、去除水印、二值化等多种文档增强人物上具有较好的效果。\n在通常的文档去除污渍、去除水印等任务中，对于这些水印/退化条件缺少先验知识，特别是污渍将字符完全覆盖的情况。因此很难用传统的方法去除。近年来生成模型在应对缺失数据、多模态任务中取得非常好的结果。因此在论文中，首次在文档增强任务中使用了生成对抗网络来解决二值化和去除水印的任务。而且论文中还提出了密集水印/印章移除任务。\n相关工作 文档图像修复和二值化任务旨在将文本和背景/污渍相区分，传统方法中大多使用设置阈值的方式，包括全局阈值、局部阈值搜索等方式，但是传统方法对于文档状态非常敏感，不够通用。在使用深度神经网络的方法中，整体思路类似图像分割，输出像素级的预测结果，判断当前像素为文本前景还是污渍背景。在论文中所使用的文档增强任务将污渍背景预测为正确的颜色/灰度，而不是设置为0。\n在水印移除任务中，目标是将水印前景与文本背景相分离，多出现在自然图像处理（Natural Image Processing）任务中，此前常见的做法首先使用通用的目标检测算法检测水印/印章的位置然后再移除。\n目前生成对抗网络已经广泛应用于图像到图像的转换任务中，例如语义分割、图像超分辨率等。其中conditional GANs常被应用在一些与文档增强相似的任务中。例如CycleGAN、pix2pix-HD等模型。\n本文方法 首先将文档增强任务定义为图像到图像的转换任务。即给定原始图像生成对应的干净的图像。在最简单的GAN网络中，给定随机抽样$z$，生成图像$y$。在conditional GAN网络中，给定了一个另外的输入参数$x$，生成器依据输入$x$和随机向量$z$生成$y$，即 $G_{\\varphi_G}:{x,z}\\to y$，判别器依据输入$x$判别$y$的真伪，即 $D_{\\varphi_D}: {x, y}\\to P(real)$。\n在最简单的conditional GAN网络中，给定输入为$I^W$，Ground Truth为 $I^{GT}$，模型的对抗损失如下。即最小化判别器分类的损失。 $$\\begin{aligned} L_{GAN}(\\varphi_G, \\varphi_D) \u0026amp;= \\mathbb{E}_{I^W, I^{GT}}\\log[D_{\\varphi_D}(I^W, I^{GT})] \\\\ \u0026amp;+ \\mathbb{E}_{I_W} \\log[1 - D_{\\varphi_D}(I^W, G_{\\varphi_G}(I^W))] \\end{aligned}$$ 在论文中，为了加速模型的训练，添加了额外的辅助损失指导模型的训练。公式如下。（添加了生成器输出结果和Ground Truth之间的交叉熵损失？）\n$$\\begin{aligned} L_{log}(\\varphi_G) \u0026amp;= \\mathbb{E}_{I^{GT}, I^W}[-(I^{GT}\\log(G_{\\varphi_G}(I^W)) \\\\ \u0026amp;+ ((1-I^{GT})\\log(1-G_{\\varphi_G}(I^W))))] \\\\ L_{net}(\\varphi_G, \\varphi_D) \u0026amp;= \\min_{\\varphi_G}\\max_{\\varphi_D}L_{GAN}(\\varphi_G, \\varphi_D) + \\lambda L_{log}(\\varphi_G) \\end{aligned}$$ 模型整体结构如下。 对于生成器，使用了基于U-Net的结构，添加旁路链接可以减少信息的丢失，也可以使模型学习更加高级的特征。 对于判别器，使用简单的多层卷积的结构。在输入层将生成器输出的图像与Ground Truth通过Concatenate相连接。 结果分析 在文档清洁和二值化任务中，损失函数中的$\\lambda$设置为100。与最简单的U-Net相比，模型性能有所提升。说明使用对抗训练可以增强模型的性能。 在DIBCO2013上与现有模型相比达到了SOTA的效果。 在水印和印章移除任务中，损失函数中的$\\lambda$设置为500。与现有模型相比达到了SOTA的效果。 除此之外，还在文档去模糊等任务上和下游的OCR任务上做了测试，均取得了非常好的效果。\n总结 论文中首次提出了使用GAN解决文本增强任务。文中提出的DE-GAN可以认为是pix2pix模型的升级版，通过修改生成器和辅助损失函数提升了模型性能，在很多文档增强任务中都取得了非常好的效果。\n","date":1629613244,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1629613244,"objectID":"36df52698c4568fea11285bcb8e761ed","permalink":"https://yangleisx.github.io/post/paper-de-gan/","publishdate":"2021-08-22T14:20:44+08:00","relpermalink":"/post/paper-de-gan/","section":"post","summary":"论文题目：DE-GAN： A Conditional Generative Adversarial Network for Document Enhancement\n作者：Mohamed Ali Souibgui and Yousri Kessentini\n会议/时间：arXiv\n链接: arXiv\n","tags":["Document Enhancement","Generative Adversarial Network"],"title":"【论文】DE-GAN: A Conditional Generative Adversarial Network for Document Enhancement","type":"post"},{"authors":[],"categories":["论文阅读"],"content":"论文题目：【论文】ABCNet： Real-time Scene Text Spotting with Adaptive Bezier-Curve Network\n作者：Yuliang Liu, Hao Chen, Chunhua Shen, Tong He, Lianwen Jin, Liangwei Wang\n会议/时间：CVPR2020\n链接: arXiv\n论文目标 目前的文本检测和识别任务，包括基于字符或者基于分割的方式，通常需要负责的后处理流程提取得到文本边界框或者是负责的模型结构和处理流程。文章通过提出自适应的贝塞尔曲线网络，实现了端到端的检测和识别任务，同时避免引入计算开支，在保证较高的准确率的时候具有较高的效率。使用贝塞尔曲线作为边界框也可以减少任意形状文本的表示成本。\n相关工作 端到端的文本识别任务通常包括文本检测和文本识别两个阶段。在通用的端到端文本识别任务中，可以使用RoI Pooling等方式将检测阶段提取到的特征应用在识别任务中。类似的思路还包括RoI Masking、RoI Transform、Text Align Sampling、RoI Slide等方式。在面向任意形状文本的端到端识别任务中，关键在于在检测阶段使用什么方式来表示任意形状的文本，例如使用多边形边框或者使用基于单字符的方式。\n本文方法 模型整体结构如下，主要包括贝塞尔曲线表示的文本检测，贝塞尔对齐和轻量级的文本识别网络。 在模型中，将文本边框使用贝塞尔曲线表示。其中文本行的长边使用三阶贝塞尔曲线表示，短边则直接相连。因此每个文本行对象使用8个控制点表示。模型的预测输出阶段输出16个通道的数据，表示这8个控制点到外接正矩形左上角的偏移量（其实是计算 $\\Delta x = b_{ix}-x_{min}, \\Delta y = b_{iy}-y_{min}$）。这样可以将控制点位于图像边界之外的情况也考虑进来。 由于使用贝塞尔曲线表示任意形状的文本位置，在训练时需要将数据集中使用矩形/多边形的标注转换为贝塞尔曲线的形式。这里使用最小二乘的方式优化求解如下方程，可以得到多边形标注对应的贝塞尔曲线控制点坐标。 在提取特征用于识别模型时，文中提出了BezierAlign方式，取代RoI Pooling等其他的方式，可以提取到更加稳定的特征。具体的方式为在平行于贝塞尔曲线的位置进行等距离采样，采用双线性差值的方式得到输出的特征值。公式如下。其中，输出特征值为 $h_{out} \\times w_{out}$。对于输出特征图上的点 $g_i$，坐标为 $(g_{iw}, g_{ih})$，根据 $t$计算上下贝塞尔曲线上的采样点 $tp$和 $bp$，从而得到在原图中的采样点 $op$，再使用双线性差值的方式提取特征。 $$\\begin{aligned} t \u0026amp;= \\frac{g_{iw}}{w_{out}} \\\\ op \u0026amp;= bp \\cdot \\frac{g_{ih}}{h_{out}} + tp\\cdot (1 - \\frac{g_{ih}}{h_{out}}) \\end{aligned}$$ 对齐结果如下。 在训练的时候，使用Ground Truth中的边界框从检测阶段中提取特征用于识别模块的训练，避免检测阶段尚未收敛时产生的影响。\n结果分析 在Total-Text数据集上进行Ablation Study。可以证明文中提出的BezierAlign相比其他的特征提取和对齐方式能提高性能，同时BezierAlign受到采样数量的影响，考虑到性能和速度的折衷，经过实验之后选择了（7，32）。\n在Total-Text和CTW1500上的测试表示模型性能达到了SOTA。 总结 提出了使用Bezier表示任意形状文本边界的方式，结合BezierAlign可以实现性能的提升。同时不引入多余的计算量，具有较高的效率。\n","date":1629361578,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1629361578,"objectID":"8a63aafe5d65dd765d7a532ee74a895f","permalink":"https://yangleisx.github.io/post/paper-abcnet/","publishdate":"2021-08-19T16:26:18+08:00","relpermalink":"/post/paper-abcnet/","section":"post","summary":"论文题目：【论文】ABCNet： Real-time Scene Text Spotting with Adaptive Bezier-Curve Network\n作者：Yuliang Liu, Hao Chen, Chunhua Shen, Tong He, Lianwen Jin, Liangwei Wang\n会议/时间：CVPR2020\n链接: arXiv\n","tags":["Text Detection","Text Recognition","End-to-End Text Spotter"],"title":"【论文】ABCNet: Real-time Scene Text Spotting with Adaptive Bezier-Curve Network","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文题目：Adaptive Boundary Proposal Network for Arbitrary Shape Text Detection\n作者：Shi-Xue Zhang, Xiaobin Zhu, Chun Yang, Hongfa Wang, Xu-Cheng Yin\n会议/时间：ICCV2021\n链接: arXiv\n论文目标 目前的任意形状文本检测工作尽管取得了不错的结果，但是仍然存在两个问题，一个是基于分割的文本检测方案需要复杂的后处理流程，从分割图中提取文本边框坐标，而且很难区分间距比较小的文本目标，。另一个问题是，基于分割的方法很容易受到图像中的噪声等影响，特别是由于文本没有比较完整的轮廓，基于轮廓的检测方式效果比较差。\n在文中提出了一个端到端的文本检测模型，包括BPN(Boundary Proposal Network)和一个迭代的变形模型，可以不经过任何后处理就直接生成任意形状文本的边界位置。\n相关工作 基于回归的方法通常计算生成的anchor或者当前像素到图文边界框的距离，很难识别任意形状的文本或者是宽高比较大的文本。基于联通成分的方法通常找到文本中的单独成分然后连接起来，需要复杂的后处理流程。基于分割的方法通常通过文本边界来进行像素级预测，但是难以区分比较近的多个对象。基于轮廓点的方法学习寻找文本对象的轮廓点，相比分割的方法具有更高的效率和准确度。\n本文方法 模型主要结构如图，包含三个部分，最前方的特征提取（Shared Convolution）、边界建议网络（Boundary Proposal Network，BPN）和自适应边界修正模型（Adaptive Deformation Model）。\n特征提取模块如图，是基于ResNet-50的类似FPN/U-Net的结构。 在BPN中，输出为四个通道：text/non-text classification、distance field和direction field。其中距离图和方向图表示当前点距离边界框上最近的点的距离和方向。通过距离和方向可以从当前点的坐标导出边界框的坐标。相关的监督数据如下图所示。 BPN输出的四个通道数据与特征提取模块输出的特征相拼接。从中选择N个点，每个点特征长度为C，得到了NxC的矩阵输入修正模型。\n在自适应修正模型中，分为编码器和解码器两部分。编码器通过三个并行的模块：RNN（使用Bi-LSTM），GCN（将每个点与相近的四个点相连接），CNN（1x1的卷积）之后再连接起来进入解码器。解码器使用全连接层输出正确结果距离当前结果的偏置值用于更新。\n在训练修正模型时采用迭代的方式。整体的损失函数如下。 $$\\begin{aligned} L =\u0026amp; L_{BP} + \\lambda\\frac{L_{BD}}{1 + e^{(i-eps) / eps}} \\\\ L_{BP} =\u0026amp; L_{cls} + \\alpha \\times L_D + L_V \\\\ L_V =\u0026amp; \\sum w(p)||V_p - \\hat{V}_p||_2 + \\frac{1}{T}\\sum(1 - cos(V_p \\hat{V}_p)) \\\\ w(p) =\u0026amp; \\frac{1}{\\sqrt{GT_p}} \\\\ L_{BD} =\u0026amp; \\frac{1}{T}\\sum L_{(p,p\u0026#39;)} \\\\ L_{(p,p\u0026#39;)} =\u0026amp; \\min\\limits_{j \\in [0,1,2,...N-1]}\\sum\\limits_{i=0}^{N-1} smooth_{L1} (p_i, p\u0026#39;_{(i+j)\\% N}) \\\\ \\end{aligned}$$ 结果分析 实验在Total-Text、CTW-1500、MSRA-TD500、SynthText、ICDAR2017-MLT数据集上训练。\n经过Ablation Study可以证明提出的Adaptive Deformation Model可以提高模型的性能。 经过实验，每个目标的控制点（轮廓点）数量为20、迭代修正次数为3时效果较好，综合距离图、方向图的效果比只使用分类图要好，FPN分辨率选择1/2或者1/4均能达到比较好的效果。\n在常见数据集上实验证明达到了SOTA。 总结 使用图网络和RNN作为修正模型对粗检测结果进行修正。 提出BPN，根据模型提取的特征输出边界框的粗检测结果。 ","date":1629252323,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1629252323,"objectID":"7d0ab323f1ead8a2847ca482d67e12e1","permalink":"https://yangleisx.github.io/post/paper-bpn/","publishdate":"2021-08-18T10:05:23+08:00","relpermalink":"/post/paper-bpn/","section":"post","summary":"论文题目：Adaptive Boundary Proposal Network for Arbitrary Shape Text Detection\n作者：Shi-Xue Zhang, Xiaobin Zhu, Chun Yang, Hongfa Wang, Xu-Cheng Yin\n会议/时间：ICCV2021\n链接: arXiv\n","tags":["Text Detection"],"title":"【论文】Adaptive Boundary Proposal Network for Arbitrary Shape Text Detection","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文题目：MOST: A Multi-Oriented Scene Text Detector with Localization Refinement\n作者：Minghang He, Minghui Liao, Zhibo Yang, Humen Zhong, Jun Tang, Wenqing Cheng, Cong Yao, Yongpan Wang, Xiang Bai\n会议/时间：CVPR 2021\n链接: arXiv\n论文目标 传统的文本检测算法对于长文本和小文本的检测效果比较差。为了解决长文本和小文本的检测问题，引入了新的NMS、IoU Loss和特征对齐模块。\n例如在EAST中，由于使用分类输出作为NMS的权重，而且模型感受野比较小，很难获得足够的信息检测到长文本。\n相关工作 现有的文本检测算法主要包括两种思路，自下而上和自上而下。其中前者主要是检测到文本中的部分元素，然后合并得到完整的检测结果，包括SegLink、TextSnake、CRAFT、PSENet等，由于需要复杂的后处理算法处理模型的输出结果，整体的处理效率受限制，而且后处理算法的效果也会影响到整体的结果。后者直接使用模型输出文本边框的检测结果，包括EAST、TextBoxes等。自上而下的又可以分为一阶段的和两阶段的，前者直接输出模型结果，后者包括Mask TextSpotter系列，使用类似Mask R-CNN的思路，首先使用RPN输出Proposal。\n在LOMO模型中，使用了迭代优化模型，使用RoI Transform迭代优化模型结果，从而解决长文本的检测问题。\n本文方法 模型整体结构如下，特征提取模块使用了基于ResNet50的FPN网络，上下两个分支来自EAST中的分类和位置预测图。 来自EAST的两个分支的监督与EAST相同。分类分支使用向内收缩后的文本框表示，位置预测图包括四个通道，表示当前位置距离文本框上下左右的距离。 TFAM的结构如下。首先生成粗检测结果，然后将粗检测结果和特征传入变形卷积层中。其中变形卷积选择采样点有两种方式，分别是Feature-Based Sampling和Localization-Based Sampling。其中，前者是使用额外的卷积来计算采样点的偏移量，后者是直接使用当前点预测的粗检测框的位置作为偏移后的采样点。 本文中提出的Position-awareness NMS与EAST中的locality-awareness NMS不同。在EAST中进行的NMS是，是利用加权平均的方式，使用Text/Non-Text分类的结果作为权值进行加权和然后进行正常的NMS。\n本文中提出的PA-NMS基于一个假设，距离边界越近的点，得到的距离边界的距离越准确，因此在聚合的时候使用的权重为当前点距离边界的位置。当使用边框p和q聚合得到m时，计算过程如下。其中TBLR分别为EAST输出的Geo-Map的四个通道，即Position-Awareness Map。 其中Position-Awareness Map（相当于EAST中的Geo-Map归一化到0-1）的生成方式如下。 在损失函数的选择上，原本EAST中使用IoU-Loss。但是文中提到如下观点。因此引入了Instance-wise IoU Loss。\nthe large text region contains far more positive samples than the small text region, which makes the regression loss bias towards large and long text instances.\n其中$N_t$为Text Instance的数量，$S_j$为每个Text Instance中Positive Sample的数量。（这里我没有很清楚具体Text Instance和Positive Sample的定义，为理解为对于每一个Text/Non-Text分类为真的点都要计算IoU，对于面积比较大的文本计算IoU的次数比较多，导致模型偏重大文本和长文本。） 最终的损失函数定义如下，完整的损失包括分类损失、检测损失、位置损失。分类损失使用BCE-Loss计算，位置损失使用Smoothed L1-Loss计算。在检测损失中包括了检测结果的IoU-Loss和边界框角度的Cosine-Loss。 $$\\begin{align} L \u0026amp;= L_s + \\lambda_{gc} L_{gc} + \\lambda_{gr} L_{gr}+ \\lambda_{p} L_{p} \\\\ L_s \u0026amp;= \\operatorname{BCE-Loss}() \\\\ L_g \u0026amp;= L_{iou} + \\lambda_{i} L_{ins-iou} + \\lambda_{\\theta} L_{\\theta} \\\\ L_{\\theta} \u0026amp;= \\frac{1}{|\\Omega|}\\sum\\limits_{i \\in \\Omega}1-\\cos (\\hat{\\theta_i} - \\theta_i^*) \\\\ L_p \u0026amp;= \\frac{1}{4|\\Omega|}\\sum\\limits_{i \\in \\Omega}\\sum\\limits_{\\Psi \\in \\{L,R,T,B\\}}\\operatorname{SmoothedL1}(\\hat{\\Psi_i}-\\Psi_i^*) \\end{align}$$ 结果分析 在数据集SynthText上预训练，在数据集MLT17、MTWI、IC15、MSRA-TD500(with HUST-TR400)上训练和测试。\n在Ablation Study中，证明Localization-Based Sampling相比Feature-Based Sampling效果更好，而同时结合这两种的效果最好。同时也证明了本文中提出的TFAM、PA-NMS、Instance-wise IoU Loss都能提升模型的性能。 在与SOTA模型的比较中，MOST也都能获得不错的性能提升。\n总结 为了解决长文本的检测问题，引入了TFAM扩展感受野修正粗检测结果。 为了解决不同大小的文本的检测问题，引入了Instance-wise IoU Loss，防止损失函数过度关注大文本和长文本目标。 在NMS阶段引入了Position-Aware NMS，可以更好的合并检测框。\n","date":1625794524,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625794524,"objectID":"292a2d4eecb0108b829cd6216478f966","permalink":"https://yangleisx.github.io/post/paper-most/","publishdate":"2021-07-09T09:35:24+08:00","relpermalink":"/post/paper-most/","section":"post","summary":"论文题目：MOST: A Multi-Oriented Scene Text Detector with Localization Refinement\n作者：Minghang He, Minghui Liao, Zhibo Yang, Humen Zhong, Jun Tang, Wenqing Cheng, Cong Yao, Yongpan Wang, Xiang Bai\n会议/时间：CVPR 2021\n链接: arXiv\n","tags":["Text_Detection"],"title":"【论文】MOST: A Multi-Oriented Scene Text Detector with Localization Refinement","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文题目：Feature Pyramid Networks for Object Detection\n作者：Tsung-Yi Lin, Piotr Doll´ar, Ross Girshick, Kaiming He, Bharath Hariharan, Serge Belongie\n会议/时间：CVPR2017\n链接: arxiv\n论文目标 在传统目标检测任务中，通常会使用图像金字塔的方式来检测到不同尺度大小的目标。但是在深度神经网络中，直接使用图像金字塔的计算复杂度比较高，因此限制了图像金字塔的使用。\n在论文中提出了一种使用旁路链接的特征金字塔网络，可以充分利用到不同尺度的特征信息，从而提高目标检测等相关任务的性能，同时不会引入太高的时空复杂度。\n相关工作 最早的图像金字塔网络中，将原始图像经过不同程度的缩放之后，分别提取特征信息用于预测，时空复杂度都很高。在使用卷积神经网络的模型中，使用多层卷积层方式逐渐提取高级图像特征，最终用于预测的方式具有较高的鲁棒性，相比传统方法取得了不错的效果，但是没有充分利用到不同尺度的信息，中间层提取的特征解释性比较差。相比之下在[[SSD 系列]]中使用卷积神经网络的中间层的特征进行预测，不仅利用到了不同尺度的图像特征，相比只使用最高层特征的方式也没有引入太多的计算成本。\n本文方法 通过旁路连接，构建了一个自上而下的特征金字塔网络，在编码器一端使用现有的分类网络结构，逐层提取特征。在特征融合部分，将上层特征经过上采样放大后，与使用卷积修改通道数之后的下层特征相加，得到了融合后的特征。 在预测的时候，在每一层融合后的特征都使用固定大小的卷积得到特征图用于预测，从而可以检测到不同大小的目标。 论文中指出在特征融合的时候可以设计多种融合形式，不局限于文中的1*1卷积，也可以使用残差模块等，论文中只讨论整体的特征融合结构。\n结果分析 文中将提出的FPN结构加入RPN 区域建议网络和Fast R-CNN网络中进行了测试。同时也另在图像分割任务中进行了实验。 经实验可以看到所提出的特征金字塔结构均能取得性能的提升。\n总结 提出了一种自上而下的特征融合结构，使用逐元素相加的方式实现上下层特征相结合，并且在每一层融合后的特征之上都生成特征图用于预测。\n","date":1620725664,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1620725664,"objectID":"da8a7b6c91cb756af5db7eeb9f333723","permalink":"https://yangleisx.github.io/post/paper-fpn/","publishdate":"2021-05-11T17:34:24+08:00","relpermalink":"/post/paper-fpn/","section":"post","summary":"论文题目：Feature Pyramid Networks for Object Detection\n作者：Tsung-Yi Lin, Piotr Doll´ar, Ross Girshick, Kaiming He, Bharath Hariharan, Serge Belongie\n会议/时间：CVPR2017\n链接: arxiv\n","tags":["Object Detection"],"title":"【论文】Feature Pyramid Networks for Object Detection","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文题目：ContourNet: Taking a Further Step toward Accurate Arbitrary-shaped Scene Text Detection\n作者：Yuxin Wang, Hongtao Xie, Zhengjun Zha, Mengting Xing, Zilong Fu, Yongdong Zhang\n会议/时间：CVPR2020\n链接: arXiv\n论文目标 目前的图像文本检测算法常常会将一些纹理信息识别为文本，得到假正例，而且图像文本常常具有多种尺度大小和形状，难以识别。 在论文中提出了一种模型，通过引入自适应区域建议网络和正交的纹理敏感模块来解决上述问题。前者是一种区域大小无关的RPN网络，使用IoU监督，后者可以从正交的两个方向上检测纹理信息，有效避免假正例。模型检测结果为目标的若干个轮廓点，可以通过进一步后处理得到多边形边界框。\n相关工作 近年来图像文本检测算法对于假正例的问题有多种解决思路：SPCNET中使用了语义特征来修正边界框，或者也可以使用置信度等修正边界框。\n对于图像尺度多变的问题，MSR使用了多尺度网络结构、DSRN提出了双向多尺度关系网络等。\n在传统文本检测中常用的算法包括连通域分析和滑窗处理。在深度模型中常用的思路包括基于边界框回归的思路和基于语义的思路。前者包括EAST、DDR、LOMO等首先需要使用Anchor-Based或者Anchor-Free的思路生成边界框。后者需要对分割图进行后处理。\n本文方法 模型包括两个部分，前半部分Adaptive-RPN生成文本所在区域，然后使用LOTM进行两个方向的处理得到文本轮廓点。 在Adaptive-RPN中，传统方法是使用生成四个值 ${\\Delta x, \\Delta y, \\Delta w, \\Delta h}$去优化得到矩形区域，使用$l_1\\ Loss$监督。但是这样的方式对于区域的大小比较敏感。\n本文中一方面使用$N$个点来表示$RoI$，其中一个点表示区域中心，剩下$N-1$个点表示区域的边框，根据这$N$个点的最边界点得到$RoI$。另一方面使用$IoU\\ Loss$来监督这个$N$个点的回归，对尺度不敏感。计算最边界点的方式如下： $$\\begin{aligned} Proposal = \u0026amp; \\{x_{tl}, y_{tl}, x_{rb}, y_{rb}\\} \\\\ = \u0026amp; \\{\\min\\{x_r\\}_{r=1}^n, \\min\\{y_r\\}_{r=1}^n, \\\\ \\ \u0026amp; \\ \\max\\{x_r\\}_{r=1}^n, \\max\\{y_r\\}_{r=1}^n\\} \\end{aligned}$$ 在获得文本边界点的时候，使用了相互正交的两个方向上的特征分别得到轮廓点热力图。文中假设对于一个文字在两个方向上都具有明显的特征，但是其他无意义的纹理通常只在一个方向上具有比较明显的特征，因此可以通过两个方向上的分别处理区分开。 接着在后处理算法中将两个轮廓点热力图合并起来得到文本轮廓点。其算法如下，首先分别进行NMS处理减少多余的点，然后将两个方向上都都具有较高置信度的点作为输出得到轮廓点。最终通过Alpha-Shape Algorithm得到多边形边界框。 需要注意在生成监督的时候，对于两个方向上的轮廓点都使用相同的监督，即通过原始多边形边界框生成的宽度不低于2个像素的边框（这里是我的理解，原文如下）。\nwe use distance_transform_edt in Scipy to obtain the two-points wide edge.\n结果分析 对于Adap-RPN中表示RoI的点的数量的实验。 对于Adap_RPN的有效性的实验。 对于LOTM中$1*N$和$N*1$卷积长度的实验。 对于LOTM的两方向特征融合效果的实验。 总结 在三个任务上（弯曲文本：Total-Text，长弯曲文本：CTW1500，多方向文本：ICDAR2015）均相对SOTA有一定的提升。可以看到本文方法有效减少了假正例的出现。\n","date":1620446317,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1620446317,"objectID":"78a95a23028717246c5bd82163119b9b","permalink":"https://yangleisx.github.io/post/paper-contournet/","publishdate":"2021-05-08T11:58:37+08:00","relpermalink":"/post/paper-contournet/","section":"post","summary":"论文题目：ContourNet: Taking a Further Step toward Accurate Arbitrary-shaped Scene Text Detection\n作者：Yuxin Wang, Hongtao Xie, Zhengjun Zha, Mengting Xing, Zilong Fu, Yongdong Zhang\n会议/时间：CVPR2020\n链接: arXiv\n","tags":["Text Detection","Region Proposal Network"],"title":"【论文】ContourNet: Taking a Further Step toward Accurate Arbitrary-shaped Scene Text Detection","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文题目： Densely Connected Convolutional Networks\n作者： Gao Huang, Zhuang Liu, Laurens van der Maaten, Kilian Q. Weinberger\n会议/时间：CVPR2017\n链接: arXiv\n论文目标 在CNN中，增加模型深度可以增加卷积层的感受野，从而提升CNN的性能，但是深度太大的CNN在训练的时候会出现梯度消失的问题。根据ResNet 残差网络的设计，通过添加短路链接可以使得比较深的网络更容易训练和收敛。\n为了进一步融合不同尺度特征，本文提出的DenseNet模型通过添加稠密的短路链接可以使特征图得到充分的利用，增大梯度信息流，从而减少参数数量，提升模型的性能。通过稠密的短路连接，每一个卷积层都可以看作与输入的数据和最后的全连接层直接相连，从而得到充分的监督。\n相关工作 在Highway Network中，首次引入了短路连接的思想，从而使得训练上百层的神经网络成为可能。在ResNet 残差网络中，通过短路连接，将每一个Residual Block的输入通过恒等映射直接连接到输出，实现了突破性的提升。在Stochastic Depth网络中训练的时候随机跳过了模型中的某些层，实际上也能取得非常不错的效果，这就证明在非常深的模型中有一些卷积层的存在其实是冗余的。\n与上述模型不同的是，在GoogLeNet和FractalNet中使用了Inception结构增加模型宽度的方式来提升模型的性能。\n其他的提升性能的思路包括：NIN（在卷积层中添加多层感知机提取丰富特征），DSN（使用一些分类器监督卷积的中间结果），DFN（将不同网络的中间层融合在一起）等。\n本文方法 将多个卷积层组合得到Dense Block，其中每一个卷积层的输入都是之前所有层的输出按通道连接得到。即 $x_l = H_l([x_0, x_1, …, x_{l-1}])$。同时需要注意，每一个卷积层都是由带有bottleneck的混合卷积操作组成的，其中的混合卷积操作指BatchNorm + ReLU + Conv3x3组成，通道数为 $k$，bottleneck是指BatchNorm + ReLU + Conv1x1组成，通道数为 $4k$。这里的 $k$称为Growth Rate，即每通过一个卷积层，通道数都会增加 $k$个。\n在每一个Dense Block之中的特征图大小是相同的，在相邻的DenseBlock之间引入Transition层，包括Conv1x1和Pooling2x2，其中的卷积操作用于压缩通道数量，防止通道数量无限制的增大，而池化操作用于压缩特征图数量。最终得到完整的DenseNet结构如下。 在实验中提出的不同大小的模型结构如下： 结果分析 模型在CIFAR、SVHN、ImageNet等任务上测试，结果与现有的SOTA模型相比，取得了比较大的提升。 重点比较了ResNet，证明了DenseNet使用更小的模型参数也能取得与ResNet相近甚至更好的效果，证明了之前提到了使用DenseNet可以减少模型参数的说法。 需要注意的是，尽管DenseNet模型参数数量很少，但是由于包含稠密连接，最直接的实现在训练和优化的时候中间变量需要占用大量的显存，空间效率很低。因此本文的作者在另一篇文章1中提出了DenseNet的优化实现。\n总结 使用稠密的短路连接，使得模型学到丰富的不同尺度的信息，使梯度信息的传播最大化，从而在减少参数数量的基础上提升模型的性能。\nG. Pleiss, D. Chen, G. Huang, T. Li, L. van der Maaten, and K. Q. Weinberger. Memory-efficient implementation of densenets. arXiv preprint arXiv:1707.06990, 2017. 5 ↩︎\n","date":1618899792,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618899792,"objectID":"9373651d608a4541c34a04bc1dfc9050","permalink":"https://yangleisx.github.io/post/paper-densenet/","publishdate":"2021-04-20T14:23:12+08:00","relpermalink":"/post/paper-densenet/","section":"post","summary":"论文题目： Densely Connected Convolutional Networks\n作者： Gao Huang, Zhuang Liu, Laurens van der Maaten, Kilian Q. Weinberger\n会议/时间：CVPR2017\n链接: arXiv\n","tags":["Image Recognition","Backbone"],"title":"【论文】Densely Connected Convolutional Networks","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文题目：Densely connected multidilated convolutional networks for dense prediction tasks\n作者：Naoya Takahashi, Yuki Mitsufuji\n会议/时间：CVPR2021\n链接: arXiv:2011.1184v1\n论文目标 在密集预测任务中，模型通常需要处理和学习非常大范围的上下文信息，为了满足这一需求，常用的方法包括增加模型的深度（例如Resnet和DenseNet）、增加模型的宽度（例如Inception）。一种效果比较好的方式是增加短路链接使得低层特征能够传递到比较高的卷积层中，因此在ResNet的基础上有了DenseNet。更深的网络具有的优点是高层的卷积模块具有更大的感受野，从而可以学习到更大范围的上下文信息。但是更深的网络通常比较难以训练。为了增大感受野而不增加深度，常用的方法包括空洞卷积，使用注意力机制，使用特征金字塔网络等。\n为了进一步提升在密集预测任务上的效果，作者将空洞卷积引入了DenseNet中，并且设计了D2-Block模块和D3Net网络，消除简单使用空洞卷积可能会引入的混淆问题，并在图像分割和语音讲话人分离两个任务上测试，取得了不错的效果。\n相关工作 在DenseNet中，使用了稠密的短路链接，每一层卷积层的输入都是之前的所有卷积层的输出，充分利用了不同尺度的特征图的信息，从而学习到输入数据在不同尺度上的信息。同时也增加了丰富的梯度流，使得模型能学到更丰富的信息。\n在空洞卷积或者说膨胀卷积中，在计算卷积操作的时候为卷积核之间填充了0，从而能显著的增加感受野。考虑到使用相同的膨胀因子导致的网格效应，可以采用HDC的思路，选择若干层为一组，组内使用逐渐增大的膨胀因子，使用多组连接得到完整的网络。\n本文方法 设计了一个将空洞卷积引入稠密卷积模块的方法，从而设计了D2-Block和D3Net。\n在设计D2-Block的时候，直接将空洞卷积引入了DenseNet的Dense-Block中，此时由于增加了稠密连接，最后一层使用膨胀因子为4的空洞卷积时，其感受野之间出现了盲区，可能会丢失一些局部的信息。\n因此文章中提出了混合膨胀因子的空洞卷积，也就是较高层的卷积层在计算空洞卷积的时候，对于不同层输入的特征图使用不同的膨胀因子，从而避免了上述的盲区，捕捉到更多的信息。\n文章中将上述的D2-Block通过稠密连接相组合得到D3-Block。同时使用HDC的思路来设置参数，每一组内的膨胀系数都是互素而且逐渐增加的，同时多次重复来实现锯齿形的膨胀因子。\n同时参考DenseNet的设计，在每一个D2-Block的前后都设计了Bottleneck和Compress模块，从而避免模型中的通道数量无限制的增加。\n实验结果分析 文章中进行了两组密集预测任务的实验，分别是语义分割和音频源分离。\n在第一个任务中使用CityScapes数据集。 第二个任务使用MUSDB18数据集。 总结 将空洞卷积引入了DenseNet中。提出了混合膨胀因子的空洞卷积。\n","date":1618651722,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618651722,"objectID":"41a4606f121e8249d04c04f8ec4efb23","permalink":"https://yangleisx.github.io/post/paper-d3net/","publishdate":"2021-04-17T17:28:42+08:00","relpermalink":"/post/paper-d3net/","section":"post","summary":"论文题目：Densely connected multidilated convolutional networks for dense prediction tasks\n作者：Naoya Takahashi, Yuki Mitsufuji\n会议/时间：CVPR2021\n链接: arXiv:2011.1184v1\n","tags":["Semantic Segmentation","Audio Source Separation"],"title":"【论文】Densely connected multidilated convolutional networks for dense prediction tasks","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文题目：Real-time Scene Text Detection with Differentiable Binarization\n作者：Minghui Liao, Zhaoyi Wan, Cong Yao, Kai Chen, Xiang Bai\n会议/时间：AAAI2020\n链接：https://arxiv.org/pdf/1911.08947.pdf\n论文目标 基于目标分割的文本检测系统通常能取得比较好的结果，尤其是在检测形状比较多变的文本目标的时候，但是基于分割的系统通常需要设计后处理算法，对模型输出的概率图加以处理得到文本区域的位置。为此本文设计了Differentiable Binarization模块，使得模型同时输出分割图和阈值，使用模型输出的阈值对分割图进行二值化可以得到比较好的结果。\n相关工作 近年来图像文本检测的算法主要分为两类，即基于回归的和基于分割的。前者包括TextBoxes、SSD、EAST、SegLink等，后者包括Mask TextSpotter、PSENet等。同时有一些快速文本检测算法，旨在在不损失精确度的情况下提高预测的速度。例如在SSD的基础上发展了TextBoxes++和RRD等，在PVANet基础上发展EAST等。\n本文思路/解决方案 整体使用特征金字塔结构，不同尺度的特征图融合得到特征F，在此基础上得到预测图和阈值图，利用阈值图T对预测图P二值化，得到二值化的图像B，最终得到检测结果。在训练过程中预测图和二值化图使用相同的目标监督，在预测的时候可以通过预测图或者二值化图中的任意一个得到目标检测结果。\n为了便于梯度传播，这里使用了可微的二值化函数代替标准的二值化。 $$\\begin{align} \\hat{B}_{i,j} = \\frac{1}{1+e^{-k(P_{i,j}-T_{i,j})}} \\end{align}$$ 同时在文章中使用的ResNet-18和ResNet-50中采用了可变形卷积取代原本的卷积操作，经实验有一定的性能提升。\n在生成标签时，使用Vatti算法，将多边形框收缩得到预测图的标签。同时将多边形框收缩和膨胀，其中的区域作为阈值图的区域，阈值图的取值由距离原多边形框的距离确定。\n在计算loss的时候，使用 Binary Cross-Entropy(BCE)作为预测图和二值化图的损失函数，使用L1距离作为阈值图的损失函数。其中$R_d$是膨胀后的边界框内部的像素，$S_l$是用于计算的数据集合。 $$\\begin{align} L \u0026amp;= L_s+\\alpha L_b+\\beta L_t \\\\ L_s = L_b \u0026amp;= \\sum\\limits_{i \\in S_l}y_i\\log x_i + (1-y_i)\\log(1-x_i) \\\\ L_t \u0026amp;= \\sum\\limits_{i\\in R_d}|y_i^* - x_i^*| \\end{align}$$ 结果 使用了可变形卷积和DB模块之后，模型在CTW1500和MSRA-TD500上的性能均有所提升。为阈值图添加监督之后性能也有所提升。在卷曲文本、多语言文本、多朝向文本上的效果均相比之前的模型有所提升。\n总结 引入了DB模块，通过二值化阈值的预测提升检测的结果，同时使用了比较精简的模型，具有较快的处理速度。\n","date":1614926357,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614926357,"objectID":"a1b2c97fc65a3380984f6a9502448b9c","permalink":"https://yangleisx.github.io/post/paper-db-mod/","publishdate":"2021-03-05T14:39:17+08:00","relpermalink":"/post/paper-db-mod/","section":"post","summary":"论文题目：Real-time Scene Text Detection with Differentiable Binarization\n作者：Minghui Liao, Zhaoyi Wan, Cong Yao, Kai Chen, Xiang Bai\n会议/时间：AAAI2020\n链接：https://arxiv.org/pdf/1911.08947.pdf\n","tags":["Deep Learning","Text Detection"],"title":"【论文】Real-time Scene Text Detection with Differentiable Binarization","type":"post"},{"authors":["Lei Yang"],"categories":["杂谈"],"content":"蛮早的时候就打算写点东西总结一下我的2020年。但是一直都没顾得上，一直拖到现在。\n回顾一下这博客的历史，我大概是在2018年初开始使用Hexo为框架写一点东西并且放在Github Pages，但是18年中的时候，由于电脑的SSD烧坏，所有的代码和笔记都没有了（如果没有这事我也不会开始学着定期备份我的资料），也就一直都没再次开通。一方面是觉得整个过程有点繁琐，另一方面也是觉得自己其实没有太多的东西可以发出来。但是后来慢慢地又开始觉得写点东西做记录对于自己还是蛮好的，于是再次萌生了搭个博客分享给大家的念头，最终在2019年九月的时候付诸实际再次把博客搭起来。\n记得那时这博客还部署在宿舍的一台小服务器上，说小并不过分，因为实际上只是一块arm核的开发板。似乎是OrangePi系列的最小的型号，大概5cm见方，RAM只有256M。当然了这样的小开发板并不能支持7*24h的工作，在十一月份就不堪重负烧掉了。于是我再次将博客部署在Github Pages上，并且把他加入了Google搜索。\n从2019年九月底的时候再一次开通博客到现在，总共写了78篇各种各样内容的东西（想用“文章”这个词，又觉得太大了，不如用“笔记”更好一点）。其中19年的三个月25篇，20年全年只有53篇。\n大概回顾一下之前写的东西，19年发的笔记基本都是对之前学过的东西做的总结，比如之前参加美赛时候学LaTeX的一些记录，Linux的学习记录等，也有一些是平时上课的复习笔记。那个时候更多的把这个博客作为笔记的管理工具，既然平时喜欢总结一些笔记，不如整理一下发出来，以后自己看的时候也方便，可以直接打开浏览器来看。\n20年前期写的东西有一些是论文笔记，还有一些是深度学习相关的，主要是因为要参加2020年的信安竞赛，为了准备自己的项目，补充了一些机器学习相关的知识（可以看到有在做一些西瓜书和花书的读书笔记，并且烂尾了）。\n20年大多数的文章都是平时上课和考试复习过程中总结的课程相关的内容，因为平时有总结笔记的习惯，觉得删掉也是浪费，不如总结一下发上来。后来发现其实还是非常有用的，比如说每次Google给我发月度报告的时候我都会发现，我浏览量最高的笔记不是别的，而是在Clion上搭建STM32的开发环境的记录（其实还是比较愧疚的，那笔记我写的太简单了，应该多配一点图什么的）。其中还有一些是读代码过程中学到的一些库的使用方式，我也都总结了一下发了上来。\n20年还有很多笔记是读论文的记录，我觉得这一部分将会变成未来很长一段时间的主流。由于我毕设的题目是与Text Detection相关的内容，在接下来的至少半年时间内，我主要的精力应该都是放在与OCR有关的内容上。例如阅读这个领域相关的论文，写一些论文的阅读笔记。因为主要使用PyTorch完成毕设，应该还会有一些笔记是关于PyTorch和OpenCV的使用技巧的，例如一些代码段的记录。比如说最近就在看SynthText数据集的生成代码，感觉可以从中学到很多实用的Python编程技巧，如果可能的话，我也会把自己的理解写一写发上来。\n回顾2020年发的各种笔记，这一年中发生的各种事情也仿佛就在我面前，从寒假期间速成PyTorch，准备信安竞赛的项目。到学期中为了顺利完成大作业疯狂学习QT，调试STM32，速成NodeJS。再到暑假的时候为了准备面试而自学网安概论的相关知识。最后再到20年后半年没有什么特别的压力，随便看看随便写写。这个博客记录了我一整年的成长过程，我也希望能够这么一直记录下去。\n2021年内，我希望我能有不少于50篇左右的笔记能在这里和大家分享，我希望这些笔记包括：西瓜书和花书的后续一些章节、python中的一些函数库的用法（Counter、pickle、shutil、Colorize、tqdm等）、近几年的其他Text Detection相关论文、CRAFT模型复现、SynthText中文引擎（最后这两个应该会在我的Github上更新）。如果flag不会倒的话，应该不久之后就能看到其中的一些笔记。\n2020年结束了，2021年开始了。希望我能在新的一年里不停的进步，也希望看到这段话的hxd们新的一年里心想事成。\n","date":1610018458,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1610018458,"objectID":"f65df797db8cf726956cc71a649ecf5c","permalink":"https://yangleisx.github.io/post/2020-review/","publishdate":"2021-01-07T19:20:58+08:00","relpermalink":"/post/2020-review/","section":"post","summary":"蛮早的时候就打算写点东西总结一下我的2020年。但是一直都没顾得上，一直拖到现在。\n","tags":[],"title":"2020年度总结","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文题目：EAST: An Efficient and Accurate Scene Text Detector\n作者：Xinyu Zhou, Cong Yao, He Wen, Yuzhi Wang, Shuchang Zhou, Weiran He, and Jiajun Liang\n会议/时间：CVPR2017\n链接：https://arxiv.org/abs/1704.03155v2\n论文目标 传统的文字检测模型尽管可以取得不错的效果，但是往往由多个阶段和结构组成，这样复杂的结构往往会影响到整体的性能，因此本文的作者设计了一种简单快速的pipeline，可以从给定图像中直接检测到文本的位置。通过使用一个简单的神经网络而不是多个模块组合的方式加快了处理的速度，简化了模型的复杂度。\n相关工作 常规的处理方法依赖于人工设计的特征，例如SWT和MSER等模型通过边缘检测等方式。但是这些依赖人工设计特征的算法在处理一些有挑战性的场景时效果比较差，例如低分辨率或者出现失真的情况下。\n相比之下，基于深度神经网络的文本检测算法由于能取得更好的效果，逐渐成为主流，包括使用CNN对文本检测的结果进行筛选或者使用FCN生成热力图/分割图对原始图像处理得到检测结果。但是多数基于深度神经网络的模型由多个阶段组成，结构比较复杂性能也比较差。\n本文思路/解决方案 本文设计了一个基于FCN的神经网络，且完整的模型只有两个阶段，省去了冗余的中间处理阶段，即神经网络得到预测的文本框，再通过非极大值抑制得到最终的预测结果。\n基于FCN的网络结构设计如下，通过神经网络直接得到了三类型的输出：Score Map、Rotated Box、Quadrangle。其中的score map为置信度，置信度超过给定阈值的预测框通过NMS得到最终的输出。通过使用U-Net可以融合不同尺度的特征，有助于检测不同大小的文本目标。\n在生成GT时，将原本的四边形缩小到0.7倍并二值化可以得到Score Map，对于没有RBOX标注的数据，首先根据QUAD创建一个最小矩形，再计算每个点到四个边界的距离得到RBOX标注。\n对于损失函数的计算，采用了Score Map损失和Geometry损失的加权平均值。由于在自然场景下的图像中，检测目标与背景占据的面积不均衡，在计算Loss的时候会受到影响，为了不引入额外的处理流程，计算Score Map损失时使用了class-balanced cross-entropy，可以比较好的解决正反例不均衡的情况。\n$$\\begin{aligned} L_s =\u0026amp;\\; \\operatorname{balances-xent}(\\mathbf{\\hat{Y}}, \\mathbf{Y^*}) \\\\ =\u0026amp; -\\beta\\mathbf{Y^*}\\log\\mathbf{\\hat{Y}}-(1-\\beta)(1-\\mathbf{Y^*})\\log(1-\\mathbf{\\hat{Y}}) \\\\ \\beta =\u0026amp;\\; 1 - \\frac{\\sum_{y^*\\in\\mathbf{Y^*}}y^*}{|\\mathbf{Y^*}|} \\end{aligned}$$ 对于Geometry输出的损失函数，在RBOX的情形中，对于AABB部分使用IOU损失，对于倾斜角的部分使用余弦函数计算损失。 $$\\begin{aligned} L_{AABB} =\u0026amp;\\; -\\log\\operatorname{IoU}(\\mathbf{\\hat{R}},\\mathbf{R^*}) \\\\ =\u0026amp;\\;-\\log\\frac{|\\mathbf{\\hat{R}}\\cap\\mathbf{R^*}|}{|\\mathbf{\\hat{R}}\\cup\\mathbf{R^*}|} \\\\ L_\\theta(\\hat{\\theta},\\theta^*) =\u0026amp;\\;1 - \\operatorname{cos}(\\hat{\\theta} - \\theta^*) \\\\ L_g =\u0026amp;\\;L_{AABB} + \\lambda_\\theta L_\\theta \\end{aligned}$$ 在QUAD的情形中，使用增加了正则项的smoothed-L1损失计算。 $$\\begin{aligned} L_g =\u0026amp;\\; L_{QUAD}(\\mathbf{\\hat{Q}},\\mathbf{Q^*}) \\\\ =\u0026amp;\\;\\min\\limits_{\\mathbf{\\tilde{Q}} \\in P_{\\mathbf{Q^*}}}\\sum\\limits_{c_i \\in C_{\\mathbf{Q}} \\\\\\tilde{c}_i\\in C_{\\mathbf{\\tilde{Q}}}} \\frac{\\operatorname{smoothed_{L1}}(c_i - \\tilde{c}_i)}{8 \\times N_{\\mathbf{Q^*}}} \\\\ N_{\\mathbf{Q^*}} =\u0026amp;\\;\\min\\limits_{i=1}^{4}D(p_i, p_{(i \\operatorname{mod} 4)+1}) \\end{aligned}$$ 对于模型输出的结果，使用阈值筛选之后，再使用作者设计的一种基于合并候选框的NMS算法处理得到结果。\n结果 在ICDAR2015、COCO-Text和MSRA-TD500三个数据集上进行测试。同时对于模型的骨架也使用了PVANET、PVANET2x和VGG16三种不同的结构进行测试（网络框架都在InageNet上预训练）。经测试模型在上述数据集上能取得超过SOTA的F值。在处理速度上也能达到比较高的FPS。\n总结 本文提出的EAST模型，通过减少冗余的处理阶段，得到了简单快速的处理效果，通过FCN网络直接生成预测的结果（geometry map），结合NMS处理多余的候选框，可以得到比较好的效果。\n","date":1607223682,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607223682,"objectID":"d49eff923261ea1879721e6614c6a752","permalink":"https://yangleisx.github.io/post/paper-east/","publishdate":"2020-12-06T11:01:22+08:00","relpermalink":"/post/paper-east/","section":"post","summary":"论文题目：EAST: An Efficient and Accurate Scene Text Detector\n作者：Xinyu Zhou, Cong Yao, He Wen, Yuzhi Wang, Shuchang Zhou, Weiran He, and Jiajun Liang\n会议/时间：CVPR2017\n链接：https://arxiv.org/abs/1704.03155v2\n","tags":["Text Detection","Deep Learning","Computer Vision"],"title":"【论文】EAST: An Efficient and Accurate Scene Text Detector","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文题目：Shape Robust Text Detection with Progressive Scale Expansion Network\n作者：Wenhai Wang, Enze Xie, Xiang Li, Wenbo Hou, Tong Lu, Gang Yu, Shuai Shao\n会议/时间：CVPR2019\n链接：arxiv\n论文目标 在当前的文字检测算法在应用时有两个问题：当前的算法通常得到一个四边形边界框，难以检测任意形状的文本；如果两行文本距离比较近，有可能会被框选为同一个边界框。因此提出了PSENet，可以有效的解决上述的两个问题。\n相关工作 现有的基于CNN的文本检测模型可以分为两类：基于回归的方案和基于分割的方案。前者生成四边形的边界框，无法处理任意形状的文本，后者使用像素级的分类得到目标区域，但是很难区分开相聚比较近的目标。\n基于回归的文本检测方案大多是基于通用的目标检测模型，包括Faster R-CNN等。其他的文本检测模型还有TextBoxes、EAST等。大多数这一类的模型都需要设计Anchor而且由多个处理阶段组成，可能会导致性能比较差。基于分割的文本检测方案主要使用FCN，例如通过FCN获得热力图等，再进行后处理获得文本位置。\n本文思路/解决方案 本文提出的PSENet是基于分割的方案，每一个预测的分割称为kernel，形状相似但是大小不同，最后设计了一个基于BFS的渐进扩展算法，将原本的kernel扩展得到最终的预测分割。由于使用渐近扩展式的算法，对于最小尺寸的kernel，可以区分开距离较近的文本，同时也可以解决小尺寸分割难以覆盖完整文本的问题。\n模型结构是基于ResNet的FPN结构，从中选取不同大小的特征图连接得到混合特征图，最后通过卷积等操作得到不同尺寸的多个分割图，再经过尺寸扩展得到预测结果。\n在这个尺寸扩展算法中，首先选择了尺寸最小的分割图进行连通域分析作为kernel，然后将其他的分割图作为输入，通过Scale Expansion算法计算新的扩展后的kernel，最终得到结果。作者提到对于位于多个文本之间的像素，使用先来先服务的方式合并到不同的标签中，同时由于使用了渐进式的方法，这些边界上的重合并不会影响最终的处理结果，这可能也是作者选择多个不同尺寸的分割图渐近处理的原因。\n在训练过程中，为了获得不同尺寸的分割图，需要提供对应的标签供学习，作者使用了Vatti clipping algorithm来将最初的文本框标签收缩一定的像素得到这些标签。算法中使用到的像素值通过下面的公式计算得到。其中m为最小的缩放比例，n为不同尺寸的分割图的个数。\n$$\\begin{aligned} d_i = \\frac{\\mathrm{Area}(p_n)\\times(1-r_i^2)}{\\mathrm{Perimeter}(p_n)}\\notag\\\\ r_i = 1 - \\frac{(1-m)\\times(n-i)}{n-1} \\end{aligned}$$ 在实验中作者使用了Dice Coefficient作为模型的评价指标，使用了完整尺寸的标签和缩放后的标签上的Dice系数作为损失函数来指导模型的学习。其中对于完整尺寸的标签，使用Online Hard Example Mining(OHEM)来获得一个mask协助训练。 $$\\begin{aligned} L \u0026amp;= \\lambda L_c + (1-\\lambda)L_s\\notag\\\\ L_c \u0026amp;= 1 - D(S_n\\cdot M, G_n \\cdot M)\\notag\\\\ L_s \u0026amp;= 1 - \\frac{\\sum\\limits^{n-1} D(S_i\\cdot W, G_i \\cdot W)}{n-1}\\notag\\\\ W_{x,y} \u0026amp;= \\left\\{ \\begin{align} 1,\u0026amp; \\quad if\\ S_{n,x,y} \\geq0.5;\\notag\\\\ 0,\u0026amp; \\quad otherwise\\notag\\\\ \\end{align} \\right. \\end{aligned}$$ 结果 实验包括了四个数据集：CTW1500、Total-Text、ICDAR2015和ICDAR2017MLT。模型使用预训练好的ResNet，在IC17-MLT上训练，而且没有使用另外的人造数据集。实验讨论的结果包括：\n最小尺寸的kernel并不能直接作为模型的输出，模型的F-measure结果比较差，而且文本框内容的识别结果也比较差。 对于最小缩放比例m的选择，选择太大或者太小都会导致性能的下降。 分割图的个数n增加时，性能会有一定的上升，但是不能无限制增大，在n大于5之后性能提升不大。 修改模型骨架，例如增加ResNet的层数也会提升模型的性能。 总结 使用了基于FPN的结构，将不同尺度的特征图上采样并连接在一起。\n获得不同尺度下的分割图，再从小到大渐进式的合并，不仅可以检测到任意形状的文本，也可以避免将距离比较近的文本识别为同一对象。\n","date":1605754555,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605754555,"objectID":"439ed86e8c0f5c7d5db042a857d4da49","permalink":"https://yangleisx.github.io/post/paper-psenet/","publishdate":"2020-11-19T10:55:55+08:00","relpermalink":"/post/paper-psenet/","section":"post","summary":"论文题目：Shape Robust Text Detection with Progressive Scale Expansion Network\n作者：Wenhai Wang, Enze Xie, Xiang Li, Wenbo Hou, Tong Lu, Gang Yu, Shuai Shao\n会议/时间：CVPR2019\n链接：arxiv\n","tags":["Text Detection","Deep Learning","Computer Vision"],"title":"【论文】Shape Robust Text Detection with Progressive Scale Expansion Network","type":"post"},{"authors":["Lei Yang"],"categories":["代码学习"],"content":"最近接手了一个Linux下内核编程的项目，在阅读项目原有代码的基础上，学到了很多新知识，总结一下记录在这里。\n在这个项目中，使用SQLite存储用户数据，因此需要在C语言中实现SQLite的访问和增删改查处理。\n实际上由于C语言不支持面向对象的操作，因此无法使用对象关系模型来进行处理，只能在C语言中使用SQL语句操纵数据库。\n基本操作 打开数据库 需要指定数据库文件的路径，如果不存在的话就会在指定的路径创建一个db文件保存数据库的数据。\n#include \u0026lt;sqlite3.h\u0026gt; sqlite3 * db; // 连接数据库 rc = sqlite3_open(\u0026#34;fvault.db\u0026#34;, \u0026amp; db); if (rc) { printf(\u0026#34;%s\\n\u0026#34;, \u0026#34;SQLITE OPEN ERROR\u0026#34;); sqlite3_close(db); exit(1); } 执行SQL语句 通过将SQL语句写在字符串中，可以执行SQL语句，在执行SQL语句时，可以设置一个回调函数，数据库操作结束后会调用回调函数对数据库返回的数据做响应的处理。\nsqlite3_exec的参数分别为数据库对象、SQL语句、回调函数、互调函数的参数、错误信息指针。\n无回调函数 #define CREATE \u0026#34;CREATE TABLE IF NOT EXISTS fvault\u0026#34;\\ \u0026#34;(\u0026#34; \\ \u0026#34;inode INTEGER PRIMARY KEY,\u0026#34; \\ \u0026#34;owner INTEGER\u0026#34; \\ \u0026#34;)\u0026#34; rc = sqlite3_exec(db, CREATE, NULL, 0, NULL); if (rc != SQLITE_OK) { printf(\u0026#34;%s\\n\u0026#34;, \u0026#34;ERROR\u0026#34;); sqlite3_close(db); exit(1); } 无参数的回调函数 // 回调函数，对于数据库返回的每一行都执行一次 // void* NotUsed 参数保留位置，无参数时不使用 // int argc 返回字段的个数 // char ** argv 每一个字段的值 // char ** azCoolName 字段的名称 static int callback_get_filelist(void * NotUsed, int argc, char ** argv, char ** azColName) { for (int i = 0; i \u0026lt; argc; i++) printf(\u0026#34;%s\\n\u0026#34;, argv[i]); return 0; } // 执行SQL语句 #define SELECT1 \u0026#34;SELECT inode, owner FROM fvault\u0026#34; uid_t owner = 1000; snprintf(sql, 63, SELECT1, owner); rc = sqlite3_exec(db, sql, callback_get_filelist, 0, NULL); if (rc != SQLITE_OK) { printf(\u0026#34;%s\\n\u0026#34;, \u0026#34;ERROR\u0026#34;); sqlite3_close(db); exit(1); } 有参数的回调函数 使用第四个参数传递参数的指针，在回调函数中可以实现赋值。\n// 回调函数，对于数据库返回的每一行都执行一次 // void* result 输入的参数 // int argc 返回字段的个数 // char ** argv 每一个字段的值 // char ** azCoolName 字段的名称 static int callback_get_fileowner(void * result, int argc, char ** argv, char ** azColName) { // 将查询得到的值赋给参数 if (argc == 1) * (uid_t *)result = atoi(* argv); return 0; } // 执行SQL语句 #define SELECT2 \u0026#34;SELECT owner FROM fvault WHERE inode = %lu LIMIT 1\u0026#34; unsigned long inode = 40075; snprintf(sql, 63, SELECT2, inode); rc = sqlite3_exec(db, sql, callback_get_fileowner, \u0026amp; result, NULL); if (rc != SQLITE_OK) { printf(\u0026#34;%s\\n\u0026#34;, \u0026#34;ERROR\u0026#34;); sqlite3_close(db); exit(1); } 关闭数据库 sqlite3_close(db); 编译 安装依赖 需要使用apt安装依赖的库文件\nsudo apt install libsqlite3-dev 指定库 编译时需要指定库文件\ngcc main.c -l sqlite3 -o main 总结 可以参考SQLite的C接口或者参考官网提供的接口文档。\n","date":1605340168,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605340168,"objectID":"1cdf197943901aad33c46a65b9b23630","permalink":"https://yangleisx.github.io/post/sqlite-c/","publishdate":"2020-11-14T15:49:28+08:00","relpermalink":"/post/sqlite-c/","section":"post","summary":"最近接手了一个Linux下内核编程的项目，在阅读项目原有代码的基础上，学到了很多新知识，总结一下记录在这里。\n在这个项目中，使用SQLite存储用户数据，因此需要在C语言中实现SQLite的访问和增删改查处理。\n","tags":["C/C++","Linux","SQL"],"title":"SQLite的C语言接口","type":"post"},{"authors":[],"categories":["代码学习"],"content":"最近接手了一个Linux下内核编程的项目，在阅读项目原有代码的基础上，学到了很多新知识，总结一下记录在这里。\n在这个项目中，编写内核模块进行加解密操作，使用了Linux内核提供的crypto加密API。\n环境 操作系统：Ubuntu18.10（使用Linux 4.18.0-25内核）\n使用的头文件如下：\n#include \u0026lt;crypto/hash.h\u0026gt; #include \u0026lt;crypto/skcipher.h\u0026gt; #include \u0026lt;linux/cred.h\u0026gt; #include \u0026lt;linux/scatterlist.h\u0026gt; 概述 在Linux内核中提供了加密API，通过一组头文件crypto引出。整体的思路为首先创建加密上下文，并且在上下文中注册使用的算法，最后使用内核API完成加解密的操作。这里以散列计算和对称加密为例。\n散列操作 函数目标为通过用户的ID（长度为4Byte）生成长度为32Byte的序列作为对称加密的密钥。\nstatic void generate_key(unsigned char* key) { // 创建散列操作 struct shash_desc sdesc; uid_t uid = current_uid().val; short i; // 申请运算上下文，指定算法为crc32-pclmul sdesc.tfm = crypto_alloc_shash(\u0026#34;crc32-pclmul\u0026#34;, 0, 0); // 这里选择的hash算法每次生成4Byte(32bit)长度的输出 // 满足32Byte(256bit）长度的密钥需要迭代生成 // 每次使用之前生成的部分计算哈希，将结果与之前的结果拼接起来 crypto_shash_digest(\u0026amp;sdesc, (char*)\u0026amp;uid, sizeof(uid_t), key + 28); for (i = 28; i \u0026gt; 0; i -= 4) { crypto_shash_digest(\u0026amp;sdesc, key + i, 32 - i, key + i - 4); } // 释放空间 crypto_free_shash(sdesc.tfm); } 对称加密 函数目标为当读写文件时，使用加密读写，加密是使用的参数来自用户、文件Inode、读写的位置。实现的细节参见注释。\nstatic void transform(char* ubuf, unsigned long inode, loff_t offset, size_t count) { // 创建对称加密操作 struct crypto_skcipher* skcipher = NULL; struct skcipher_request* req = NULL; struct scatterlist sg; // 密钥和初始化向量的空间 unsigned char key[32] = { 0 }; char ivdata[16] = { 0 }; // 处理时以16Byte(128bit)为单位 // 将文件分为16Byte的分段时，偏移量低四位表示位于上一分段的字节数 // 因此需要额外处理，将上一分段读取出来 short pre_len = offset \u0026amp; 0xf; char prefix[15] = { 0 }; // char* buf; buf = (char*)kmalloc(count + pre_len, GFP_KERNEL); copy_from_user(buf + pre_len, (void *)ubuf, count); // 为算法申请内核中运算的上下文 // 在crypto_alg_list链表中查询，找到AES的CTR模式并注册 // 在内核中为该算法的各个函数指针初始化 skcipher = crypto_alloc_skcipher(\u0026#34;ctr-aes-aesni\u0026#34;, 0, 0); // 在该上下文空间中申请数据处理请求 // 实际上完成了后台的内存申请和绑定 req = skcipher_request_alloc(skcipher, GFP_KERNEL); // 创建256bit的密钥，并写入本次运算的上下文内存中 generate_key(key); crypto_skcipher_setkey(skcipher, key, 32); // 创建初始化向量iv generate_iv(ivdata, inode, offset \u0026gt;\u0026gt; 4); // 在内存空间中开辟并维护一段内存 // scatterlist用于维护大段的被多个组件访问的内存（例如，CPU和DMA） // 根据位于上一分段的字节数扩展需要的内存 sg_init_one(\u0026amp;sg, buf, count + pre_len); // 将待加密数据放入本次运算的请求空间 // 第二/三参数分别表示source和destination // 第四/五参数为待加密数据的长度和初始化向量 skcipher_request_set_crypt(req, \u0026amp;sg, \u0026amp;sg, count + pre_len, ivdata); // 开始加密 // 将位于上一分段的数据保护在prefix中，防止被二次加密 memcpy(prefix, buf, pre_len); crypto_skcipher_encrypt(req); memcpy(buf, prefix, pre_len); copy_to_user((void *)ubuf, buf + pre_len, count); kfree(buf); // 清空本次处理的内存，释放空间 skcipher_request_free(req); crypto_free_skcipher(skcipher); } 总结 在Linux内核编程的过程中，需要注意使用的API和数据结构大多与用户态不太相同，这个时候需要查看内核中的相关代码寻找线索。\n可以使用在线文档工具查看相关的函数定义。\n","date":1605253347,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605253347,"objectID":"b10a88138c99153293a40cc11f328b76","permalink":"https://yangleisx.github.io/post/cpp-crypto/","publishdate":"2020-11-13T15:42:27+08:00","relpermalink":"/post/cpp-crypto/","section":"post","summary":"最近接手了一个Linux下内核编程的项目，在阅读项目原有代码的基础上，学到了很多新知识，总结一下记录在这里。\n在这个项目中，编写内核模块进行加解密操作，使用了Linux内核提供的crypto加密API。\n","tags":["C/C++","Linux"],"title":"Linux内核加密模块crypto的使用","type":"post"},{"authors":["Lei Yang"],"categories":["代码学习"],"content":"最近接手了一个Linux下内核编程的项目，在阅读项目原有代码的基础上，学到了很多新知识，总结一下记录在这里。\n在这个项目中，编写内核模块进行操作，与用户态进程之间使用Netlink Socket进行通信。\n用户空间和内核空间相互通信的方式有三种，/proc目录、ioctl和neltink。使用netlink可以很很简单的建立起内核态和用户态的全双工通信，并且可以使用简单的socket语法进行操作，比较简单。需要注意的是，内核中已经定义了多种netlink消息类型/协议，如果不使用现成的消息类型可以添加一个新的协议定义。\n需要注意的是，使用netlink通信的用户态和内核态的语法有些许的不同。而且在netlink的数据传输并不是同步的，而是将报文信息加到了接收者的接受队列中，因此netlink socket支持iov机制，也就是在一次系统调用的过程中，将多个报文信息打包发送。\n环境 操作系统：Ubuntu 18.10（使用Linux 4.18.0-25内核）\n基本数据结构 // Netlink使用sockaddr_nl地址 struct sockaddr_nl { __kernel_sa_family_t nl_family; unsigned short nl_pad; __u32 nl_pid; __u32 nl_groups; }; // struct nlmsghd 是netlink消息头 struct nlmsghdr { __u32 nlmsg_len; __u16 nlmsg_type; __u16 nlmsg_flags; __u32 nlmsg_seq; __u32 nlmsg_pid; }; /* iov_base: iov_base指向数据包缓冲区，即参数buff， iov_len是buff的长度。 msghdr中允许一次传递多个buff，以数组的形式组织在 msg_iov中，msg_iovlen就记录数组的长度 */ struct iovec { void *iov_base; size_t iov_len; }; // msghdr是发送的报文信息的头部 struct msghdr { void *msg_name; socklen_t msg_namelen; struct iovec *msg_iov; size_t msg_iovlen; void *msg_control; size_t msg_controllen; int msg_flags; }; 基本操作 用户态：相关变量 // 创建所需的变量 struct sockaddr_nl src_sockaddr, dest_sockaddr; struct nlmsghdr * nlh = NULL; struct msghdr msg; struct iovec iov; // 变量初始化 nlh = (struct nlmsghdr *)malloc(NLMSG_SPACE(sizeof(unsigned long))); memset(\u0026amp; src_sockaddr, 0, sizeof(struct sockaddr_nl)); memset(\u0026amp; dest_sockaddr, 0, sizeof(struct sockaddr_nl)); memset(nlh, 0, NLMSG_SPACE(sizeof(unsigned long))); memset(\u0026amp; msg, 0, sizeof(struct msghdr)); 用户态：创建socket 如果不使用内核中定义好的协议类型，可以自己增加一个新的协议定义作为socket的初始化参数。\n#define NETLINK_SAFE 30 server_sock = socket(AF_NETLINK, SOCK_RAW, NETLINK_SAFE); 用户态：绑定地址 通常使用进程号作为用户空间的socket地址。实际上只是一个socket的标示号码，可以任意设置，对于同一个进程的不同线程可以使用不同的标示号。\n由于netlink支持多播，还需要指定多播组，指定为0时表示不开启多播功能。\nsrc_sockaddr.nl_family = AF_NETLINK; src_sockaddr.nl_pid = getpid(); src_sockaddr.nl_groups = 0; // 绑定socket和地址 bind(server_sock, (struct sockaddr *)\u0026amp; src_sockaddr, sizeof(struct sockaddr_nl)); 用户态：构建并发送消息 使用netlink通信时需要在消息头部指定通信目标，因此需要首先建立接受方的用户地址，也就是核心态的内核模块。然后依次设置netlink消息头和每一条信息的消息头。\n需要注意使用宏NLMSG_DATA获得netlink报文的实际数据地址。使用宏NLMSG_SPACE获得报文的实际数据大小。\n// 设置核心态用户地址，核心态的pid必须设置为0 dest_sockaddr.nl_family = AF_NETLINK; dest_sockaddr.nl_pid = 0; dest_sockaddr.nl_groups = 0; // 设置netlink socket的信息头部 nlh -\u0026gt; nlmsg_len = NLMSG_SPACE(sizeof(unsigned long)); nlh -\u0026gt; nlmsg_pid = getpid(); nlh -\u0026gt; nlmsg_flags = 0; // 设置iov 可以把多个信息通过一次系统调用发送 iov.iov_base = (void *)nlh; iov.iov_len = NLMSG_SPACE(sizeof(unsigned long)); // 设置接收地址 msg.msg_name = (void *)\u0026amp; dest_sockaddr; msg.msg_namelen = sizeof(struct sockaddr_nl); msg.msg_iov = \u0026amp; iov; msg.msg_iovlen = 1; // 填充消息内容 * (unsigned long *)NLMSG_DATA(nlh) = (unsigned long)0xffffffff \u0026lt;\u0026lt; 32; // 发送和接收消息 sendmsg(server_sock, \u0026amp; msg, 0); recvmsg(server_sock, \u0026amp; msg, 0); 内核态：相关变量 static struct sock* socket; static int pid = 0; static int ino_len = sizeof(unsigned long); static atomic_t sequence = ATOMIC_INIT(0); 内核态：初始化 在内核模块的编写中需要指定初始化函数，在初始化函数中创建内核态的netlink socket。由于使用异步通信，需要在内核态中定义接收回调函数，对于接收到的消息进行处理，内核态接收到的消息类型为sk_buff类型，可以转换为nlmsghdr结构并进一步提取信息。\nstatic void nl_receive_callback(struct sk_buff* skb){ // 转换格式 struct nlmsghdr* nlh = (struct nlmsghdr*)skb-\u0026gt;data; // 获得用户凭证 int pid = NETLINK_CREDS(skb)-\u0026gt;pid; } static int __init netlink_init(void) { // 设置接收到消息的回调函数 struct netlink_kernel_cfg cfg = { .input = nl_receive_callback, }; int i; // 创建内核态netlink套接字 socket = netlink_kernel_create(\u0026amp;init_net, NETLINK_SAFE, \u0026amp;cfg); return 0; } 内核态：资源回收 在内核模块的编写中需要指定出口函数，进行资源的回收。\nstatic void __exit netlink_exit(void) { if (socket) { netlink_kernel_release(socket); } } 内核态：构建和发送数据 // 内核态存储网络结构的数据为sk_buff // 首先创建 sk_buff空间， skb = nlmsg_new(msg_len, GFP_ATOMIC); if (!skb) { return 0; } // 设置netlink消息头部 nlh = nlmsg_put(skb, 0, 0, NLMSG_DONE, msg_len, 0); seq = atomic_inc_return(\u0026amp;sequence); nlh-\u0026gt;nlmsg_seq = seq; memcpy(NLMSG_DATA(nlh), msg_buf, meg_len) // 单播类型发送数据 // 用户态使用pid作为标识符 nlmsg_unicast(socket, skb, pid); 总结 在Linux内核编程的过程中，需要注意使用的API和数据结构大多与用户态不太相同，这个时候需要查看内核中的相关代码寻找线索。\n可以使用在线文档工具查看相关的函数定义。\n","date":1605251964,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605251964,"objectID":"9693d8192cb1c293d189df547e3dfeed","permalink":"https://yangleisx.github.io/post/netlink-socket/","publishdate":"2020-11-13T15:19:24+08:00","relpermalink":"/post/netlink-socket/","section":"post","summary":"最近接手了一个Linux下内核编程的项目，在阅读项目原有代码的基础上，学到了很多新知识，总结一下记录在这里。\n在这个项目中，编写内核模块进行操作，与用户态进程之间使用Netlink Socket进行通信。\n","tags":["C/C++","Linux","Socket"],"title":"Netlink Socket内核通信","type":"post"},{"authors":["Lei Yang"],"categories":["代码学习"],"content":"最近接手了一个Linux下内核编程的项目，在阅读项目原有代码的基础上，学到了很多新知识，总结一下记录在这里。\n在这个项目中，客户端进程和服务器进程在同一台机器上，使用Unix Domain Socket通信。\nsocket是为了网络通信设计的，但是Unix Domain Socket其实是一种进程间通信的机制，实现同一主机上的进程之间的通信，使用socket的方式相比消息、信号、共享内存等进程间通信方式更加的灵活可靠，同时其语法与socket通信基本相同，因此方便使用。\n整体上的代码结构与使用socket进行网络通信相似，唯一的区别在于需要为进程绑定socket文件。\n环境说明 操作系统：Ubuntu 18.10（使用Linux 4.18.0-25内核）\n基本数据结构 // 用于socket通信的通用地址类型 struct sockaddr { unsigned short sa_family; char sa_data[14]; }; // 用于Unix域通信的地址类型 struct sockaddr_un { uint8_t sun_len; sa_family_t sun_family; char sun_path[104]; } 基本操作模块 相关变量 int rc; int server_sock, client_sock; int sockaddr_len; struct sockaddr_un server_sockaddr; struct sockaddr_un client_sockaddr; sockaddr_len = sizeof(struct sockaddr_un); memset(\u0026amp; server_sockaddr, 0, sockaddr_len); memset(\u0026amp; client_sockaddr, 0, sockaddr_len); 创建socket 需要使用AF_UNIX指定socket类型为Unix Domain类型，建立面向连接的通信。\nserver_sock = socket(AF_UNIX, SOCK_STREAM, 0); if (server_sock == -1) { printf(\u0026#34;%s\\n\u0026#34;, \u0026#34;SOCKET ERROR\u0026#34;); exit(1); } 绑定socket文件 在Unix Domain Socket中，不使用IP地址+端口来表示地址，而是使用本地保存的socket文件表示地址，因此需要建立socket到地址的绑定。主要注意在服务器端和客户端都要建立到socket文件的绑定。\n#define SOCK_PATH \u0026#34;/tmp/server.socket\u0026#34; server_sockaddr.sun_family = AF_UNIX; strcpy(server_sockaddr.sun_path, SOCK_PATH); rc = bind(server_sock, (struct sockaddr *)\u0026amp; server_sockaddr, sockaddr_len); if (rc == -1) { printf(\u0026#34;%s\\n\u0026#34;, \u0026#34;BIND ERROR\u0026#34;); close(server_sock); exit(1); } 监听地址等待连接 使用listen将一个socket变为等待被动连接的socket，同时指定了等待队列的长度，从而建立起服务器端的socket。需要注意将socket文件放置于所有用户可见的位置并修改访问权限。\nchmod(SOCK_PATH, 0666); rc = listen(server_sock, 16); if (rc == -1) { printf(\u0026#34;%s\\n\u0026#34;, \u0026#34;LISTEN ERROR\u0026#34;); close(server_sock); exit(1); } 发送连接请求 在客户端，首先要获得服务器端socket地址，也就是socket文件的路径，将其写入Unix的socket地址中，直接发起连接请求。\n#define SERVER_PATH \u0026#34;/tmp/server.socket\u0026#34; server_sockaddr.sun_family = AF_UNIX; strcpy(server_sockaddr.sun_path, SERVER_PATH); rc = connect(client_sock, (struct sockaddr *)\u0026amp; server_sockaddr, sockaddr_len); if (rc == -1) { printf(\u0026#34;%s\\n\u0026#34;, \u0026#34;CONNECT ERROR\u0026#34;); close(client_sock); exit(1); } 接受连接请求 接受请求并建立到请求着的socket通信，将对方的地址保存下来。\nclient_sock = accept(server_sock, (struct sockaddr *)\u0026amp; client_sockaddr, \u0026amp; sockaddr_len); if (client_sock == -1) { close(client_sock); continue; } 接受数据 rc = recv(client_sock, \u0026amp; reqbuf, req_len, 0); if (rc == -1) { printf(\u0026#34;%s\\n\u0026#34;, \u0026#34;RECV ERROR\u0026#34;); close(client_sock); continue; } 发送数据 rc = send(client_sock, \u0026amp; reqbuf, req_len, 0); if (rc == -1) { printf(\u0026#34;%s\\n\u0026#34;, \u0026#34;SEND ERROR\u0026#34;); close(client_sock); exit(1); } 获得通信对象信息 通过getsockopt函数可以获得socket连接的属性，包括通信对象的相关信息，由于在同一主机的不同进程间通信，可以获得进程的身份凭证，包括了进程号、用户ID和组ID。\n/* Defined in Linux/socket.h struct ucred { __u32 pid; __u32 uid; __u32 gid; }; */ struct ucred cr; ucred_len = sizeof(struct ucred); # 使用SO_PEERCRED可以获得对方的身份凭证 # ucred结构体中包含了用户id和进程id if (getsockopt(client_sock, SOL_SOCKET, SO_PEERCRED, \u0026amp; cr, \u0026amp; ucred_len) == -1) { close(client_sock); continue; } 代码框架 服务器端 int server() { listenSocket = socket(); bind(); listen(listenSocket); while(1){ clientSocket = accept(); accept(); recv() or send(); closesocket(clientSocket); } closesocket(listenSocket); } 客户端 int client() { client_socket = socket(); bind(); connect(client_socket, server_sockaddr); recv() or send(); closesocket(clientSocket); } ","date":1605247355,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605247355,"objectID":"f2942fb81f9f15b6e3da5fab084c85ed","permalink":"https://yangleisx.github.io/post/unix-socket/","publishdate":"2020-11-13T14:02:35+08:00","relpermalink":"/post/unix-socket/","section":"post","summary":"最近接手了一个Linux下内核编程的项目，在阅读项目原有代码的基础上，学到了很多新知识，总结一下记录在这里。\n在这个项目中，客户端进程和服务器进程在同一台机器上，使用Unix Domain Socket通信。\n","tags":["C/C++","Linux","Socket"],"title":"Unix Domain Socket通信","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文题目：Character Region Awareness for Text Detection\n作者：Youngmin Baek, Bado Lee, Dongyoon Han, Sangdoo Yun, and Hwalsuk Lee\n会议/时间：CVPR2019\n链接：https://arxiv.org/pdf/1904.01941.pdf\n论文目标 今年来使用深度神经网络实现的文本检测得到许多关注，但是过去的文本检测工作大多使用边界框框选每一个词，存在一定的缺陷，例如在单词非常长或者扭曲畸形的情况下效果不好，本文提出了一种基于检测单个字符的文本检测模型，通过检测连续的字符实现自下而上的单词检测。由于成本非常高，现有的文本检测数据库并没有提供字符级的标注，文中使用弱监督学习方法，可以在单词级标注的数据集上训练字符级模型。\n相关工作 很多的文本检测模型（即regression-based text detectors），使用了目标检测模型中常用的边框回归思路。尽管取得了比较好的效果，但是不能应对实际场景下的各种形状的文字。一些文本检测模型（segmentation-based text detectors），在像素级分割和检测文本区域。还有一些端到端的文本检测工具将文本检测和识别任务结合在一起，可以避免一些背景中的图形的影响，提高检测效果。大多数的文本检测是以单词为识别单位，但是在标注和划分时很难确定，造成效果较差。\n本文思路/解决方案 本文构建卷积神经网络，从图像中学习得到字符（region score）和字符之间的连接关系（affinity score），从而从数据中检测单词和句子。\n模型使用添加了BatchNormal的VGG-16作为基本结构，通过添加解码器和短路连接构建了类似U-Net的模型结构，最终输出2通道的特征图。\n模型输出的特征图分别表示字符和字符之间的连接关系。region score表示当前像素为一个字符中心点的概率，affnity score表示当前像素为两个字符中间点的概率。本文使用了高斯热力图来表示字符的位置，相比使用几何形状框选，更容易表示各种形状的字符。\n数据标注的生成方式 如下，分别对每一个字符使用四边形框选，在每个框中选择上下两个三角的中心点生成新的四边形，将二维高斯热图变换填充进去得到。\n在训练过程中，由于实际的数据集只有单词级或者句子级的标注，首先使用合成的样本训练得到一个临时的模型，然后将实际数据集中的单词或者句子裁剪出来通过模型得到单词边界框，与原数据预测的结果相比计算置信度。一种可行的方法是使用字符框的个数与单词长度相比较得到置信度，作为计算目标函数时的像素权重。即 $$L = \\sum\\limits_{p} S_c(p)\\cdot(||S_r(p) - S_r^*(p)||^2_2+||S_a(p) - S_a^*(p)||^2_2)$$ 最后在预测时需要进行相应的后处理，例如使用矩形框将检测到的文本从原数据裁剪出来包括如下操作：分别设置阈值将特征图转为二值，使用连通区域标记技术从二值图中框选单词，最后选择一个矩形框将上述连通区域框选出来1。或者使用多边形折线框框选：每个字符使用相同长度的竖线表示，竖线的中点连线得到单词中线，上述竖线转至与中线垂直，以端点为多边形的顶点绘制中线的平行线。\n结果 在选择的六个数据集上，经过训练和测试，都实现了超过SOTA的效果。可以证明使用字符级的检测效果比较好。\n总结 提出了一种基于检测单字符从而实现文本检测的方法，针对数据标注比较少的情况引入了弱监督的训练方式，取得了比较好的结果。\n模型通过检测字符而不是单词，在感受野比较小的情况下具有较好的鲁棒性，但是只能针对字符相分离的语言，不能处理孟加拉语、阿拉伯语等语言。模型中只有文本检测没有文本识别，与端到端的模型相比性能受限，但是在多个数据集上都取得了非常好的结果，证明泛化能力比较强。\n可以使用opencv中提供的connectedComponents函数和minAreaRect函数等实现。 ↩︎\n","date":1603264245,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603264245,"objectID":"eeb9677457d3a0ab83395e295cc0c968","permalink":"https://yangleisx.github.io/post/paper-craft/","publishdate":"2020-10-21T15:10:45+08:00","relpermalink":"/post/paper-craft/","section":"post","summary":"论文题目：Character Region Awareness for Text Detection\n作者：Youngmin Baek, Bado Lee, Dongyoon Han, Sangdoo Yun, and Hwalsuk Lee\n会议/时间：CVPR2019\n链接：https://arxiv.org/pdf/1904.01941.pdf\n","tags":["Deep Learning","Text Detection"],"title":"【论文】Character Region Awareness for Text Detection","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文题目：Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations\n作者：Francesco Locatello, Stefan Bauer, Mario Lucic, Gunnar Rätsch, Sylvain Gelly, Bernhard Schölkopf, Olivier Bachem\n会议/时间：ICML2019\n链接：https://arxiv.org/pdf/1811.12359.pdf\n论文目标 近年来关于disentangled representation 的unsupervised learning相关的研究非常多，其核心观点为现实世界中的数据是通过一些单独的可解释的元素生成的，可以通过无监督学习的方式学习到数据的一种表示。本文通过理论分析，证明在模型和数据不添加归纳偏置的情况下这种无监督学习是不可能实现的，同时文中在多个数据集上训练了近年来的相关模型。最终提出了进一步研究的方向。\n相关工作 目前效果比较好的模型大多是基于变分自编码器（Variational Autoencoder，VAE），即认为现实世界中的数据来源于一个高维隐变量$z \\sim P(z)$，实际观察到的数据为$x$，通过建立一个自编码器，包括编码器和解码器学习得到$P(x|z)$和$Q(z|x)$，其中使用$Q(z|x)$近似实际的$P(z|x)$，从而从数据$x$中学到一个表示$r(x)$去寻找隐变量$z$。\n这一领域之前的研究包括独立成分分析（Independent Component Analysis，ICA）等。\n本文思路/解决方案 给定如下的理论\nFor $d \u0026gt; 1$ , let $z \\sim P$ denote any distribution which admits a density $p(z) = \\prod_{i=1}^{d}p(z_i)$. Then, there exists an infinite family of bijective functions f : supp(z) → supp(z) such that $\\frac {\\partial f_i(u)}{\\partial u_j}$ almost everywhere for all $i$ and $j$ (i.e., $z$ and $f(z)$ are completely entangled) and $P(z \\leq u) = P(f(z) \\leq u)$ for all $u \\in supp(z)$ (i.e., they have the same marginal distribution).\n可以得到，对于给定的数据$x$，可以找到无限多的$p(z)$满足要求，且这些$p(z)$相互等价并满足disentangled的要求，一个无监督的模型难以区分这些$p(z)$。因此在实际的模型中，需要为模型结构和数据集引入合理的归纳偏置（inductive bias）。\n在实验设计中，使用到的模型为添加了正则项的VAE，包括betaVAE、AnnealedVAE、FactorVAE、beta-TCVAE、DIP-VAE等。在模型的度量标准中，使用了包括BetaVAE Metric、FactorVAE Metric、MIG(Mutual Information Gap)、Modularity、SAP Score等方法。使用到的数据集包括四个3D空间变化的数据集和三个随机的噪声数据集。\n在归纳偏置中，为了控制变量，对于所有的模型使用相同的卷积结构、优化算法、超参数，使用相同的Gaussian Encoder和Bernoulli Decoder，使用相同的隐变量维度（=10），构建模型进行测试。仅使用不同的正则项和不同的正则项权重。\n结果 当正则化系数增大时，使用拟合高斯的采样得到的相关性减小，使用均值表示的相关性增大。可以证明上述模型可以得到不同维度相关性比较弱的聚合先验，但是并不能表示均值表示也是不相关的。 在不同的性能度量中，除了Modularity以外的几种都是相关的，只是在不同的数据集上的相关性有差异。 模型的性能受到随机初始化和超参数的影响比较大，目标函数在其中影响比较小。 如何选择无监督模型仍然等待得到解决。在不同数据集和度量指标之间的超参数迁移用处不大。 实验并不能证明这些disentangled表示对于下游的任务有所帮助。 总结 在将来的研究中可以将重点更多放在如下三个方面：1）归纳偏置和显/隐性监督，2）disentangled representation的实际效益，3）实验设置和数据集的多样性。\n","date":1603202786,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603202786,"objectID":"7df17f20cd11da5291e355036f7fe748","permalink":"https://yangleisx.github.io/post/paper-challenge-disentabgle/","publishdate":"2020-10-20T22:06:26+08:00","relpermalink":"/post/paper-challenge-disentabgle/","section":"post","summary":"论文题目：Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations\n作者：Francesco Locatello, Stefan Bauer, Mario Lucic, Gunnar Rätsch, Sylvain Gelly, Bernhard Schölkopf, Olivier Bachem\n会议/时间：ICML2019\n链接：https://arxiv.org/pdf/1811.12359.pdf\n","tags":["Deep Learning","Auto Encoder","Disentangled Learning"],"title":"【论文】Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文题目：Non-local Neural Networks\n作者：Xiaolong Wang, Ross Girshick, Abhinav Gupta, Kaiming He\n会议/时间：CVPR2018\n链接：https://arxiv.org/abs/1711.07971\n论文目标 当前的CNN或者RNN结构中的卷积等操作都是针对数据中的一个小区域（local neighborhood）处理和提取特征，并没有考虑到数据中的长期/远距离依赖关系。因此设计一个non-local操作，可以考虑到输入数据中的每一个位置上的特征和依赖关系，学习到全局信息。\n相关工作 在CNN中通过多次卷积扩大感受野，在RNN中通过设计迭代模型学习到序列中的远距离特征/信息，但是在实际的每一次处理过程中都只考虑到局部的信息。通过重复处理局部信息获得全局信息不仅计算效率低，而且引入了优化的困难。\n参考了传统的CV领域使用的non-local mean operation方法。其他相关的内容包括Graphical models、Feedforward modeling for sequences、self-attention、interaction networks、video classification architectures等。实际上self-attention可以看作是non-local的一种情况。\n本文思路/解决方案 通过考虑特征图中每一个位置的加权和来得到特定位置的响应。\n一方面可以直接学习到数据中远距离的信息，另一方面使用较浅层的网络也能实现比较好的结果，而且作者设计的non-local模块不改变数据的大小，可以方便的插在现有的网络中。\n简单来说，non-local的思路如下，其中$x_i$为输出位置，$x_j$为数据中的每一个点，使用$f(x_i,x_j)$计算两者之间的关系并作为权重计算输入数据特征$g(x)$的加权和。 $$ y_i = \\frac{1}{C(x)}\\sum\\limits_{\\forall j}f(x_i, x_j)g(x_j) $$ 在实际使用过程中，函数$f(\\cdot)$和$g(\\cdot)$有多种选择。后者常选用$1\\times1\\times1$的卷积实现。\nFunction Type Pairwise Function Gaussian $f(x_i,x_j) = e^{x_i^T x_j}$ Embedded Gaussian $f(x_i, x_j) =e^{\\theta(x_i)^T\\phi(x_j)}$ Dot product $f(x_i,x_j) = \\theta(x_i)^T\\phi(x_j)$ Concatenation $f(x_i, x_j) = ReLU(w_f^T[\\theta(x_i),\\phi(x_j)])$\n其中$[\\cdot, \\cdot]$表示连接得向量并经$w_f$变成标量 通过将non-local block定义为残差结构，使得模块输出的形状不发生变化，可以将non-local block插入到已有的预训练模型中，而不改变其性能（$W_z$初始化为0）。通过在较高的特征层加入该block，同时引入降采样，可以减小引入的计算量。 $$ z_i = W_z y_i + x_i $$\n结果 经过测试，添加了non-local block的模型具有更高的预测准确率，在non-local block中选择不同的函数计算数据之间的距离（即$f(x_i,x_j)$）对于最后的模型效果影响不大。而且在模型中添加了时空维度上的nonn-local block后效果相比单纯的时间或空间维度的效果更好。\n总结 提出了一种non-local的结构学习数据中距离比较远的特征的影响。并且实现了一种non-local block可以插入到现有的网络结构中并提升其性能。\n","date":1602396845,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602396845,"objectID":"cbcfa7d275d0f3e06a46c49d26138f3a","permalink":"https://yangleisx.github.io/post/paper-non-local/","publishdate":"2020-10-11T14:14:05+08:00","relpermalink":"/post/paper-non-local/","section":"post","summary":"论文题目：Non-local Neural Networks\n作者：Xiaolong Wang, Ross Girshick, Abhinav Gupta, Kaiming He\n会议/时间：CVPR2018\n链接：https://arxiv.org/abs/1711.07971\n","tags":["Deep Learning","Computer Vision"],"title":"【论文】Non-local Neural Networks","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文题目：Feature Extraction for Visual Speaker Authentication against Computer-Generated Video Attacks\n作者：Jun Ma, Shilin Wang, Senior Member, IEEE, Aixin Zhang and Alan Wee-Chung Liew\n会议/时间：IEEE ICIP 2020\n论文目标 使用唇语特征进行身份认证具有一定的活体检测能力，但是容易受到使用DeepFake等技术构建的视频攻击，因此构建一个神经网络从视频中提取动态的说话习惯信息，同时尽量减少唇语特征身份认证对于唇部静态特征的依赖。\n相关工作 之前的工作中他人使用了唇部的图像和运动特征、纹理描述符等方式实现了比较不错的结果。作者所在 团队之前的工作中使用3D残差单元实现了唇部动态和静态特征的提取。\n近来使用DeepFake换脸技术可以很容易伪造讲话视频，甚至可以在单照片的数据集上实现。使用唇部特征的认证系统由于过多依赖静态特征，受到一定的威胁。\n本文提出的网络结构的基础包括frame difference、self-attention、non-local neural network1等。\n本文思路/解决方案 构建了一个深度神经网络结构提取用户唇部特征用于认证。包括两个模块：Difference block（Diff-block）和Dynamic Response block（DR-block）两者相互补用于提取用户动态讲话特征信息。\nDiff-block 给定长度为T帧的视频，通过计算每一帧图像与其他T-1帧图像的相关性来消除静态特征。\n$$ Y_t = \\sum\\limits_{t\\neq j}f(x_t,x_j)\\times(x_t-x_j)\\ f(x_t, x_j) = softmax(\\theta(x_t)^T\\varphi(x_j)) $$ 其中$\\theta(x_t)$和$\\varphi(x_j)$为输入数据分别经由两组不同的Conv+Pool之后得到的，经过转置和相乘得到 $T*T$ 形状的张量，表示两帧数据之间的相关性。将原数据经过 D-value操作 之后得到每一帧与其他帧的差值，并按照上述操作得到的相关性矩阵加权求和得到最终的输出。\nDR-block 用于提取像素级的全局动态信息，通过计算同一空间位置上的像素在不同时间位置的差异实现。\n$$\\begin{aligned} \u0026amp;Y_{(t,h,w,c)} = \\sum\\limits_{t\\neq j}g(p(t,h,w,c),p(j,h,w,c))\\times p(j,h,w,c)\\\\ \u0026amp;g(p(t,h,w,c),p(j,h,w,c)) = softmax(|p(t,h,w,c)-p(j,h,w,c)|) \\end{aligned}$$ 其中$g(p(t,h,w,c),p(j,h,w,c))$计算相同空间位置不同时间位置的像素差异。原数据首先经过 D_value操作 和softmax后得到了像素值的差异。原数据经过 Select-T操作 提取到特征，按照上述操作得到的差异矩阵加权求和得到了最终的输出。\nDEA_Net 在上述两个处理单元的基础上得到了Dynamic Enhances Authentication Network（DEA_Net）用于分类任务。\n结果 使用GRID数据集用于模型的评估和测试，使用Faceswap工具生成攻击视频。经过测试，本文提出的模型与SOTA模型相比拥有更低的FAR和HTER，取得了比较好的结果。可以证明Diff-block和DR-block结合能够有效的消除数据中的静态特征，更好的对抗换脸攻击。\n总结 提出了两个网络单元用于消除数据中的静态特征，提取动态特征用于识别和认证。 使用了non-local neural network的结构，增大了感知域，使得浅层网络可以学习到更多的全局信息。 X.L. Wang, R. Girshick, A. Gupta, and K.M. He, “Non-local neural networks,” Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 7794-7803, 2018. ↩︎\n","date":1602145117,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602145117,"objectID":"84637fedc9b7f780fe721858ed854a88","permalink":"https://yangleisx.github.io/post/paper-deanet/","publishdate":"2020-10-08T16:18:37+08:00","relpermalink":"/post/paper-deanet/","section":"post","summary":"论文题目：Feature Extraction for Visual Speaker Authentication against Computer-Generated Video Attacks\n作者：Jun Ma, Shilin Wang, Senior Member, IEEE, Aixin Zhang and Alan Wee-Chung Liew\n会议/时间：IEEE ICIP 2020\n","tags":["Deep Learning","Computer Vision"],"title":"【论文】Feature Extraction for Visual Speaker Authentication against Computer-Generated Video Attacks","type":"post"},{"authors":["Lei Yang"],"categories":["基础知识"],"content":"说实话查了一些资料还不是很清楚，大概给出一个简单的理解。\nGNU Compiler Collection(GCC)是GNU推出的一套开源编译工具链。包括了make，sed，Emacs，glibc，gdb和gcc等工具，和Linux内核共同构成一套系统。支持C、C++、Obj-C、Fortran、Ada、Go等语言。\nClang/LLVM是一套编译工具链，受到Apple的支持。包括中间语言LLVMIR，调试器，LLVMC++标准库，静态分析工具等。近年来包括Swift、Rust等都在使用LLVM作为编译框架。Clang是Apple开发用来取代GCC的前端编译器，与LLVM兼容性更好。\nVisual C++是微软的一套编译工具链，在Linux平台的支持比较差。\nMinGW(Minimalist GNU for Windows)是一个工具集，在Windows上提供了GNU下的多种工具，包括了GCC等。编译得到的结果运行在Windows系统之上。\nCygwin是位于Windows系统下的POSIX环境。在Windows上提供了Unix\\Linux命令的执行支持环境。将Linux环境的程序迁移到Windows中，实际上通过dll文件在Windows系统中模拟了Linux的系统调用。\nOpenMP是跨平台的并行API，更适用于一台多核机器上的并行处理。通过在代码中添加pragma omp的指令使得编译器自动生成并行执行的代码。\nMPI(Message Passing Interface)是跨平台的并行API，适用于多个运算节点间的通信和并行处理。\nOpenACC是一个计算加速API，支持CPU/GPU结构，可以提供科学计算等各种加速功能。通过在代码中添加pragma acc的指令使得运算得到加速。\n参考资料： GCC和Clang/LLVM的比较\n","date":1601452563,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601452563,"objectID":"3fc2c5561533e146e0bf4275d45b14cc","permalink":"https://yangleisx.github.io/post/toolchain/","publishdate":"2020-09-30T15:56:03+08:00","relpermalink":"/post/toolchain/","section":"post","summary":"说实话查了一些资料还不是很清楚，大概给出一个简单的理解。\n","tags":["C/C++"],"title":"GNU、Clang/LLVM到底是些什么东西","type":"post"},{"authors":["Lei Yang"],"categories":["实用工具","基础知识"],"content":"简单了解了一下gdb的用法。 在已经了解lldb的基础上，再看gdb的用法就简单多了，大部分的操作都是基本一致的。\n编译部分 a. 使用-g选项编译支持调试 导入可执行文件 a. 在开启gdb时指定 b. 或者使用file指令导入 运行可执行文件 a. 使用run开始运行 b. 使用continue继续运行到下一个断点 c. 使用step运行一行（进入函数） d. 使用next运行一行 添加断点 a. 使用break file.c:6在指定文件的指定行添加断点 b. 使用break func在指定函数添加断点 c. 使用info breakpoints显示断点信息 d. 使用delete b_id删除指定断点 添加观察点 a. 观察点在变量值改变时中断程序并显示数据 b. watch var_name为指定变量添加观察点 查看数据 a. 使用print打印变量的值 b. 使用backtrace查看跟踪栈 条件断点： a. 仅在满足某些条件时触发 b. break main.c:6 if I \u0026gt;= ARRAYSIZE ","date":1601451874,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601451874,"objectID":"fd7155cfdb203dd34ae05a2082196baa","permalink":"https://yangleisx.github.io/post/gdb-base/","publishdate":"2020-09-30T15:44:34+08:00","relpermalink":"/post/gdb-base/","section":"post","summary":"简单了解了一下gdb的用法。 在已经了解lldb的基础上，再看gdb的用法就简单多了，大部分的操作都是基本一致的。\n","tags":["C/C++"],"title":"GDB简单用法","type":"post"},{"authors":["Lei Yang"],"categories":["实用工具","基础知识"],"content":"LLDB是一种C/C++程序的调试器工具，可以监控程序的变量值和堆栈的变化情况。在没有IDE情况下调试程序非常实用。网上找到的资料大多都是help信息的简单翻译，要想熟练使用还得经常练习。\n一次执行过程 测试代码 代码功能为获得C语言字符串的长度。\n#include \u0026lt;stdio.h\u0026gt; size_t strlen(const char *s) { const char *sc; for (sc = s; *sc != \u0026#39;\\0\u0026#39;; ++sc) {} return sc - s; } int main() { char str[] = \u0026#34;Hello World, I\u0026#39;m R2-D2.\u0026#34;; int length = strlen(str); printf(\u0026#34;The length of str is %d\\n\u0026#34;, length); return 0; } 编译过程 注意在编译过程中使用-g编译指令支持调试器的工作。\nCC = gcc CFLAGS = -g -std=c11 -Wall SOURCE = test.c OBJECT = $(SOURCE: .c=.o) main: $(OBJECT) $(CC) $(CFLAGS) $(OBJECT) -o $@ clear: rm *.o 基本流程 # 开启调试器 $ lldb main # 或者使用lldb开启调试器 使用file命令导入文件 # # 在指定文件指定行添加断点 (lldb) b test.c:11 # breakpoint set --file test.c --line 11 # breakpoint set -f test.c -l 11 # # 开始运行 (lldb) r # run # # 查看当前函数和调用关系 (lldb) bt # backtrace # # 查看本地变量(当前堆栈帧) (lldb) frame variable # # 步进和运行 (lldb) next (lldb) continue 常用的指令 断点操作 # 在指定文件指定行添加断点 (lldb) b test.c:11 # breakpoint set --file test.c --line 11 # breakpoint set -f test.c -l 11 # 为指定函数添加断点 (lldb) breakpoint set --name strlen # 查看断点 (lldb) breakpoint list # 设置断点命令 即触发断点时执行操作 1.1为断点编号 (lldb) breakpoint command add 1.1 启动和运行操作 # 开始运行 在断点停止 (lldb) r # run # 继续运行 下一个断点停止 (lldb) c # continue # 步进操作 运行下一行 (lldb) n # next # 进入当前行函数 (lldb) step 查看操作 # 查看跟踪栈 即函数调用关系 (lldb) bt # backtrace # 查看栈帧 即局部变量 (lldb) frame variable [variable_name] # 选择栈帧 9为栈帧标号 (lldb) frame select 9 线程操作 上述各种操作在多线程的环境中都可以对某一个线程进行操作\n(lldb) thread backtrace (lldb) thread list # 运行直到12行 (lldb) thread until 12 数据操作 # 修改程序中a的值 (lldb) exp a = 10 参考资料：\nLLDB TUTORIAL\nLLDB调试器的使用\nLLDB 十分钟快速教程\nLLDB使用\n","date":1601089976,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601089976,"objectID":"942de1b46d42f7aababfe7eb67ca802e","permalink":"https://yangleisx.github.io/post/lldb-base/","publishdate":"2020-09-26T11:12:56+08:00","relpermalink":"/post/lldb-base/","section":"post","summary":"LLDB是一种C/C++程序的调试器工具，可以监控程序的变量值和堆栈的变化情况。在没有IDE情况下调试程序非常实用。网上找到的资料大多都是help信息的简单翻译，要想熟练使用还得经常练习。\n","tags":["MacOS","C/C++"],"title":"LLDB的简单使用","type":"post"},{"authors":[],"categories":["实用工具"],"content":"最近抽空整理了一下电脑里面装了一些什么软件，毕竟没有备份，如果机器出了什么问题，重新装机时候也有个参考，另一个原因也算是推荐一些好用的小工具吧。 从Mac选手换到Windows刚开始有点不适应，大半年过去了现在觉得习惯了还挺方便的。\n办公软件 Adobe Acrobat DC PDF 阅读和编辑工具 Microsoft Office（Word、Powerpoint、Excel） 办公套件 Microsoft OneDrive 微软云盘 Typora Markdown 编辑器 编程相关 MinGW C/C++ 编译环境 Anaconda Python 包管理环境 Java（JDK） Java 开发环境 Clion 用于C/C++ 的IDE IntelliJ IDEA 用于Java 的IDE PyCharm 用于Python 的IDE Qt（Qt Creator） 开发Qt 程序的IDE 和环境 MATLAB 数学处理程序 Microsoft Visual Studio 宇宙第一IDE(maybe) Microsoft Visual Studio Code 后期比较常用的编辑器 VMware Workstation 虚拟机管理软件 Wireshark 抓包和网络分析工具 texlive LaTeX 编译环境 Windows Terminal Preview Windows 原生终端 Windows Subsystem for Linux（Ubuntu） Windows 子系统 WinSCP 可视化的SCP 文件传输工具 Git 代码管理工具 gVim 编辑器 Scoop Windows 环境的包管理工具 其他工具 Motrix 一个开源的下载器 ShareX 截图工具 Wox 文件搜索和启动器(结合Everything 使用) Everything 文件搜索工具 PowerToys 微软官方提供的一套工具 Stardock Fences 桌面图标管理工具 GeekUninstaller 非常好用的卸载工具 RealTemp 实时温度检测工具 SysinternalsSuite 微软官方的系统管理工具 Microsoft To Do 日程和待办清单管理 QuickLook 空格键预览工具 FileZilla FTP 文件传输工具 欧陆词典 非常好用的词典 PotPlayer 一个比较好用的播放器 ","date":1599920228,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599920228,"objectID":"4a472c9fed21bd69eacb406dffa2ab13","permalink":"https://yangleisx.github.io/post/windows-software-list/","publishdate":"2020-09-12T22:17:08+08:00","relpermalink":"/post/windows-software-list/","section":"post","summary":"最近抽空整理了一下电脑里面装了一些什么软件，毕竟没有备份，如果机器出了什么问题，重新装机时候也有个参考，另一个原因也算是推荐一些好用的小工具吧。 从Mac选手换到Windows刚开始有点不适应，大半年过去了现在觉得习惯了还挺方便的。\n","tags":[],"title":"Windows电脑上一些好用的软件","type":"post"},{"authors":null,"categories":null,"content":"2020年8月, 参赛作品\u0026lt;基于唇语特征的活体身份认证系统\u0026gt;获得第十三届全国大学生信息安全竞赛一等奖.\n","date":1598572800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598572800,"objectID":"0c41ccd18c958a98f8d44353fd33368b","permalink":"https://yangleisx.github.io/project/infosec-competition/","publishdate":"2020-08-28T00:00:00Z","relpermalink":"/project/infosec-competition/","section":"project","summary":"2020年8月, 参赛作品\u003c基于唇语特征的活体身份认证系统\u003e获得第十三届全国大学生信息安全竞赛一等奖.","tags":["Visual Speaker Authentication"],"title":"第十三届全国大学生信息安全竞赛一等奖","type":"project"},{"authors":["Lei Yang"],"categories":["基础知识"],"content":"三小时女娲补天网安概论\n0x01网络信息安全发展历史 网络信息安全历史： 通信保密阶段：COMSEC，20世纪20-60年代，主要解决发方和收方的信息源编码（Source Coding）、信道编码和传输（Channel Coding）、通信协议和密码的问题。 信息安全阶段：INFOSEC，20世纪80-90年代，主要目标为保密性Confidential、完整性Integrity、可用性Availability。包括TCSEC橙皮书和ITSEC白皮书。 信息保障阶段：IA，20世纪90年代至今，主要为为从整体角度考虑其体系建设的信息保障(Information Assurance)阶段，代表是美国的IATF规范。 网络空间安全：2010年后 信息安全的基本特征： 相对性 时效性 安全攻击源和防范对象的不确定性 反传统的技术思维和复杂的人-机关系 相关性 信息结构的高度脆弱性和风险性 动态性 0x02计算机网络 OSI七层模型\n应用层Application Layer，表示层Presentation Layer，会话层Session Layer，传输层Transport Layer，网络层Network Layer，数据链路层DataLink Layer，物理层Physical Layer\nTCP/IP协议栈\n应用层，传输层，网络层，网络接口层\n五层参考模型\n应用层，传输层，网络层，数据链路层，物理层\n相关概念\nMAC地址 IP地址、端口号、套接字Socket TCP vs. UDP 域名解析 网络工具\nping使用ICMP检查目标IP是否可达 ipconfig/ifconfig查看网络配置信息 netstat查看网络连接状态 arp查看ARP缓存信息 0x03安全基础 信息安全的定义：信息安全是防止对知识、事实、数据或能力的非授权使用、误用、篡改或拒绝使用所采取的措施。 完整的定义：指在既定的安全密级条件下，信 息系统通过预警、保护、检测、响应、恢复和反击机制，抵 御意外事件或恶意行为攻击，确保信息系统避免非授权的访 问、破坏或者服务中断，实现信息和资源的保密性、完整性、 可用性、非否认性和可控性的能力。 三要素： 机密性Confidential：不被截获和未授权使用 完整性Integrity：内容真实可信、不被冒充伪造和篡改 可用性Availability：信息和信息服务被授权人正常使用 其他属性： 不可否认性No-Repudiation：行为的不可否认 可控性Controllability：验证Authentication和审计Accountability 可存活性Survivability：在攻击和错误情况下继续提供服务 安全攻击 中断Interruption：破坏了可用性 修改Modification：破坏了完整性 伪造Fabrication：破坏了真实性 截取Interception：破坏机密性 安全服务 认证Authentication：提供实体的身份保证 访问控制Access Control：授权资源访问 机密性服务Confidential：信息不泄露和暴露 完整性服务Integrity：数据的价值和存在性没有改变 不可抵赖服务 安全机制：安全服务的实现 加密机制 数字签名 访问控制 数据完整性 通信业务流填充 路由控制 认证交换 公证机制 0x04威胁和攻击技术 安全问题的根源： 物理安全因素：设备本身的问题、环境的安全 方案设计因素：安全策略不合理、安全配置不当、设计需要牺牲安全机制 系统安全因素：操作系统和网络软件等的漏洞和后门 TCP/IP协议的安全因素：设计之初没有考虑安全问题 人的因素：无意的失误和错误、恶意攻击 攻击技术： 被动攻击：窃听和监视数据传输，不对数据进行修改，难以检测，重在预防 嗅探sniff 分析 主动攻击：数据流的篡改和错误数据的添加，能够检测，难以防止 假冒fabrication 重放replay 篡改modification 攻击过程 预攻击pre-attack：搜集信息，域名、IP、拓扑、OS、端口、服务 攻击attack：远程权限、接入、本地权限、提权、攻击 后攻击post-attack：植入木马、删除日志、进一步渗透 攻击手段： 网络监听sniff：监听网络状态和数据流 密码破解crack：字典攻击、暴力破解 会话劫持session hijack：”中间人攻击“ 缓冲区溢出buffer overflow：输入数据规模超过了给定缓冲区的大小 拒绝服务攻击DoS：消耗目标资源使其无法为正常用户提供服务 病毒和蠕虫worm：自我复制和传播，利用漏洞传播 木马trojan：隐蔽运行，远程控制和信息窃取 SQL注入SQL insert：访问数据库的动态网页 APT攻击： 高级可持续性攻击：Advanced Persistent Threat 攻击路径：网络欺诈和0day攻击——找到漏洞——感染内部人员——获取数据 0x05网络信息安全模型 网络通信模型： 包括：消息的安全转换、通信主体共享的秘密信息（密钥）、可信第三方trusted third party。 消息经过安全转换后经由信道传输。其中的安全转换通过该秘密信息指导。 访问安全模型： 外部安全：阻止非授权用户 内部安全：内部安全控制 P2DR模型： 安全策略Policy、防护Protection、检测Detection、响应Response 基于时间的安全理论，通过每一个行为消耗的时间衡量安全能力 暴露时间E = 检测时间 + 响应时间 - 攻击时间。攻击时间越短、响应时间越长，则暴露时间越长，系统越危险。当暴露时间小于0，可以认为系统是安全的。 系统安全 = 风险分析 + 安全策略 + 系统防护 + 实时监测 + 实时响应 + 灾难恢复，其中外围五个因素都收到了系统安全策略的影响。 信息技术安全评估准则： TCSEC桔皮书：A、B3、B2、B1、C2、C1、D INSEC桔皮书的进一步发展 0x06密码学技术 密码学发展：手工阶段、机器阶段、现代密码学 基本概念： Cryptology、Cryptography、Cryptanalysis 加密Encryption、解密Decryption 无条件安全Unconditionally Security、计算安全Computationally Security 编码原则：加密算法建立在算法的公开不影响铭文和密钥的安全 古典密码：古典替换（substitution，替换明文）、古典置换（permutation/transportation，改变明文字符的位置） 密码分析方式： 唯密文攻击：只有密文串和加密算法，利用统计方式分析 已知明文攻击：具有明文密文和加密算法，推导密钥 自适应选择明文攻击：攻击者选择明文并得到对应的密文 选择密文攻击：攻击者选择密文兵构造对应的明文 选择文本攻击 典型攻击方式： 暴力攻击Brute Force：穷举法、字典攻击 数学方式：差分攻击（明文插值对密文插值的影响）、线性密码、插值攻击 密钥相关攻击 对称密钥体系： 分组密码：明文和密文分组，相同密钥和明文能得到相同密文 序列密码：流密码，按bit加密 分组密码原理： 明文消息编码得到的序列分组，在密钥控制下变换成等长的输出序列 混乱原则：Confusion，即使用替换法Substitution，S-box。防止利用明文和密文的依赖关系破解。 扩散原则：Diffusion，即使用置换法Permutation，P-box。密钥的每位数字影响密文的多个数字，明文的每位数字影像密文的多个数字。 Feistel加密结构：多轮迭代、使用动态子密钥 数据加密标准DES： 56bit的密钥加密64bit的明文分组 16轮迭代 double-DES、triple-DES 高级加密标准AES： 明文分组为16字节128bit 10轮迭代，但是不是Feistel结构 随机数： 特性：不可预料性、统计独立性 生成方法：自然随机数源，随机数生成函数，通常只能生成伪随机数序列 流密码： 原理：一次一密的密码体制绝对安全。 使用种子密钥生成密钥序列，利用密钥序列一次加密明文的一个或几个比特 硬件实现简单 公开算法包括RC4算法 分组密码模式： ECB电子密码本：每一个分组使用相同的密钥 CBC分组链接：当前明文段与上一密文段异或处理后进行加密 CFB密码反馈：将分组密码转为流密码 CTR计数器：计数器加密后与明文异或后进行加密 0x07公钥密码技术 消息认证： 验证发送者的身份（真实性），验证信息完整性 常规方式：共享密钥、序列号、时间戳、错误检测码 非加密方式：报文鉴别码、单向散列函数 消息认证码MAC： 使用密钥，从消息中生成数据，成为MAC或密码校验和（cryptographic checksum） 通信双方使用相同的密钥计算MAC并验证，保证了完整性和真实性 信息摘要/哈希/散列函数： 变长输入压缩到定长的输出，输入改变后输出变化很大。 MAC计算速度慢，需要密钥，但是计算信息摘要不需要密钥，只能验证完整性 特点：单向性、抗碰撞性 安全问题：密码分析法（分析算法缺陷）、穷举攻击 典型散列算法： MD5：明文补全为512bit的组，生成128bit的摘要，已经被证明了不安全可以破解。 SHA：明文补全为512bit的组，生成160bit的摘要，记录在5个32bit的数据中。 HMAC：使用散列函数实现的MAC，使用密钥参与哈希过程 公钥密码思想： 公钥公开，私钥保密，私钥可导出公钥，公钥难以计算私钥。 公私钥的生成利用了单向陷门函数，即容易计算但难以求逆，给定陷门后易于求逆。 常用数学难题：大整数因子分解，有限域上乘法群的离散对数问题，椭圆曲线离散对数问题。 RSA机制： 利用大整数因子分解难题 给定素数p、q，公开其乘积n，选择e与$\\varphi(n)$互素，计算$d=e^{-1}mod\\ \\varphi(n)$。 给定私钥p和q和d，计算公钥e和n比较简单，但是逆运算非常难。 Diffie-Hellman密钥交换： 用户事先共享a和p 用户选择随机数$X_A$和$X_B$ 计算$Y_A = a^{X_A}mod\\ p$和$Y_B = a^{X_B} mod\\ p$并交换 计算$K = Y_B^{X_A} mod\\ p= Y_A^{X_A}mod\\ p$。 容易被中间人攻击 椭圆曲线机制ECC，相比RSA在较短的密钥提供了更高的安全性。 对称和非对称加密 对称加密：速度快，密钥短但是管理困难 非对称加密：密钥管理简单，可以数字签名，速度慢 数字签名技术： 同时保护信息完整性和信息发送者的身份确认 原理：数字信息经过散列函数计算摘要，使用私钥加密信息摘要并作为信息的一部分。使用公钥解密得到摘要并检查信息的完整性。 0x08密钥分发和用户认证 密码管理处理密码产生到销毁过程中的各个问题，包括初始化、产生、存储、分配、停用、更新、销毁。 密钥生产形式：密钥管理中心集中生产（有边界生产），个人生成（无边界生产） 密钥分配：自动分配机制减轻负担，同时尽量减小密钥量 对称密码体制： 一方选择密钥，通过安全方式传递给另一方 可信第三方选定，安全方式传递给双方 使用旧密钥加密新密钥传输 可信第三方的加密分发：设立KDC(Key Distribution Center)使用永久密钥加密传输会话密钥，会话密钥用于加密会话内容，一次一密。 分布式环境认证： 一组工作站和一组分布式服务器组成 工作站可以保证用户认证，客户端向服务器验证，客户端和服务器的双向验证 Kerberos：提供两个密钥TGT和ST，用户向DC验证身份得到TGT，访问服务时通过TGT得到ST，使用ST与服务器加密传输并验证身份。 kerberos保存有用户的ID和密钥散列，同时与每一个应用服务器共享一个保密密钥。 一个kerberos环境包括kerberos服务器、应用服务器和工作站。实际上存在跨环境的访问，此时需要不同环境的Kerberos服务器之间共享一 …","date":1594954901,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594954901,"objectID":"4ec932c7cfc24fe5faaf94e63189c7d6","permalink":"https://yangleisx.github.io/post/intro-cyber-sec/","publishdate":"2020-07-17T11:01:41+08:00","relpermalink":"/post/intro-cyber-sec/","section":"post","summary":"三小时女娲补天网安概论\n","tags":["Hexo","OpenSSL","HTTPS","SSH","Socket","Trojan"],"title":"网络安全概论","type":"post"},{"authors":["Lei Yang"],"categories":["实用工具"],"content":"简单整理Windows安全课堂上讲解和提及的各种安全工具。\nCMD 命令 ver：查看内核版本。\nsysteminfo：查看系统信息，包括版本，补丁等大量信息。\nset：查看所有的环境变量。\nsc：查询服务信息。\nsc query [service name] 查询状态 sc qc [service name] 查询配置 sc start [service name] 启动需要手动启动的服务/驱动 sc stop [service name] 停止服务 sc showsid [service name] 查看服务的SID attrib：修改文件属性\n例如隐藏文件：添加hidden和system属性\n\u0026gt; attrib +h +s file-name whoami：显示域名和用户名（没有加入域时，显示主机名）。\nwhoami /user显示用户名和SID whoami /all显示详细信息（特权、权限、所属组等） whoami /all 显示详细的用户访问控制令牌信息 hostname：查看主机名称\nnet：用户和用户组操作\nnet user [username] 查看用户信息 net user [username] /add 添加新的用户 net user [username] [password] /add添加用户 net user [username] /del net localgroup [groupname] [username] /add 用户加入本地组 makecab：压缩工具\nwusa：补丁安装命令\nnetstat：查看网络连接信息，各种参数参见help信息\nreg：注册表管理工具\nreg save [hkey] [filename] 将注册表导出到文件中 cacls：查看客体的安全访问控制项ACE\n系统工具（cmd+R） regedit：（Registry Editer）注册表查看和编辑。 services.msc：服务控制面板（位于控制面板-系统和安全-管理工具-服务），查看和管理系统服务（只能看到用户态服务）。 secpol.msc：（Security Policy）本地安全策略配置。 syskey：SAM锁定工具，可以将密码存入本地或软盘。 msinfo32.exe：查看所有加载的驱动程序。 control：控制面板 eventvwr：（Event Viewer）审计日志查看器 certmgr.msc：（Certificate Manager）证书管理工具 其他工具 PE文件查看器：\nPE Explorer。 Stud_PE。 PEiD：可以看到加壳工具和编译工具。 DarkRemoteRAT：一个木马软件\nAgony：一个RootKit代码演示工具\nagony -p [进程名] 隐藏进程 agony -f [文件名] 隐藏文件/文件夹 SystInternalsSuite工具集：\nautoruns：查看自启动项（注册表，自启动目录，服务，计划程序等） procexp（process explorer）：查看进程信息（父子进程关系，进程加载的DLL和句柄列表，访问控制令牌，DEP，ASLR，完整性级别，虚拟化等，包括svchost内部的具体服务，进程的网络连接信息） tcpview：查看网络连接、端口、数据等 procmon（process monitor）：检查和记录进程的各种操作 PsGetSid：查看用户的SID（默认显示主机SID） psexec：运行程序 使用-s参数可以使用SYSTEM权限运行程序 使用-l参数可以使用Low完整性级别运行程序 procdump：进程内存导出工具 AccessChk：查看主客体对象的完整性级别 Strings：二进制代码的明文字符串查找 RootKit/BootKit检测工具\nXueTr（XT）：一个RootKit检测查看工具 PowerTool（PT）：可以检测到Bootkit和Rootkit IceSword：不再更新，经典 RootkitUnhooker（RKU） Kaspersky TDSSKiller：可以检测到Bootkit和Rootkit OSR Driver Loader：一个向系统加载驱动的工具。\nnc：一个常见的网络监控和通信工具。“网络的瑞士军刀”\nwireshark：一个开源的网络数据包分析软件。\n沙箱工具（用于动态分析）：\nSSM沙箱：System Safety Monitor，给系统函数加hook Cuckoo：开源的沙箱，使用最多 Anubis沙箱 Norman沙箱 GFI沙箱 OllyDbg：一个常见的动态分析调试工具。\n静态分析工具：\nIDA Pro：高级分析工具 Depends：查看链接库，导入导出表 Dependancy Walker 明文字符串查找：\nBinText：查看明文字符串，包括函数名等 Strings 加壳识别和脱壳：\nVMUnpacker UPX：可以加壳和脱壳 UnPEPack ASPack unpacker 文件格式识别：\nPEid：检查是否加壳，检测编译工具 FileAnalyzer 反病毒引擎扫描：\nVirusScan VirusTool mimikatz：一个获得登陆用户明文密码的工具\nwinhex：二进制读写工具，直接操纵硬盘而不是使用WinAPI\nSAMINside：SAM文件解析和读取工具\n本地密码破解工具：\nL0phtCrack SAMInside Ophcrack Windows本地密码散列导出工具：\nPwdump wce：Windows密码凭证编辑器 gsecdump copypwd QuarksPwDump 提取登录用户明文密码：\nwce：Windows密码凭证编辑器 mimikatz 数据恢复工具：\nEasyRecovery FinalData 参考Github项目 UACME LOLBAS BypassAntiVirus ","date":1593075651,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593075651,"objectID":"01e9a86a4cbb2cba46f217bdfa7d53e5","permalink":"https://yangleisx.github.io/post/win-sec-tool/","publishdate":"2020-06-25T17:00:51+08:00","relpermalink":"/post/win-sec-tool/","section":"post","summary":"简单整理Windows安全课堂上讲解和提及的各种安全工具。\n","tags":["Windows"],"title":"Windows安全管理工具总结","type":"post"},{"authors":[],"categories":["论文阅读"],"content":"论文题目：A Discriminative Feature Learning Approach for Deep Face Recognition\n作者：Yandong Wen, Kaipeng Zhang, Zhifeng Li, and Yu Qiao\n会议/时间：ECCV2016\n链接：原文链接\n论文目标 之前的工作中仅仅使用Softmax loss作为模型的监督信号，学到的模型具有一定判别能力(Separable)，本文通过介绍一种新的Centor Loss作为监督信号进行学习，使模型学到更具有判别能力(Discriminative)的特征。Centor Loss可以学习到一类特征的分类中心并减小类内距离，从而更具有更强的判别能力。\n相关工作 传统的度量学习(Metric Learning)中，由于识别样本在训练集中出现过，使用Softmax可以起到比较好的学习效果。但是在面识别任务中，很难预先搜集到所有可能的实体的数据用于学习，因此对于泛化能力的要求更高。这就要求学习到的特征具有更小的类内距离和更大的类间距离。\n使用contrastive loss或者triplet loss对于pair/triplet的取样要求比较高，使用精心设计的取样方法可以在一定程度上避免，但是引入了更高的计算复杂度。\n本文思路/解决方案 首先定义了centor loss函数 $$\\mathcal{L}_c = \\frac{1}{2}\\sum\\limits_{i=1}^{m}||\\mathbb{x}_i-\\mathbb{c}_{y_i}||^2_2$$ 其中 $\\mathbb{c}$表示对应的类的中心。\n直观的想法是在每一轮学习结束后将所有同类别数据的特征求均值，但是在大规模数据库中难以实现，因此采用每一批中同类别的数据的特征求均值用于类中心的更新。即令 $$\\Delta\\mathbb{c}_j = \\frac{\\sum\\limits_{i=1}^{m}\\delta(y_i=j)(\\mathbb{c}_j - \\mathbb{x}_i)}{1+\\sum\\limits_{i=1}^{m}\\delta(y_j = j)}$$ 其中 $\\delta(condition) = condition\\ is\\ true ? 1: 0$，同时引入一个超参数$\\alpha$作为类的中心更新时的“学习率”。\n完整的loss function为 $$\\mathcal{L} = \\mathcal{L}_s + \\lambda\\mathcal{L}_c$$，其中$\\lambda$为权重系数。\n网络结构如下：可以看到引入了跨层连接和Joint Supervision Signal。 训练结果如下：可以看到在引入了Center Loss之后，类间距离显著减小，判别能力增强。 结果 可以发现 $\\lambda=0$时的学习效果较差，当 $\\lambda$太大时学习效果也会下降，测试得到的参数为$\\lambda=0.03$。\n可以发现$\\alpha$的取值对结果影响不大（不为零时），测试得到的参数为$\\alpha=0.5$。\n最终实现的模型在小数据库训练，LFW达到了99.28%泛化准确率，YTF达到了94.9%的泛化准确率。\n在MegaFace数据库上测试的结果中，本文的模型均达到了更好的性能。\n总结 提出了Center Loss，使用Center Loss结合Softmax Loss实现具有判别力的模型学习。 使用了跨层连接的模型结构。 使用Joint Supervision Signal，合理选择权重超参数。 ","date":1592037710,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592037710,"objectID":"009954e27dbac948fe63774840d83820","permalink":"https://yangleisx.github.io/post/paper-center-loss/","publishdate":"2020-06-13T16:41:50+08:00","relpermalink":"/post/paper-center-loss/","section":"post","summary":"论文题目：A Discriminative Feature Learning Approach for Deep Face Recognition\n作者：Yandong Wen, Kaipeng Zhang, Zhifeng Li, and Yu Qiao\n会议/时间：ECCV2016\n链接：原文链接\n","tags":["Deep Learning","Face Recognition"],"title":"【论文】A Discriminative Feature Learning Approach for Deep Face Recognition","type":"post"},{"authors":["Lei Yang"],"categories":["代码学习"],"content":"刚开始使用Windows提供的各种API函数时，对于函数参数的类型感到非常的迷惑，实际上Windows中对于各种C++数据类型做了封装和处理，得到了一组Windows的变量类型，其中的部分字符和字符串的定义如下。\n其他的类型定义可以在具体使用时搜索查看头文件（例如#include \u0026lt;Windows.h\u0026gt;）或者MSDN。\n字符和字符串类型 变量类型 解释 定义 CHAR ANSI型字符 char WCHAT Unicode型字符 wchar_t TCHAR 自适应字符（ANSI or Unicode） 可变 LPSTR/PSTR ANSI型字符串 char* LPWSTR/PWSTR Unicode型字符串 wchar_t* LPTSTR/PTSTR 自适应字符串（ANSI or Unicode） 可变 LPCSTR/PCSTR 常量ANSI型字符串 const char* LPCWSTR/PCWSTR 常量Unicode型字符串 const wchar_t* LPCTSTR/PCTSTR 常量自适应字符串 可变 其中的前缀LP/P，可以理解为表示指针Pointer（字符串变量为字符数组的首地址指针）。\n字符串函数 绝大多数操作字符串的函数都提供了A和W两种，例如RegOpenExA()和RegOpenExW()，同时提供了自适应的版本RegOpenEx()，A为后缀的函数参数通常为ANSI型，W为后缀的函数参数通常为Unicode型，无后缀的函数使用自适应定义。\n#ifdef UNICODE #define TCHAR Wchar_t #else #define TCHAR char #endif #ifdef UNICODE #define RegOpenEx RegOpenExW #else #define RegOpenEx RegOpenExA #endif 参考MSDN\n","date":1591847254,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591847254,"objectID":"2bc1a42c1b048041b9709272496d3b19","permalink":"https://yangleisx.github.io/post/win-api-type/","publishdate":"2020-06-11T11:47:34+08:00","relpermalink":"/post/win-api-type/","section":"post","summary":"刚开始使用Windows提供的各种API函数时，对于函数参数的类型感到非常的迷惑，实际上Windows中对于各种C++数据类型做了封装和处理，得到了一组Windows的变量类型，其中的部分字符和字符串的定义如下。\n其他的类型定义可以在具体使用时搜索查看头文件（例如#include \u003cWindows.h\u003e）或者MSDN。\n","tags":["Windows","WinAPI","C/C++"],"title":"WinAPI的数据类型(字符串)","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文题目：Deep Learning Face Representation by Joint Identification-Verification\n作者：Yi Sun、 Xiaogang Wang、 Xiaoou Tang\n时间：2014\n链接：原文链接\n论文目标 在面部识别中，关键任务是提取面部特征，并增大类间距离、减小类内距离。\n相关工作 在之前的工作中，本文作者提出的DeepID使用softmax作为输出用于身份验证，达到了比较好的效果。其他诸如LDA、metric learning等方法使用线性模型或使用浅层网络，具有一定的局限性。\n本文思路/解决方案 同时使用两种supervisory signal来指导模型的学习，即同时使用identification（给定输入，判断属于哪一个类别，多分类）和verification（给定两个输入，判断是否属于同一类别，二分类），前者可以增大类间距离，后者减小类内距离。\n深度神经网络的结构与本文作者之前的工作基本相同，即包括四层卷积和三层最大池化，经过跨层连接得到长度为160的特征向量。\n使用特征网络的输出向量分别用于identification和verification，反向传播时使用超参数 $\\lambda$对两个损失函数的梯度加权。在前者使用softmax得到输出并优化cross-entropy loss。在后者使用基于L1/L2正则和cosine相似的损失函数，并对比较其效果。\n基于cosine相似:$$Verif(f_i,f_j, y_{ij}, \\theta_{ve}) = \\frac{1}{2}(y_{ij}-\\sigma(wd+b))^2$$，其中$\\sigma$为sigmoid函数，$$d = \\frac{f_i · f_j}{||f_i||_2·||f_j||_2}$$。\n基于L2的: $$Verif(f_i,f_j, y_{ij}, \\theta_{ij}) = \\begin{cases} \\frac{1}{2}||f_i - f_j||^2 \u0026amp;if\\ y_{ij}=1\\\\ \\frac{1}{2}\\max(0, m-||f_i - f_j||^2)\u0026amp;if\\ y_{ij}=-1\\end{cases}$$ ，其中 $y_{ij}$表示输入是否为同一类别，$m$为指定的边界，在训练过程中手动调整。\n训练过程中，每一张图片选择了400个patch，包括不同位置、大小、通道（RGB or 灰度），训练得到200个网络。\n测试Verification时，通过前后向贪婪算法选择其中效果最好的25个得到 $25*160=4000$维度的特征向量，并通过PCA压缩，便于识别和预测。在预测时分别使用L2 Norm模型和联合贝叶斯模型来得到结果。\n结果 对于超参数 $\\lambda$的选择，通过测试可以发现在0.05处达到最高。当 $\\lambda=0$或者 $\\lambda=+\\infty$时，据无法得到比较好的效果，说明identification和verification对于特征提取都具有重要作用。\n与DeepID中的情况相同，训练时使用的类别越多，学习效果越好。\n使用联合贝叶斯模型实现预测可以得到更高的准确率。同时在训练过程中，使用L2正则的损失函数效果更好。\n多次选择效果比较好的patch组合，使用得到的结果结合SVM进行预测，整体系统的性能达到了99.15%的识别准确率。\n总结 使用identification和verification结合的方式，合理选择权重超参数，使得学习效果进一步提升。 在verification中测试多种损失函数，最终选择了效果最好的基于L2的模型。 ","date":1591429709,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591429709,"objectID":"a85d51c3ef31aae7ab3944fe42e86c14","permalink":"https://yangleisx.github.io/post/paper-deepid2/","publishdate":"2020-06-06T15:48:29+08:00","relpermalink":"/post/paper-deepid2/","section":"post","summary":"论文题目：Deep Learning Face Representation by Joint Identification-Verification\n作者：Yi Sun、 Xiaogang Wang、 Xiaoou Tang\n时间：2014\n链接：原文链接\n","tags":["Face Recognition","Deep Learning"],"title":"【论文】Deep Learning Face Representation by Joint Identification-Verification","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文题目：FaceNet: A Unified Embedding for Face Recognition and Clustering\n作者：Florian Schroff、Dmitry Kalenichenko、James Philbin\n会议/时间：2015\n链接：原文链接\n论文目标 学习一种直接的从面部图片到欧氏空间向量的映射，用于人脸识别、分类和聚类等工作。欧氏空间向量之间的距离表示图片内人脸的相似度。\n相关工作 过去的人脸识别网络中往往通过人脸识别/分类等任务训练，最终将其中的某一层提取出来用作特征向量的生成。缺点在于泛化能力可能不够强，而且往往生成的特征向量长度比较大，效率较低。多数研究中对于较长的特征向量使用PCA简化。\n本文思路/解决方案 通过引入triplet loss和online triplet mining method，直接学习得到特征向量，具体是对于深度神经网络的输出，经过L2Norm后得到向量，并使用Triplet loss优化。本文作者使用的两种深度网络分别来自Zeiler\u0026amp;Fergus Model和Szegedy’s Inception Model，将其视作黑箱并训练。\n文中假设相同的人输入的数据分布在欧氏空间内的一个超平面，当给定一组triplet（包括锚anchor、正例positive、反例negative，其中anchor和positive是同一类）时，则有$$||f(x_i^a)-f(x_i^p)||^2_2+\\alpha \u0026lt; ||f(x_i^a)-f(x_i^n)||^2_2$$，即正例的距离与反例距离的差值不小于给定的边界值$\\alpha$。从而得到优化目标为$$triplet\\ loss = \\sum\\limits_{i}^{N}\\left[||f(x_i^a)-f(x_i^p)||^2_2+\\alpha - ||f(x_i^a)-f(x_i^n)||^2_2 \\right]_+$$。\n在训练过程中，需要选择合适的数据计算损失函数，如果选择简单的triplet会导致收敛缓慢，训练效果较差。因此在训练过程中，对于每一个给定的数据$$ x_i^a $$，选择距离最大的正例($$ \\arg\\max_{x_i^p}||f(x_i^a)-f(x_i^p)||^2_2 $$)和距离最小的反例($$ \\arg\\min||f(x_i^a)-f(x_i^n)||^2 $$)，称为hard取样。\n在实际的训练过程中，获得满足要求的triplet是不可能的，两种可行的方法包括：offline方式（每次训练N步后计算距离并选择triplet）、online方法（在每一个batch中选择满足要求的数据）。选择后者时需要注意保证每一个batch中都必须含有正例和反例。\n当在训练开始时就选择hard采样时，会导致模型进入局部最优，因此提出了semi-hard取样，即选择那些满足$$||f(x_i^a)-f(x_i^p)||^2_2 \u0026lt; ||f(x_i^a)-f(x_i^n)||^2_2$$的反例数据组成triplet进行训练。\n总结 提出了triplet loss，便于直接训练一个图像到向量的映射。 分析了选择triplet的方式，使用semi-hard策略解决hard策略的缺点。 ","date":1591429709,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591429709,"objectID":"34422f5e5fee044891c77403bc5f2c32","permalink":"https://yangleisx.github.io/post/paper-facenet/","publishdate":"2020-06-06T15:48:29+08:00","relpermalink":"/post/paper-facenet/","section":"post","summary":"论文题目：FaceNet: A Unified Embedding for Face Recognition and Clustering\n作者：Florian Schroff、Dmitry Kalenichenko、James Philbin\n会议/时间：2015\n链接：原文链接\n","tags":["Deep Learning","Face Recognition"],"title":"【论文】FaceNet: A Unified Embedding for Face Recognition and Clustering","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文题目：Deep Learning Face Representation from Predicting 10,000 Classes\n会议：CVPR2014\n作者：Yi Sun、Xiaogang Wang、 Xiaoou Tang\n链接：原文链接\n论文目标 通过深度神经网络学习高层次的图像特征并用于身份验证。\n相关工作 无限制条件下的面部识别和验证是近年来的研究热点，大多面部识别算法是通过浅层模型学习到的超完备的底层特征实现。\n本文思路/解决方案 通过深度卷积神经网络学习得到特征表示并用于面部识别。其中的特征表示通过深度神经网络的最后一层得到，称为DeepID（Deep Hidden Identity Features）。这一特征表示被用于最后的多分类识别任务，保证了卷积神经网络可以充分的学习到每个人的特征，具有更好的泛化能力。\n网络结构如下 通过跨层连接，保证DeepID可以获取到更多的信息，学习到更高级的特征（Conv4之后的特征更加高级/抽象）。跨层连接使用公式$$y_i = \\max(0, \\sum\\limits_{i}x_i^1\\omega_{i,j}^1+\\sum\\limits_{i}x_i^2\\omega_{i,j}^2+b_j)$$实现，其中的$\\omega$为权重。最终使用softmax层作为预测输出。\n特征提取部分的具体工作方式：每一张照片，划分为10个位置，每个位置选取三个不同的输入规模，每个照片得到RGB和灰度图，即每一条数据得到$10\\times3\\times2=60$条数据（patches）作为输入，训练60个网络。对于每一个卷积网络，给定数据，将其翻转后，得到两个向量作为输出，总的输出数据量为$160260$。 在面部识别的预测中，使用联合贝叶斯方法。同时也测试了使用深度神经网络进行预测。\n结果 在CelebFaces上训练，在LFW上测试，达到了SOTA的效果。\n测试中可以发现添加了跨层连接的模型具有更低的验证错误率和更高的预测正确率。 使用更多的patch与仅使用一张图片作为输入相比也具有更高的识别准确率。\n与现有的识别算法比较，具有更高的识别准确率（97.45%）。\n总结 提出了跨层连接（multi-scale），可以显著提高识别准确率。 使用同一张照片的多个patch作为输入，包括不同的位置，不同的大小，不同的通道（RGB、灰度），并将60个网络的输出合并作为预测的依据，可以提高识别准确率。 通过增加识别的人数（多分类的输出）可以使得特征网络学习到关键的信息。 ","date":1591429349,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591429349,"objectID":"784360dbecc89aac50f3f1ea1c177dd6","permalink":"https://yangleisx.github.io/post/paper-deepid/","publishdate":"2020-06-06T15:42:29+08:00","relpermalink":"/post/paper-deepid/","section":"post","summary":"论文题目：Deep Learning Face Representation from Predicting 10,000 Classes\n会议：CVPR2014\n作者：Yi Sun、Xiaogang Wang、 Xiaoou Tang\n链接：原文链接\n","tags":["Deep Learning","Face Recognition"],"title":"【论文】Deep Learning Face Representation from Predicting 10000 Classes","type":"post"},{"authors":["Lei Yang"],"categories":["代码学习"],"content":"Winsock就是windows下的socket编程的简称，函数用法与BSD的socket（即unix中的socket）编程基本相同。\n所有的代码实现位于我的Github。\n重要：所有的函数使用、讲解和实例请参考Winsock文档 via Microsoft。\n环境 使用VS开发，需要使用的头文件和库文件如下\n// 头文件 #include \u0026lt;winsock2.h\u0026gt; #include \u0026lt;ws2tcpip.h\u0026gt; // 静态库 #pragma comment (lib, \u0026#34;Ws2_32.lib\u0026#34;) #pragma comment (lib, \u0026#34;Mswsock.lib\u0026#34;) #pragma comment (lib, \u0026#34;AdvApi32.lib\u0026#34;) 基本数据结构 使用比较多的数据结构包括sockaddr，addrinfo等，定义如下。\nstruct sockaddr { ushort sa_family; char sa_data[14]; }; struct sockaddr_in { short sin_family; u_short sin_port; struct in_addr sin_addr; char sin_zero[8]; }; typedef struct addrinfo { int ai_flags; int ai_family; int ai_socktype; int ai_protocol; size_t ai_addrlen; char *ai_canonname; struct sockaddr *ai_addr; struct addrinfo *ai_next; } ADDRINFOA, *PADDRINFOA; 这里的sockaddr_in为IP协议的地址结构体，sockaddr为所有网络层协议的地址结构体，可以保存所有网络层协议的地址数据。当使用IP协议栈时使用sockaddr_in结构体，winsock的函数大多使用sockaddr作为函数参数，从而实现更好的兼容性。（winsock还实现了sockaddr_storage，地址空间更大，兼容性更好）。\n基本函数模块 由于Winsock有完备的错误代码提示，因此养成在每一步操作之后都要检查错误代码的习惯。这里添加一个全局的函数返回值（错误代码）变量用于检测操作是否完成。\nint iResult = 0; Winsock初始化：WSAStartup() Winsock在socket各种函数的基础上实现了一套WSA函数（WinSockApplication），需要在程序前部初始化。\nWORD wVersion = MAKEWORD(2, 2); WSADATA wsaDATA; // initialize winsock iResult = WSAStartup(wVersion, \u0026amp;wsaDATA); if (0 != iResult) { printf(\u0026#34;WSAStartup failed: %d\\n\u0026#34;, iResult); return -1; } Winsock清理： WSACleanup() Winsock在程序推出之前需要使用WSACleanup()函数完成收尾工作，通常位于main函数的return之前。\n获得本地主机名：gethostname() 可以获得本地的主机名\nchar hostname[NI_MAXHOST]; int hostlen = NI_MAXHOST; // 获得本地主机名 gethostname(hostname, hostlen); 获得地址信息：getaddrinfo() 给定主机名和端口号，可以解析得到目标主机的网络地址（例如IP地址），类似ARP协议的作用。需要使用hints传入参数。\n其中第一个参数为NULL时为获得本地主机信息。\n当目标主机存在多个网卡/IP地址时，得到的result为一个链表，使用result-\u0026gt;ai_next连接。\nchar hostname[NI_MAXHOST] = “localhost”; char servname[NI_MAXSERV] = “8080”; struct addrinfo *result = NULL; struct addrinfo hints; // 初始化 ZeroMemory(\u0026amp;hints, sizeof(hints)); hints.ai_family = AF_UNSPEC; hints.ai_socktype = SOCK_STREAM; hints.ai_protocol = IPPROTO_TCP; // 解析地址 iResult = getaddrinfo(hostname, servname, \u0026amp;hints, \u0026amp;result); if (0 != iResult) { printf(\u0026#34;getaddrinfo failed: %d\\n\u0026#34;, iResult); WSACleanup(); return -1; } 获得主机名信息: getnameinfo() 给定目标主机的网络地址，可以解析得到主机名和端口号，类似RARP协议的作用。\nchar hostname[NI_MAXHOST]; char servname[NI_MAXSERV]; struct sockaddr_in sa; int addrlen = sizeof(struct sockaddr); u_short port = 8080; const char* localhost = \u0026#34;127.0.0.1\u0026#34;; // 初始化 inet_pton(AF_INET, localhost, \u0026amp;sa.sin_addr.s_addr); sa.sin_family = AF_INET; sa.sin_port = htons(port); // 获得主机名信息 iResult = getnameinfo( (struct sockaddr*) \u0026amp;sa, addrlen, hostname, NI_MAXHOST, servname, NI_MAXSERV, 0); if (0 != iResult) { printf(\u0026#34;getnameinfo failed: %d\\n\u0026#34;, WSAGetLastError()); WSACleanup(); return -1; } 清空地址信息: freeaddrinfo() 使用getaddrinfo得到的地址消息不再使用时，建议显式清空。\nstruct addrinfo *result; // 非空的地址信息指针 freeaddrinfo(result); 地址信息可视化 想要以可读方式显示地址信息，涉及到大端/小端的转换、二进制和点分十进制的转换等处理。\nstruct addrinfo *result; // 非空的地址信息指针 struct sockaddr_in server_addr; char ipstringbuffer[46]; short port; // 转换地址格式 memcpy(\u0026amp;server_addr, result-\u0026gt;ai_addr, sizeof(server_addr)); inet_ntop(AF_INET, \u0026amp;server_addr.sin_addr, ipstringbuffer, sizeof(ipstringbuffer)); port = ntohs(server_addr.sin_port); // 显示地址信息 printf(\u0026#34;Server Address: %s\\n\u0026#34;, ipstringbuffer); printf(\u0026#34;Server Port Number: %d\\n\u0026#34;, port); 创建套接字: socket() socket编程中核心的部分为套接字socket，创建socket的进程才可以实现不同主机上的进程间通信。\nSOCKET s = INVALID_SOCKET; // 创建套接字 s = socket(AF_INET, SOCK_STREAM, IPPROTO_TCP); if (ConnectSocket == INVALID_SOCKET) { printf(\u0026#34;socket failed : %d\\n\u0026#34;, WSAGetLastError()); WSACleanup(); return -1; } 关闭套接字: closesocket() 套接字使用完毕后，建议手动关闭套接字。\nSOCKET s; // 合法套接字 // 关闭套接字 closesocket(s); 绑定套接字: bind() 在服务器端创建的套接字需要绑定，即建立socket和地址之间的联系。相当于内部地址（进程描述符、套接字描述符）和外部地址（网络地址、端口号）之间建立连接。\nSOCKET s; // 合法的套接字 struct addrinfo local; // 绑定套接字 iResult = bind(s, local-\u0026gt;ai_addr, (int)local-\u0026gt;ai_addrlen); if (iResult == SOCKET_ERROR) { printf(\u0026#34;bind failed: %d\\n\u0026#34;, WSAGetLastError()); freeaddrinfo(local); closesocket(s); WSACleanup(); return 1; } 监听端口: listen() 在服务器端绑定后的套接字可以监听端口，用于连接型的数据传输。类似TCP连接中等待SYN报文。\nSOCKET s; // 合法的套接字 // 监听端口（套接字） iResult = listen(s, SOMAXCONN); if (iResult == SOCKET_ERROR) { printf(\u0026#34;listen failed: %d\\n\u0026#34;, WSAGetLastError()); closesocket(s); WSACleanup(); return 1; } 接受连接请求: accpet() 当服务器端接收到连接请求时（请求队列不为空），接受连接请求并创建连接。类似TCP连接中发送SYN ACK报文。此时创建了用于传输的套接字，与监听套接字分离。\nSOCKET ListenSocket; // 合法的套接字 SOCKET ComSocket = INVALID_SOCKET; struct sockaddr_in client_addr; int addr_len = sizeof(struct sockaddr_in); // 接受连接请求 ComSocket = accept(ListenSocket, (struct sockaddr*)\u0026amp;client_addr, \u0026amp;addr_len); if (ComSocket == INVALID_SOCKET) { printf(\u0026#34;accept failed: %d\\n\u0026#34;, WSAGetLastError()); closesocket(ListenSocket); WSACleanup(); return 1; } 请求连接: connect() 客户端需要向服务器发送链接请求时，使用connect函数。类似TCP连接中发送SYN报文。\nSOCKET s; // 合法套接字 struct addrinfo remote; // 发送连接请求 iResult = connect(s, remote-\u0026gt;ai_addr, (int)remote-\u0026gt;ai_addrlen); if (iResult == SOCKET_ERROR) { printf(\u0026#34;connect failed: %d\\n\u0026#34;, WSAGetLastError()); closesocket(s); s = INVALID_SOCKET; } 关闭连接: shutdown() 通信结束时，不可以直接关闭socket，应该首先关闭连接（关闭发送方向的连接，表示不再发送消息）。类 …","date":1589342192,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589342192,"objectID":"b0ecb995fd75118c4b7d09b3d483e896","permalink":"https://yangleisx.github.io/post/winsock/","publishdate":"2020-05-13T11:56:32+08:00","relpermalink":"/post/winsock/","section":"post","summary":"Winsock就是windows下的socket编程的简称，函数用法与BSD的socket（即unix中的socket）编程基本相同。\n所有的代码实现位于我的Github。\n重要：所有的函数使用、讲解和实例请参考Winsock文档 via Microsoft。\n","tags":["Winsock","Socket"],"title":"Winsock编程记录","type":"post"},{"authors":["Lei Yang"],"categories":["实用工具"],"content":"简单记录SSH的用法\nSSH登陆 首次登录时发送服务器公钥的fingerprint，要求用户确认。\n用户确认后公钥保存到known_hosts，默认可信。\n密钥登陆：ssh -p [port] -i [id_file] [user]@[ip_address]\n公钥登陆：客户端ssh-keygen生成密钥对，ssh-copy-id传输公钥到服务器(自动写入authorized_keys)。\n$ ssh-keygen -t rsa # 生成SSH公私钥对 # -t 使用rsa算法 [dsa|ecdsa|ed25519|rsa] $ ssh-copy-id -i ~/.ssh/id_rsa.pub auth@192.168.1.10 # 将公钥传输到SSH服务器 # -i 指定公钥文件 # user@address 指定SSH服务器的IP地址和公钥对应的用户 # 需要使用口令方式通过认证 私钥登陆：服务器ssh-keygen生成密钥对，将公钥追加到服务器authorized_keys，通过scp或其他安全方式传输私钥到客户端。\nssh-copy-id的替代方式:\nLinux机器：\nssh \u0026lt;user\u0026gt;@\u0026lt;ip_address\u0026gt; \u0026#34;cat \u0026gt;\u0026gt; authorized_keys\u0026#34; \u0026lt; id.pub Windows机器：\n\u0026gt; Get-Content new.pub | ssh \u0026lt;user\u0026gt;@\u0026lt;ip_address\u0026gt; \u0026#34;cat \u0026gt;\u0026gt; authorized_keys\u0026#34; 权限：通常公钥权限644，私钥权限600。authorized_keys权限600，known_hosts权限644。\n服务器端私钥权限为640、644之后，SSH服务器会自动忽略对应密钥对（认为该私钥是不安全的）。\nauthorized_keys权限改为620、622之后，SSH服务器会拒绝读取（认为公钥不安全），只能口令登陆。\n文件：\nauthorized_keys在服务器端保存客户端的公钥。用于密钥登陆时加密随机挑战。防止冒用。\nknown_hosts在客户端保存服务器的公钥。用于公钥的比较确认，口令登录时用公钥加密口令。\nscp：基于SSH的加密文件传输，使用单行命令传输文件。\nsftp：基于SSH的加密文件传输，类似FTP的操作和使用方式。\nSSH连接 信息交换 TCP连接：三次握手建立TCP连接。发送SYN，接收SYN ACK，发送ACK。\n版本协商：双方交换SSH版本。\n算法协商：包括公钥算法，加密算法，MAC（消息验证码）算法，压缩算法列表\n密钥协商：Elliptic Curve Diffie-Hellman Key Exchange\n客户端发送ECDH Key Exchange Init报文。包括客户端交换密钥Q_C。\n服务器发送ECDH Key Exchange Replay报文。包括ECDSA服务器公钥Q和ECDH交换密钥Q_S。\n接下来通过发送New Keys报文表示交换密钥已经建立。\n登陆认证：（传输过程使用交换密钥对称加密）\n口令认证过程：服务器发送公钥。客户端使用服务器公钥加密口令。服务器使用私钥解密验证。\n密钥认证过程：服务器使用客户公钥加密发送随机字符串。客户端使用客户私钥加密。\n防御中间人攻击 中间人拦截客户端的连接请求并发送自己的公钥，从而假冒服务器窃取用户信息。\n客户端首次连接时保存服务器的公钥。中间人攻击时，中间人发送的服务器公钥与保存的公钥不同。 SSH引入了公钥认证机制，通过安全的方式发送公钥保存在服务器的authorized_keys中。 端口转发 socks代理 要求机器A配置socks代理、机器B做代理服务器、访问web服务。\n# 机器A ssh -f -N -D 127.0.0.1:1080 \u0026lt;user\u0026gt;@\u0026lt;addressB\u0026gt; 机器A浏览器设置代理为127.0.0.1:1080即可通过机器B访问网页。\n远程转发 要求机器A访问本地端口、机器B做代理服务器、访问目标网站。\n# 机器A ssh -f -N -R 3456:bbs.fudan.edu.cn:23 \u0026lt;user\u0026gt;@\u0026lt;addressB\u0026gt; 机器A访问localhost:3456会经由机器B访问复旦BBS。\n本地转发 要求机器A访问本地端口、机器B开启web服务并做代理。\n# 机器A ssh -f -N -L 3456:lohalhost:80 \u0026lt;user\u0026gt;@\u0026lt;addressB\u0026gt; 机器A访问localhost:3456实际访问到addressB:80。\nSSH设置 设置规则之后重启服务\nsystemctl restart ssh # 或者使用 service 禁止使用密码登录\n# /etc/ssh/ssgd_config PasswordAuthentication no 拒绝用户登录\n# /etc/ssh/sshd_config DenyUsers user1 设置用户白名单\n# /etc/ssh/sshd_config # 按优先级从高到低 # 指定禁止某用户登录 DenyUsers \u0026lt;user\u0026gt; # 指定仅限某用户登录 AllowUsers \u0026lt;user\u0026gt; # 指定禁止某用户组登录 DenyGroup \u0026lt;group\u0026gt; # 指定仅限某用户组登录 AllowGroup \u0026lt;group\u0026gt; 设置IP白名单\n# 按优先级从高到低 # /etc/hosts.allow sshd:192.168.198.1:allow # /etc/hosts.deny sshd:ALL 禁止登陆root用户，如果使用弱口令的话可能被爆破\n# /etc/ssh/sshd_config PermitRootLogin no 禁止无密码的登录\n# /etc/ssh/sshd_config PermitEmptyPasswords no 更改端口\n# /etc/ssh/sshd_config Port 40121 ","date":1588919251,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588919251,"objectID":"2a9a4ca9e5b7b3d6e6bbc3e3e8d7c4b3","permalink":"https://yangleisx.github.io/post/ssh/","publishdate":"2020-05-08T14:27:31+08:00","relpermalink":"/post/ssh/","section":"post","summary":"简单记录SSH的用法\n","tags":["SSH"],"title":"SSH使用简单记录","type":"post"},{"authors":["Lei Yang"],"categories":["开发经历"],"content":"背景 分别由两个人开发的代码需要被整合进入一个完整的项目并运行。\n其中第一位同学使用Visual Studio开发基于C++和openSSL的加解密的程序，使用vcpkg安装和编译openSSL:x86-windows并且集成到Visual Studio中。另一位同学使用Qt Creator开发基于C++和Qt的GUI程序。\nIDE选择 由于需要将两份代码合成一个完整的项目运行，我首先选择IDE为Visual Studio，但是由于并没有在VS中写过Qt程序，添加的QT VS TOOL插件总是无法正常编译。因此放弃使用Visual Studio作为项目IDE。选择Qt Creator作为开发环境。\n编译 遇到的第一个问题是将openSSL集成到Qt Creator，从网上找到的资料都是从OpenSSL官网下载，并在Qt项目文件中添加库和头文件路径。如下代码所示\nLIBS += \\ -Lpath/lib -lssl \\ -Lpath/lib -lcrypto INCLUDEPATH += path/include 我遇到的问题是，添加头文件正常，但是在编译的时候会出现undefined reference to xxx的报错，仔细一看是openssl库中的函数，在代码中follow symbols可以跳转到头文件中对应的定义，因此猜测是头文件正常但库文件没有正常加载。\n这里涉及到的我尝试过的库文件包括\nlibssl.lib libcrypto.lib libssl.a libcrypto.a libssl.dll.a libcrypto.dll.a libssl-1_1.dll libcrypto-1_1.dll libeay32.dll ssleay32.dll ... 于是开始各种下载和添加库文件。包括但不限于\n使用vcpkg编译x64-windows版本的openssl库并添加（考虑到32位和64位可能产生的冲突） 官网下载openssl安装包（由于下载速度太慢，我选择了64位light版本的安装包，但是light版本安装包没有lib文件，完整版本的安装包就不曾下载成功过） 将lib和include文件copy到项目目录下，再使用上述方法添加路径。 在这个时候，我查到一篇文章说qt本身是包括openssl的但是在编译的时候默认不安装，因此qt的环境下实际上是包括openssl对应的库文件和头文件的。经过一番查找我找到这个路径C:\\Qt\\Qt5.12.0\\Tools\\mingw730_64\\opt。\n这个路径的lib目录下包括了libssl.a、libcrypto.a、libssl.dll.a、libcrypto.dll.a，bin目录下包括libeay32.dll、ssleay32.dll，include目录下包括openssl头文件目录。因此我修改.pro文件如下。\n# 这里的$$quote我也没搞清啥意思，大概是双引号 LIBS += \\ -LC:\\Qt\\Qt5.12.0\\Tools\\mingw730_64\\opt\\lib -lssl \\ -LC:\\Qt\\Qt5.12.0\\Tools\\mingw730_64\\opt\\lib -lcrypto INCLUDEPATH += \\ $$quote(C:\\Qt\\Qt5.12.0\\Tools\\mingw730_64\\opt\\include) 经过多次编译，并注释掉一些无用的函数，终于实现了0 warnigns, 0 errors，呜呼。\n运行 接下来遇到的问题是，程序无法运行。在Qt Creator中直接运行，程序闪退并显示程序异常结束。在Qt Creator中开启Debugger，同样也是闪退，添加的断点直接被无视了。\n刚开始考虑到可能是被杀毒软件杀掉了，因此经过一番操作关闭了Windows Defender，但是仍然无法运行，陷入停滞。\n这个时候查到一篇文章，详细介绍了Qt Creator中的闪退的原因并给出了一个检查的方法，就是找到编译生成的exe文件，直接双击运行。程序自然无法运行并提示缺少许多dll文件，其中包括qt的依赖库例如QtCore.dll等等，因此使用windeployqt.exe(位于C:\\Qt\\Qt5.12.0\\5.12.0\\mingw73_64\\bin)将Qt所有的依赖dll复制到exe对应的路径下，这个时候再次点击exe文件，显示缺少libeay32.dll于是将上述的libeay32.dll和ssleay32.dll（位于C:\\Qt\\Qt5.12.0\\Tools\\mingw730_64\\opt\\bin）复制到这个路径下。\n双击exe，正常运行！！！经过测试，一切正常。每次使用qt编译后，将得到的exe文件拷贝到一个新的路径下，调用windeployqt和复制dll就可以正常运行。\n总结反思 我使用Qt官网下载的安装包安装Qt时，IDE选择了QtCreator，编译环境我选择了MinGW和MSVC，因此在我的安装目录下（C:\\Qt\\Qt5.12.0\\5.12.0）包括了如下四个编译环境，每一个环境中都包含了windeployqt等一系列exe文件，和完整的Qt编译环境（bin + lib + include）。\nmingw73_64\nmsvc2015_64\nmsvc2017\nmsvc2017_64\n但是非常疑惑的一点是，在编译时我检查Qt Cretor的编译输出窗口，发现我编译使用的是Tools目录下的mingw730_64。进一步检查发现Tools目录下（C:\\Qt\\Qt5.12.0\\Tools）包括如下目录。\nmingw730_64\nQtCreator\n前者不是一个完整的Qt编译环境，不包括qt的各种dll，而是包括了ar、ld、gcc、make、objdump等一系列工具，更像是一个编译环境。其opt目录下包括了openssl的编译环境（前文使用到的）。\n那么这两个不同的mingw环境究竟有什么区别呢？后者可不可以换成我之前自己手动安装的MinGW环境呢？\n使用vcpkg编译得到的环境和使用官方安装包以及从GitHub直接下载手动编译的环境有什么区别。\n对于库文件来说存不存在32位和64位的差异，如果不存在的话，那么vcpkg编译时为什么提供了x86-windows和x64-windows的不同的triplets（还包括了arm、linux等其他选择）。\n函数静态库和动态库在使用时一定要同时存在么，即编译时指定lib文件，执行时exe文件路径中要包含对应的dll文件。\nvcpkg编译得到的libssl.lib和mingw730_64的opt路径下的libssl.a文件有什么差异，能不能简单通过改变后缀名来实现适配。同理还有.dll文件和.so文件之间的关系。\n最后的最后，还是感觉任重而道远。上述问题大多都是操作系统和C语言编译的基础知识，还是要努力打好基础。\n","date":1587432404,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587432404,"objectID":"e9b5f547f18a39fadf6db1183c5589c5","permalink":"https://yangleisx.github.io/post/log-qt-ssl/","publishdate":"2020-04-21T09:26:44+08:00","relpermalink":"/post/log-qt-ssl/","section":"post","summary":"背景 分别由两个人开发的代码需要被整合进入一个完整的项目并运行。\n","tags":["Qt","OpenSSL"],"title":"Qt开发OpenSSL程序踩坑","type":"post"},{"authors":[],"categories":["代码学习"],"content":"在C++11的STL线程库没有实现现成的信号量，可以使用互斥量和条件变量实现信号量机制。\n建议使用自己定义的namespace以防止与现成的函数/类产生冲突。\n由于使用了lambda函数和C++11的STL线程库，因此编译时需要指定 –std=c++11。\n/** * @file: main.cpp * @brief: Simulate Productor/Consumer Problem * @author: YangLei * @date: 2020-04-20 */ #include \u0026lt;list\u0026gt; #include \u0026lt;mutex\u0026gt; #include \u0026lt;condition_variable\u0026gt; #include \u0026lt;thread\u0026gt; #include \u0026lt;iostream\u0026gt; #define BUFFER_SIZE 5 namespace userdef { class semaphore { public: // construction function explicit semaphore(int value = 1): count(value), wakeups(0) {} // semWait（or operation P） void wait() { std::unique_lock\u0026lt;std::mutex\u0026gt; lock(mutex); if (--count \u0026lt; 0) { condition.wait(lock, [\u0026amp;]()-\u0026gt;bool{return wakeups \u0026gt; 0;}); --wakeups; } } // semSignal（or operation V） void signal() { std::lock_guard\u0026lt;std::mutex\u0026gt; lock(mutex); if (++count \u0026lt;= 0) { ++wakeups; condition.notify_one(); } } private: int count; int wakeups; std::mutex mutex; std::condition_variable condition; }; // class semaphore }; // namespace userdef userdef::semaphore product(BUFFER_SIZE); // space for new product userdef::semaphore consume(0); // products in buffer userdef::semaphore mutex(1); // mutex for buffer operation std::list\u0026lt;int\u0026gt; products; // products buffer unsigned int seed = (unsigned int)time(NULL); /** * @brief: Thread for Productors * @params: n(int) -- total umber of products */ void productor(int n) { for (int i = 0; i \u0026lt; n; i++) { product.wait(); // wait for buffer space int size = rand_r(\u0026amp;seed) % 10; std::this_thread::sleep_for( std::chrono::milliseconds(200 * (rand_r(\u0026amp;seed) % 10))); mutex.wait(); // mutex lock std::cout \u0026lt;\u0026lt; \u0026#34;Product: \u0026#34; \u0026lt;\u0026lt; size \u0026lt;\u0026lt; std::endl; products.push_back(size); mutex.signal(); // mutex unlock consume.signal(); // signal to consumer } quit.signal(); } /** * @brief: Thread for Consumers * @params: None */ void consumer() { while (true) { consume.wait(); // wait for products mutex.wait(); // mutex lock int size = products.front(); products.pop_front(); std::cout \u0026lt;\u0026lt; \u0026#34;Consume: \u0026#34; \u0026lt;\u0026lt; size \u0026lt;\u0026lt; std::endl; mutex.signal(); // mutex unlock product.signal(); // signal to productor std::this_thread::sleep_for(std::chrono::milliseconds(200 * size)); } } /** * @brief: main function for simulation */ int main(int argc, char* argv[]) { int number = 10; std::thread prod(productor, number); // productor thread std::thread cons(consumer); // consumer thread prod.join(); cons.join(); return 0; } ","date":1587362947,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587362947,"objectID":"f8737fef8cc27023949df6724ba9420f","permalink":"https://yangleisx.github.io/post/cpp-thread-sim/","publishdate":"2020-04-20T14:09:07+08:00","relpermalink":"/post/cpp-thread-sim/","section":"post","summary":"在C++11的STL线程库没有实现现成的信号量，可以使用互斥量和条件变量实现信号量机制。\n建议使用自己定义的namespace以防止与现成的函数/类产生冲突。\n由于使用了lambda函数和C++11的STL线程库，因此编译时需要指定 –std=c++11。\n","tags":["C/C++"],"title":"使用STL线程库模拟生产者消费者问题","type":"post"},{"authors":[],"categories":["实用工具"],"content":"使用qt编写的GUI程序部署和发布流程。\nPython\u0026amp;PyQt程序部署 使用pyinstaller工具打包部署使用pyqt编写的GUI程序。（适用于Windows和macOS）\n# 使用pip安装pyinstaller工具 $ pip install pyinstaller $ pyinstaller -F -w --noconfirm --icon myicno.ico mainwindow.py # 其中： # -F 表示打包为一个单独的exe文件 # -w 表示exe文件运行时隐藏cmd窗口(黑框) # --icon 表示指定图标 # --noconfirm 表示覆盖原有文件时不询问 运行结束后，在当前目录下会生成两个文件夹build和dist。前者存放编译生成的一些中间文件，后者为distribution的简称，存放打包结束的文件。\n使用-F生成的是单个exe文件，但是文件非常大。不添加-F选项得到的文件夹中包括程序主文件和大量依赖的dll文件。\n不添加-w选项时，上述生成的文件运行时会出现一个cmd窗口，显示程序中的qDebug()信息。因此在最后的发布版本中建议加上-w选项，并注释掉qDebug信息。\n当build和dist文件夹存在时，pyinstaller写入文件时会询问时候覆盖原有的文件，使用–noconfirm表示直接覆盖，不询问用户。\nC++\u0026amp;QT程序部署 使用QT自带的windeployqt.exe工具。通常位于QT的安装路径的/bin下。\n# 将Qt Creator编译生成的release文件夹下的内容复制到一个新的文件夹 # 此时直接点击mainwindow.exe运行失败，因为缺少一些依赖的dll文件 $ windeployqt.exe mainwindow.exe 运行结束后，这个文件夹下包含程序主文件和依赖的dll文件。\n程序发布 可以使用Inno Setup工具将上述部署得到的包含dll和exe的文件夹打包成一个安装包发布。\n可以填写程序名称、版本号、网址、LICENSE文件、README文件、安装包图标，并选择程序主exe文件、选择程序依赖文件夹，Inno Setup工具就会将所有需要的文件打包为一个setup.exe安装包。\n用户可以点击该安装包将文件安装到系统目录(例如C:\\ProgramFiles)中并创建桌面和开始菜单图标。\n","date":1587023981,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587023981,"objectID":"50d283ce89f96c524273f1302e637b9b","permalink":"https://yangleisx.github.io/post/qt-deploy/","publishdate":"2020-04-16T15:59:41+08:00","relpermalink":"/post/qt-deploy/","section":"post","summary":"使用qt编写的GUI程序部署和发布流程。\n","tags":["Qt"],"title":"QT程序打包部署","type":"post"},{"authors":["Lei Yang"],"categories":["代码学习"],"content":"使用C++11实现的标准线程库进行并发编程\n#include \u0026lt;thread\u0026gt; 创建和结束线程 创建线程 使用thread类的构造函数创建线程\n// initFunc 是线程中要执行的函数名 std::thread t(initFunc); 实际上，任何可执行的对象都可以被传入线程中\n包括函数、可执行类/结构体等\n// 可执行类的定义 class callable_class{ int \u0026amp;i; callable_class(int \u0026amp;i_):i(i_){} void operator()() const { std::cout \u0026lt;\u0026lt; \u0026#34;The value i have is \u0026#34; \u0026lt;\u0026lt; i \u0026lt;\u0026lt; std::endl; } } 函数传参 线程的iniFunc可以有多个参数\n在构造函数中的函数指针后跟参数列表\n注意，thread的构造函数默认按值传参，即复制到线程变量内部\n如果initFunc需要引用传参 则要使用 std::ref()\n如果形参和实参类型不同 则要显式使用类型转换\n结束线程 选择线程分离或者结合\nstd::thread t(initFunc); // 线程分离 // 显式决定不等待线程执行结束 t.detach(); // 线程结合 // 等待线程执行结束 t.join(); 线程分离 分离后的线程无法通信无法直接控制\n守护线程通常被分离，运行在后台\n线程结合 通常需要保证所有的线程都被结合\n一种方法是RAII（资源获取即初始化），使用一个保护类包裹\nclass thread_guard{ std::thread t; public: // 只允许显式类型转换 explicit thread_guard(std::thread t_):t(std::move(t_)){ if(!t.joinable) throw std::logit_error(\u0026#34;No thread\u0026#34;); } // 保证程序/函数结束时线程被合并 ~thread_guard(){t.join();} // 不生成默认构造函数和赋值函数 thread_guard(thread_guard const \u0026amp;) = delete; thread_guard\u0026amp; operator=(thread_guard const \u0026amp;) = delete; } ","date":1587021514,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587021514,"objectID":"72ccc2a1379fc0c9487415d06ef39e64","permalink":"https://yangleisx.github.io/post/cpp-thread-base-01/","publishdate":"2020-04-16T15:18:34+08:00","relpermalink":"/post/cpp-thread-base-01/","section":"post","summary":"使用C++11实现的标准线程库进行并发编程\n#include \u003cthread\u003e ","tags":["C/C++"],"title":"C++并发编程:线程创建和运行","type":"post"},{"authors":["Lei Yang"],"categories":["基础知识"],"content":"相关概念：SSL、TLS、证书。\nSSL或TLS运行在传输层和应用层之间。（早期称为SSL，后期称为TLS）。用户网络加密通讯。\nHTTPS可以看作HTTP+TLS，包括两个部分：握手协议+记录协议。\n链接流程（握手协议）主要流程：\n客户端HELLO（发送支持的TLS版本） 服务器HELLO（选择TLS版本，发送服务器证书） 客户端检查证书，生成主密钥（随机数）并使用服务器证书加密 服务器解密后对主密钥加密并发回（类似Diffie Hellman交换） 客户端验证主密钥，使用主密钥得到交换密钥用于非对称加密 服务器验证客户端（可选） 主要概念：使用服务器的公钥加密一个信息，服务器使用公钥解密后将该信息以客户端公钥加密后发回。用户客户端和服务器之间的验证。\n记录协议中将应用层数据分段、压缩、添加下层首部（HTTP）、对称加密、添加TLS头部并发送。\n证书包括公钥内容和私钥拥有者的信息。属于可信第三方（公钥基础设施PKI），用于证明公钥内容正确性。\n通常由CA机构使用自己的私钥为服务器的证书请求添加数字签名。拿到证书以后，客户端通过使用CA的公钥解密得到证书内部的服务器公钥。CA使用层次签名，顶级CA的证书使用自签名，其公钥在全网公开。\n","date":1586853245,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586853245,"objectID":"02972ebd0e8d8b1653318352a66ab596","permalink":"https://yangleisx.github.io/post/https/","publishdate":"2020-04-14T16:34:05+08:00","relpermalink":"/post/https/","section":"post","summary":"相关概念：SSL、TLS、证书。\n","tags":["HTTPS"],"title":"HTTPS初步理解","type":"post"},{"authors":["Lei Yang"],"categories":["实用工具"],"content":"openssl的功能主要包括对称加解密、计算哈希（信息摘要）和发布证书。\n加解密 openssl enc -e -aes-128-cbc -in main.c -out main.enc openssl enc -d -aes-128-cbc -in main.enc -out main_out.c 计算摘要 $ openssl dgst -sha1 main.c SHA1(main.c)= cc9bf223848c972e66968fb3846fc7f85721796e $ echo \u0026#34;\\n\u0026#34; \u0026gt;\u0026gt; main.c $ openssl dgst -sha1 main.c SHA1(main.c)= 52019cdc4aea16ee68f4d881465f6b8f03cf1836 自建CA并签发\u0026amp;撤销证书 更改文件目录设置 # CA目录 dir=/home/yanglei/Workspace/ssl # 证书目录 certs=$dir/certs # 证书备份目录 new_certs_dir=$dir/newcerts # CA证书 certificate=$dir/cacert.pem # CA数据库 database=$dir/CA/index.txt # CA序列号 serial=$dir/CA/serial # 吊销证书目录 crl_dir=$dir/crl # 吊销证书编号 crlnumber=$dir/crlnumber crl=$dir/crl.pem # CA私钥目录 privatekey=$dir/private/cakey.pem 创建文件夹certs、newcerts、CA、private、crl\n创建文件crlnumber（注意写入echo 01 \u0026gt; crlnumber）\n创建文件CA/index.txt、CA/serial（注意写入echo 01 \u0026gt; serial）\n创建随机数private/.rand\n证书字段 Country Name（C）国家\nState or Province Name（S）省\nLocatily Name（L）市\nOrganization Name（O）组织名\nOrganization Unit Name（OU）补充\nCommon Name（CN）通常为域名/网址\nEmail Address\n生成自签名证书 # /home/yanglei/Workspace/ssl $ openssl genrsa -out private/cakey.pem 1024 $ openssl req -new -x509 -key private/cakey.pem -out cacert.pem -days 3650 # 或者先生成请求再签名 $ openssl req -new -key xxx.pem -out xxx.csr $ openssl x509 -req -in xxx.csr -signkey cakey.pem -out xxx.crt 签发证书 # /home/yanglei/Workspace/testssl $ openssl genrsa -out user1.pem 1024 $ openssl rsa -in user1.pem -out user1.pub -pubout $ openssl req -new -key user1.pem -out user1.csr -days 365 # /home/yanglei/Workspace/ssl $ openssl ca -in ../testssl/user1.csr -out certs/user1.crt -days 365 $ openssl x509 -in certs/user1.crt -noout -text 撤销证书 # 吊销证书 $ openssl ca -revoke newcerts/01.pem # 发布吊销列表 $ openssl ca -gencrl -out crl/ca.crl # 查看吊销列表 $ openssl crl -in crl/ca.crl -noout -text ","date":1586852958,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586852958,"objectID":"5bbfa1e5544af995558f7786811ef91f","permalink":"https://yangleisx.github.io/post/bash-openssl/","publishdate":"2020-04-14T16:29:18+08:00","relpermalink":"/post/bash-openssl/","section":"post","summary":"openssl的功能主要包括对称加解密、计算哈希（信息摘要）和发布证书。\n","tags":["OpenSSL"],"title":"OpenSSL使用记录","type":"post"},{"authors":["Lei Yang"],"categories":["基础知识"],"content":"由于课程需要，进一步学习了一下make的使用，在之前的基础上添加一些高级知识， 同时提供一个makefile的模版共以后使用。\nMake的内部规则 目标 依赖 规则 x.o x.c cc -c x.c x.o x.s as -o x.s x.o x.y yacc x.y\ncc -c y.tab.c\nrm y.tab.c\nmv y.tab.o x.o x.o x.l lex x.l\ncc -c lex.yy.c\nrm -f lex.yy.c\nmv les.yy.o x.o x.c x.y yacc x.y\nmv y.tab.c x.c x.c x.l lex x.l\nmv les.yy.c x.c x.a x.c cc -c x.c\nar rv x.a x.c\nrm -f x.o 利用上述规则可以简写makefile。\nmain: main.o libylmath.a ylmathp.o cc -o main -L . -l ylmath main.o ylmathp.o libylmath.a: libylmath.a(ylmath.o) ylmathp.o: ylmathp.h Make的内部宏 内部宏 含义 $\u0026lt; 使目标过时的依赖文件（即已更新的文件） $* 不带后缀的依赖文件(常用写法$*.c) $@ 目标文件名，用于显式说明行 $? 类似$\u0026lt; 用于显式说明行 $% 用于处理库文件的依赖文件 这些宏大多用于修改上述隐含规则或创建自己的隐含规则。\n实用技巧 使用一个例子展示如下\n# 使用宏定义增加可移植性 INSTDIR= bin CFLAGS= -O -g LDFLAGS= CC= cc # 文件声明 HEADERS= ylmath.h ylmathp.h SOURCE= main.c ylmathp.c OBJECT= $(SOURCE: .c=.o) # 库声明 LIBSRC= ylmath.c LIBOBJ= ylmath.o LIBDIR= lib # 覆盖默认的.c.o规则，添加-O(优化) -g(调试) .c.o: $(CC) $(CFLAGS) -c $*.c # 连接得到可执行文件 demo: $(OBJECT) libylmath.a $(CC) -o $@ $(OBJECT) -L$(LIBDIR) -lylmath all: demo install # 声明头文件，使用.c.o规则生成 $(OBJECT): $(HEADERS) # 使用.c.a规则生成库并移到lib文件夹 # -开头的命令忽略运行错误和命令返回码，继续执行 libylmath.a: libylmath.a($(LIBOBJ)) -mv $(LIBDIR)/libylmath.a libylmath.a.old -mv libylmath.a $(LIBDIR)/libylmath.a # 更新bin文件夹 install: demo libylmath.a -mv $(INSTDIR)/demo demo.old -mv demo $(INSTDIR)/demo # 删除 clean: -rm *.old demo $(LIBDIR)/libylmath.a # 记录更新信息 # @开头的命令在运行时不显示 print: $(SOURCE) $(OBJECT) @ echo printing modified files @ echo $? \u0026gt; $@ ","date":1586414015,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586414015,"objectID":"5cbe57ccd4a91bfa20d47f22d415f02f","permalink":"https://yangleisx.github.io/post/makefile-plus/","publishdate":"2020-04-09T14:33:35+08:00","relpermalink":"/post/makefile-plus/","section":"post","summary":"由于课程需要，进一步学习了一下make的使用，在之前的基础上添加一些高级知识， 同时提供一个makefile的模版共以后使用。\n","tags":["C/C++","Make"],"title":"Make进阶使用","type":"post"},{"authors":["Lei Yang"],"categories":["代码学习"],"content":"使用Clion+CubeMX开发，开发板为野火指南者，芯片为STM32F103ZET6.\n简单实现使用串口经过STM32与ESP8266通信。\nCube MX设置 串口设置 开发板使用USART1与PC通信，因此设置USART1，使用PA9和PA10端口通信，参数为115200-8-N-1。同时添加RX和TX的DMA设置,NVIC开启串口的global中断。\n板载的ESP8266与STM芯片使用USART3通信,使用PB10和PB11端口,参数为115200-8-N-1.同理也需要添加RX和TX的DMA设置,NVIC开启串口global中断.\n控制引脚设置 ESP8266需要添加片选引脚和复位引脚.板载ESP8266使用PB8作为片选引脚(高电平为使能),PB9作为复位引脚(低电平复位).\n其他设置 SYS中设置调试器模式.\nRCC中设置HSE使用外部晶振,在Clock Configuration中设置时钟.\n生成代码时选择根据外设生成对应的.C/.H文件.\nClion代码 使用DMA接收数据,使用空闲中断处理.将PC发送的数据转发给ESP8266并将ESP8266的回复信息转发到PC.需要注意添加的代码位于指定的user code区间防止被覆盖.\nusart设置 在usart.c中添加必要的变量和缓冲区.\n// BUFFER_SIZE定义在main.h中,不大于200 /* USER CODE BEGIN 0 */ uint8_t usart1_rx_buffer[BUFFER_SIZE]; volatile uint8_t usart1_rx_len = 0; volatile uint8_t usart1_recv_end_flag = 0; uint8_t usart3_rx_buffer[BUFFER_SIZE]; volatile uint8_t usart3_rx_len = 0; volatile uint8_t usart3_recv_end_flag = 0; /* USER CODE END 0 */ 在usart.h中添加变量声明\n/* USER CODE BEGIN Private defines */ extern uint8_t usart1_rx_buffer[BUFFER_SIZE]; extern volatile uint8_t usart1_rx_len; extern volatile uint8_t usart1_recv_end_flag; extern uint8_t usart3_rx_buffer[BUFFER_SIZE]; extern volatile uint8_t usart3_rx_len; extern volatile uint8_t usart3_recv_end_flag; /* USER CODE END Private defines */ GPIO设置 在main.c的while(1)循环之前设置ESP8266使能和复位\n/* USER CODE BEGIN 2 */ // 设置ESP8266选择 HAL_GPIO_WritePin(CH_GPIO_Port, CH_Pin, GPIO_PIN_SET); HAL_GPIO_WritePin(RST_GPIO_Port, RST_Pin, GPIO_PIN_RESET); HAL_Delay(500); HAL_GPIO_WritePin(RST_GPIO_Port, RST_Pin, GPIO_PIN_SET); /* USER CODE END 2 */ 中断响应 在main.c的while(1)循环之前开启接收DMA和空闲中断\n/* USER CODE BEGIN 2 */ // 开启USART的接收DMA传输中断 HAL_UART_Receive_DMA(\u0026amp;huart1, usart1_rx_buffer, BUFFER_SIZE); __HAL_UART_ENABLE_IT(\u0026amp;huart1, UART_IT_IDLE); HAL_UART_Receive_DMA(\u0026amp;huart3, usart3_rx_buffer, BUFFER_SIZE); __HAL_UART_ENABLE_IT(\u0026amp;huart3, UART_IT_IDLE); /* USER CODE END 2 */ 在stm32f1xx_it.c中修改中断响应,分别修改USART1_IRQHandler和USART3_IRQHandler.当接收DMA接收完成时,依次触发DMA接收中断和USART全局中断.\n/* USER CODE BEGIN USART1_IRQn 0 */ // 局部变量 uint32_t tmp_flag = 0; uint32_t temp; // 空闲状态 tmp_flag = __HAL_UART_GET_FLAG(\u0026amp;huart1, UART_FLAG_IDLE); if((tmp_flag != RESET)) { // 关闭空闲状态 __HAL_UART_CLEAR_IDLEFLAG(\u0026amp;huart1); // 清空寄存器 temp = huart1.Instance-\u0026gt;SR; temp = huart1.Instance-\u0026gt;DR; HAL_UART_DMAStop(\u0026amp;huart1); // 获取未传输比特数 用于计算已传输比特数 temp = hdma_usart1_rx.Instance-\u0026gt;CNDTR; usart1_rx_len = BUFFER_SIZE - temp; // 开始标志位 usart1_recv_end_flag = 1; } /* USER CODE END USART1_IRQn 0 */ 在main.c的循环部分添加中断处理部分\n// PC传输中断 if(usart1_recv_end_flag == 1) { // 发送到ESP8266 HAL_UART_Transmit(\u0026amp;huart3, usart1_rx_buffer, usart1_rx_len, 0xFF); // 清空缓冲和标志位 memset(usart3_rx_buffer, 0, BUFFER_SIZE); usart1_rx_len = 0; usart1_recv_end_flag = 0; // 开启接收中断 HAL_UART_Receive_DMA(\u0026amp;huart1, usart1_rx_buffer, BUFFER_SIZE); } // ESP8266传输中断 if(usart3_recv_end_flag == 1) { // 发送到PC显示 HAL_UART_Transmit(\u0026amp;huart1, usart3_rx_buffer, usart3_rx_len, 0xFF); // 清空缓存和标志位 memset(usart3_rx_buffer, 0, BUFFER_SIZE); usart3_rx_len = 0; usart3_recv_end_flag = 0; // 开启接收中断 HAL_UART_Receive_DMA(\u0026amp;huart3, usart3_rx_buffer, BUFFER_SIZE); } /* USER CODE END WHILE */ 从而实现STM32转发PC和ESP8266的串口通信,接下来就可以通过ESP8266的AT指令进行设置和操作.同时在PC的串口调试工具上检测到回复的信息.\n我遇到的坑 ESP8266的使能引脚和复位引脚配置错误,导致ESP8266的通信出现一些问题. 代码中的发送指令使用HAL_UART_Transmit_DMA,导致发送/接收到的指令不全,因此改用HAL_UART_Transmit函数. 网上找到的代码和野火提供的代码大多都是基于STM32标准库和Keil开发环境,使用HAL库和CubeMX开发的代码不多,而且最开始学习STM32也是基于STM32标准库,因此会有一些不适应. ","date":1586315332,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586315332,"objectID":"3ff3a2e5fa4f76fd70962b0f9e70b484","permalink":"https://yangleisx.github.io/post/stm32-esp8266-hal/","publishdate":"2020-04-08T11:08:52+08:00","relpermalink":"/post/stm32-esp8266-hal/","section":"post","summary":"使用Clion+CubeMX开发，开发板为野火指南者，芯片为STM32F103ZET6.\n简单实现使用串口经过STM32与ESP8266通信。\n","tags":["STM32"],"title":"[HAL]STM32与ESP8266的交互","type":"post"},{"authors":["Lei Yang"],"categories":["代码学习"],"content":"使用Clion+CubeMX开发，开发板为野火指南者，芯片为STM32F103ZET6.\n简单实现使用定时器和按键中断点亮LED。\nCube MX设置 引脚设置 板载RGB-LED使用的引脚PB0，PB1，PB5设置为output push pull（推挽输出）。\n板载微动开关使用的引脚PA0，PC13设置为外部中断且下降沿触发。同时NVIC设置EXTI0和EXTI15-10的使能。\n时钟设置 选择TIM1，时钟源选择内部时钟（Internal Clock）。设置参数为预分频36000，计数为1000，此时频率为72MHz/36000/1000=2Hz。\nNVIC开启TIM1 update interrupt中断。\n其他设置 SYS中设置调试器模式.\nRCC中设置HSE使用外部晶振,在Clock Configuration中设置时钟.\n生成代码时选择根据外设生成对应的.C/.H文件.\nClion代码 在CubeMX设置时为GPIO指定user label。在生成的代码中就会自动定义对应的GPIO端口和引脚。\nLED宏定义 /* USER CODE BEGIN Private defines */ #define ON GPIO_PIN_RESET #define OFF GPIO_PIN_SET #define LED1(a) HAL_GPIO_WritePin(LED1_GPIO_Port, LED1_Pin, a) #define LED2(a) HAL_GPIO_WritePin(LED2_GPIO_Port, LED2_Pin, a) #define LED3(a) HAL_GPIO_WritePin(LED3_GPIO_Port, LED3_Pin, a) #define LED1_ON LED1(ON) #define LED1_OFF LED1(OFF) #define LED1_TOGGLE HAL_GPIO_TogglePin(LED1_GPIO_Port, LED1_Pin) #define LED2_ON LED2(ON) #define LED2_OFF LED2(OFF) #define LED2_TOGGLE HAL_GPIO_TogglePin(LED2_GPIO_Port, LED2_Pin) #define LED3_ON LED3(ON) #define LED3_OFF LED3(OFF) #define LED3_TOGGLE HAL_GPIO_TogglePin(LED3_GPIO_Port, LED3_Pin) #define LED_RED {LED1_ON;LED2_OFF;LED3_OFF;} #define LED_GREEN {LED1_OFF;LED2_ON;LED3_OFF;} #define LED_BLUE {LED1_OFF;LED2_OFF;LED3_ON;} #define LED_YELLOW {LED1_ON;LED2_ON;LED3_OFF;} #define LED_PURPLE {LED1_ON;LED2_OFF;LED3_ON;} #define LED_CYAN {LED1_OFF;LED2_ON;LED3_ON;} #define LED_WHITE {LED1_ON;LED2_ON;LED3_ON;} #define LED_BLACK {LED1_OFF;LED2_OFF;LED3_OFF;} /* USER CODE END Private defines */ 按键中断处理 在stm32f1xx_it.c文件中发现EXTI中断调用HAL_GPIO_EXTI_IRQHandler(void)函数，网上找到的资料说该函数调用弱定义的HAL_GPIO_EXTI_Callback()函数。（虽然我没找到在哪）\n因此在main.c函数中重复定义该函数用于中断处理.\n/* USER CODE BEGIN 4 */ /** * @brief EXTI Handler Callback: KEY Response * @retval None */ void HAL_GPIO_EXTI_Callback(uint16_t GPIO_Pin) { // select target GPIO switch (GPIO_Pin) { case KEY1_Pin:LED1_TOGGLE;break; case KEY2_Pin:LED2_TOGGLE;break; default:break; } } /* USER CODE END 4 */ 时钟中断处理 在stm32f1xx_it.c文件中发现TIM1中断调用HAL_TIM_IRQHandler(void)函数，网上找到的资料说该函数调用弱定义的HAL_TIM_PeriodElapsedCallback()函数。\n因此在main.c函数中重复定义该函数用于中断处理.\n/* USER CODE BEGIN 4 */ /** * @brief TIM Handler Callback: LED Blink * @retval None */ void HAL_TIM_PeriodElapsedCallback(TIM_HandleTypeDef *htim) { // TIM1: LED3 blink if (htim-\u0026gt;Instance == htim1.Instance) { LED3_TOGGLE; } } /* USER CODE END 4 */ ","date":1586315294,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586315294,"objectID":"23f94322bdf0abcc03b8cd554d6a2951","permalink":"https://yangleisx.github.io/post/stm32-interupt-hal/","publishdate":"2020-04-08T11:08:14+08:00","relpermalink":"/post/stm32-interupt-hal/","section":"post","summary":"使用Clion+CubeMX开发，开发板为野火指南者，芯片为STM32F103ZET6.\n简单实现使用定时器和按键中断点亮LED。\n","tags":["STM32"],"title":"[HAL]STM32定时器和按键中断的使用","type":"post"},{"authors":["Lei Yang"],"categories":["代码学习"],"content":"中断的概念是嵌入式开发和计算机系统中非常重要的部分。\n可以参考学堂在线的《ARM微控制器与嵌入式系统》的相关章节。\n两个概念：\nNVIC（嵌套向量中断控制器）：用于设置中断优先级和中断使能。位于芯片内部。 EXTI（外部中断/时间控制器）：用于设置外部中断和事件。位于APB2总线上。 注意：异常和中断清单在stm32f10x.h中的IRQn_Type中。\nNVIC相关的处理位于misc.h中，EXTI相关的处理位于stm32f10x_exti.h中。\n全流程：1. 初始化GPIO 2. 初始化EXTI 3. 配置NVIC使能中断 4. 编写中断服务函数\nNVIC的设置 STM32使用4bit表示中断优先级。通常首先设置优先级分组，共有五种优先级分组，分别使用0-4bit表示主优先级，剩下的表示子优先级。\nNVIC_PriorityGroupConfig(NVIC_PriorityGroup_1); 具体的设置方式使用对应的初始化结构体\nNVIC_InitTypeDef NVIC_InitStructure; NVIC_InitStructure.NVIC_IRQChannel = EXTI0_IRQn;// 中断编号 EXTI0_IRQn NVIC_InitStructure.NVIC_IRQChannelPreemptionPriority = 1; NVIC_InitStructure.NVIC_IRQChannelSubPriority = 1; NVIC_InitStructure.NVIC_IRQChannelCmd = ENABLE;// 中断使能 NVIC_Init(\u0026amp;NVIC_InitStructure); 同时还需要设置中断服务函数，其函数声明写在stm32f10x_it.h中,函数定义写在stm32f10x_it.c中。中断服务函数名在汇编启动文件中定义，与中断名相对应（例如EXTI0_IRQn和EXTI0_IRQHandler）。\n（考虑到相关的宏定义的有效性，也可以写在对应模块的C文件中）\nEXTI的设置 EXTI包括了20个外部中断/事件线。包括中断屏蔽寄存器、边沿选择寄存器、请求挂起寄存器、软件中断事件寄存器。可以从外设事件或者GPIO输入产生中断和事件。其中的中断线路信号传入NVIC内，事件线路信号得到一个脉冲（用于其他的外设使用）。\nGPIO线可以挂载到EXTI的0-15上（注意编号一一对应，例如GPIOA-3挂在EXTI3上），剩下的四根线用于特定的任务。注意这里的EXTI线的具体定义分别为EXTI0、EXTI1、EXTI2、EXTI3、EXTI4、EXTI9_5、 EXTI15_10。位于“stm32f10x_exti.h”中。\n具体的设置方式使用初始化结构体:\n// 先设置GPIO 注意打开AFIO时钟（用于EXTI设置） GPIO_InitTypeDef GPIO_InitStructure; RCC_APB2PeriphClockCmd((RCC_APB2Periph_GPIOA|RCC_APB2Periph_AFIO),ENABLE); GPIO_InitStructure.GPIO_Pin = GPIO_PIN_0 GPIO_InitStructure.GPIO_Mode = GPIO_Mode_IN_FLOATING; GPIO_Init(GPIOA, \u0026amp;GPIO_InitStructure); // 将GPIO挂载到EXTI上 GPIO_EXTILineConfig(GPIO_PortSourceGPIOA,\\ GPIO_PinSource0); // 再设置EXTI线 EXTI_InitTypeDef EXTI_InitStructure; EXTI_InitStructure.EXTI_Line = EXTI_LINE0;// 与GPIOpin对应 EXTI_InitStructure.EXTI_Mode = EXTI_Mode_Interrupt;// Interrupt或者Event EXTI_InitStructure.EXTI_Trigger = EXTI_Trigger_Rising;// Rising或Falling或RIsing_Falling EXTI_InitStructure.EXTI_LineCmd = ENABLE; EXTI_Init(\u0026amp;EXTI_InitStructure); 中断服务函数 中断号和终端服务函数在NVIC中设置，分别参见stm32f10x.h和汇编启动文件的定义。\n中断服务函数需要在stm32f10x_it.h中定义，在stm32f10x_it.c中实现，或者在对应的模块C文件中实现（考虑到宏定义的有效性）。\n中断服务函数中通过EXTI_GetITStatus()获得中断标志位为SET/RESET。处理结束后通过EXTI_ClearITPendingBit()清除中断标志位。\n","date":1585965676,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585965676,"objectID":"886a96d8bbc275ddcd29c85e7ec81610","permalink":"https://yangleisx.github.io/post/stm32-int/","publishdate":"2020-04-04T10:01:16+08:00","relpermalink":"/post/stm32-int/","section":"post","summary":"中断的概念是嵌入式开发和计算机系统中非常重要的部分。\n可以参考学堂在线的《ARM微控制器与嵌入式系统》的相关章节。\n","tags":["STM32"],"title":"STM32的中断操作","type":"post"},{"authors":["Lei Yang"],"categories":["代码学习"],"content":"STM32的时钟主要包括四个部分：系统时钟SYSCLK，AHB总线时钟HCLK，APB2总线时钟PCLK2，APB1总线时钟PCLK1。主要的时钟处理为设置各个时钟的频率和不同总线时钟和外设时钟的开启。\n通常的设置为PCLK2=HCLK=SYSCLK=PLLCLK=72MHz，PCLK1=HCLK/2=36MHz。\n库中自带了SetSysClockTo72()通过寄存器操作实现上述设置,也可以通过RCC库的函数进行具体的设置.\n系统时钟设置 时钟信号有三个来源：高速外部时钟HSE、高速内部时钟HSI(实际使用一半的频率HSI/2)、锁相环倍频输出时钟PLL。其中的PLL时钟的来源可以是HSE或HSI，但是HSI存在漂移，通常不使用。\n通常情况下HSE设置为8MHz, 因此PLL的倍频因子设置为9,从而得到72MHz的系统时钟.\n# 设置HSE或HSI的开启 RCC_HSEConfig(RCC_HSE_ON); RCC_HSICmd(ENABLE); # 设置PLL的输入为HSE或HSI/2 pllmul为倍频因子 RCC_PLLConfig(RCC_PLLSource_HSE_Div1, pllmul); RCC_PLLConfig(RCC_PLLSource_HSI_Div2, pllmul); RCC_PLLCmd(ENABLE); # 设置系统时钟为PLL的输出 RCC_SYSCLKConfig(RCC_SYSCLKSource_PLLCLK); 总线时钟设置 总线时钟通常是在系统时钟的基础上做分频.\nAHB总线时钟为HCLK,是系统时钟在AHB分频器按１分频得到,因此为72MHz.\nAPB2总线时钟为PCLK2 ,是AHB总线时钟在APB2分频器按1分频得到,因此为72MHz.\nAPB1总线时钟为PCLK1,是AHB总线时钟在APB1分频器二分频得到,因此为36MHz.\n外设时钟设置 具体使用外设时的时钟频率要根据需要具体设置.\nUSB时钟:通常令PLL时钟为72MHz,USB时钟为48MHz,通过USB分频器的１.５倍分频实现． Cortex时钟:通常为9MHz,通过HCLK经过8分频得到.用于驱动内核定时器SysTick. ADC时钟：最高为14MHz,具体根据使用情况选择.通过PCLK2分频得到. RTC时钟:可以通过HSE/128或LSE或HSI提供. 独立看门狗时钟:通过LSI提供. MCO信号输出:对外提供时钟信号,通过复用GPIO实现.时钟来源可以是PLLCLK/2,HSI,HSE,SYSCLK GPIO信号输出:使用RCC_APB2PeriphClockCmd(RCC_APB2Periph_GPIOx, ENABLE);开启 ","date":1585965673,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585965673,"objectID":"840845c8b1e194c3bb7dd435921aaace","permalink":"https://yangleisx.github.io/post/stm32-clock/","publishdate":"2020-04-04T10:01:13+08:00","relpermalink":"/post/stm32-clock/","section":"post","summary":"STM32的时钟主要包括四个部分：系统时钟SYSCLK，AHB总线时钟HCLK，APB2总线时钟PCLK2，APB1总线时钟PCLK1。主要的时钟处理为设置各个时钟的频率和不同总线时钟和外设时钟的开启。\n","tags":["STM32"],"title":"STM32的时钟处理","type":"post"},{"authors":["Lei Yang"],"categories":["实用工具"],"content":"Windows下使用CLion和CubeMX构建STM32开发环境。\n使用野火指南者开发版，芯片为STM32F103VET6。使用配套CMSIS-DAP调试器。\n下载安装\n下载STM32CubeMx 下载Clion 下载交叉编译工具链GNU Tools Arm Embedded，注意添加系统路径并在cmd测试“arm-none-eabi-gcc -v” 下载MinGW，注意至少安装gcc，g++，cmake 下载OpenOCD 设置Clion\nFile——Settings——Build，Excution，Deplotment——Toolchains，设置好mingw File——Settings——Plugin，搜索安装插件openocd File——Settings——Build，Excution，Deplotment——Embedded Deployment，设置路径 File——Settings——Build，Excution，Deplotment——OpenOCD support，设置路径 创建CubeMX工程\n选择芯片 选择功能及其对应的引脚 选择sys功能，选择使用串口下载或者使用调试器 时钟配置，使用HSE，9倍PLL，APB1选择2分频 选择保存路径，选择工具为SW4STM32 生成配置代码 Clion导入工程\n选择Cube MX生成的代码，默认选项导入\nTool——Update CMake to STM32 Projects（可以设为自动导入）\nBuild——编译Project或者编译“OCD+你创建的工程名“\nRun——Edit Configuration——OpenOCD——Board config file——选择一个stm32f10系列的板子（我选择stm32f103c8_blue_pill，之后修改）——点击Cope to Project\u0026amp;Use\n修改cfg文件，添加野火的调试器。\n# 选择对应调试器 source [find interface/cmsis-dap.cfg] # 选择模式，这里的swd对应Cube MX设置”5线JTAG“ 对应野火调试器直接插指南者的”SWD“ transport select swd # 选择片上FLASH大小 set FLASH_SiZE 0x80000 # 选择芯片 source [find target/stm32f1x.cfg] 运行\n在main.c的对应位置添加代码，注意需要添加在指定的user code部分，否则更新后可能被覆盖 Run——点击Run ”OCD+你创建的工程名“ 参考链接：紫色能量的博客\n","date":1585965406,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585965406,"objectID":"9a7d193f51f1ac4142783ad86527116c","permalink":"https://yangleisx.github.io/post/stm32-clion/","publishdate":"2020-04-04T09:56:46+08:00","relpermalink":"/post/stm32-clion/","section":"post","summary":"Windows下使用CLion和CubeMX构建STM32开发环境。\n使用野火指南者开发版，芯片为STM32F103VET6。使用配套CMSIS-DAP调试器。\n","tags":["STM32"],"title":"Clion开发STM32环境搭建","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文题目：ABS: Scanning Neural Networks for Back-doors by Artificial Brain Stimulation\n会议：CCS2019\n作者：Y. Liu .etc from Purdue University\n链接：原文链接\n论文目标/现存问题 预训练的人工智能模型可能存在一些通过训练或更改模型参数而插入的后门（AI木马）。这些模型在处理普通的输入时会得到正确的结果，但是在遇到特殊的输入数据时会出现错误的分类结果，这里的特殊输入数据通常含有称为trojan trigger的特殊模式/特征。\n因此文章实现了一种技术，通过为神经元引入不同级别的激励来检测其输出的变化而逆向构建出trojan trigger，从而证明AI模型有没有收到AI木马攻击。\n相关工作/现状 由于训练模型在搜集数据和计算能力方面的要求，越来越多的预训练模型开始在网络上传播，这些模型往往经由大的服务商训练，但是也存在一些经过个人训练或者再训练(retrain)的模型。就像传统软件的木马或者后门一样，预训练的模型也可能被AI木马攻击或者插入后门。\nGu et al.等1在2017年的研究表明通过污染训练数据可以得到藏有后门的模型，即“Data Poisoning”。此时需要攻击者可以参与训练的过程，接触到数据集并对数据进行相关操作，包括添加碎片（patch）或者扰动（perturbation）。\nLiu et al.等2的研究证明劫持部分神经元并使用精心构造的数据训练也可以藏入后门，即“Neuron HiJacking”。此时攻击者得到预训练的模型，从中选择一部分关键神经元并构造可以使这些神经元产生错误输出的触发器并再次训练部分模型。\n通常被藏入后门的模型在处理普通的输入数据时可以得到正常的结果（甚至更高的准确率），但是在处理添加了trojan trigger的数据时会得到错误的结果。\n现存的一些检查AI木马的算法具有一些局限性，例如需要提供trojan trigger，造成模型性能的下降，需要大量输入数据样本，或者无法解决特征域的攻击行为。其中比较好的是Nerual Cleanse3，但是仍然无法解决需要样本数量大、需要对trojan trigger的先验知识、无法处理尺寸较大的trojan trigger等缺点。\n这里的trojan trigger可以是输入域（像素级别）或者是特征域。目前的trojan trigger包括两类，分别为基于碎片（patch based trigger）和基于扰动（perturbations based trigger）的触发器。前者为插入图片或者覆盖原图片的一小块图像，后者为在原始数据上添加特定的数据扰动。这两种都属于输入域的攻击。常见的特征域的攻击包括为图片添加滤镜等方式。\n本文思路/解决方案 AI木马的实质是通过改变个别神经元的权重，使得某些特别的数据或行为出现时会激活并导致错误的分类结果。\n本文的算法主要从EBS（Electrical Brain Stimulation）技术中得到启发，该技术向神经元提供不同强度的电刺激并观察结果，从而研究特定神经元的功能。\n本文实现的算法中，通过为神经元提供不同程度的激励，被攻击的神经元就会在个别标签下产生错误的结果，通过这些选定的神经元可以逆向得到trojan trigger，如果该特征/输入可以使得正常的数据得到错误的结果，可以认为该网络存在后门或已被攻击。\n模型要点：1. 成功的AI木马攻击必定存在受损的神经元（错误地将trojan trigger看作是目标标签的特征之一）。2. 受损神经元在特征空间中的表示是目标标签的子空间。\n因此在具体的实现中，给定输入数据得到每一层神经元的激活信息，当选定神经元的激活信息改变时，检查输出信息的变化情况，可以判断该神经元的状态（当其他神经元激活信息改变时输出稳定于错误的标签时即可判断）。同时通过逆向工程的思想推测trojan trigger并检查消除假阳性的神经元。对每一个标签的检查中仅需要一张正常的照片即可用于神经元状态的分析。\n整体的流程包括三个部分：1. 激励测试并选择候选神经元。2. 对于候选神经元检测并推断trojan trigger。3. 使用trojan trigger对其他数据进行测试。\n结果 本文的主要结果为两个算法，分别用于选择候选神经元，逆向生成trojan trigger。经过测试，本文实现的技术可以检测到绝大多数的AI木马攻击，达到了90%甚至更高的正确率。同时所采用的逆向工程技术可以近似推断得到trojan trigger。\n本文的技术具有同时应对输入域和特征域的攻击行为、需要较少的输入数据、对trigger尺寸不敏感、高效的的特点。\n总结 本文实现的方法存在如下的改进方向：\n测试过程中可能误将目标标签的特征识别为trojan trigger。应当加以区分并避免这样的情况。 对于复杂的基于特征域的攻击难以有效地识别和分析。 对于标签特定的攻击方式难以有效识别和分析，只能识别将所有其他的数据转移为特定标签的攻击方式。 算法效率仍需提升。 仅针对单个神经元进行分析，不能处理多个神经元受更改的情况。 攻击模型的调整。 TianyuGu,BrendanDolan-Gavitt,andSiddharthGarg.2017.Badnets:Identifying vulnerabilities in the machine learning model supply chain. ↩︎\nYingqi Liu, Shiqing Ma, Yousra Aafer, Wen-Chuan Lee, Juan Zhai, Weihang Wang, and Xiangyu Zhang. 2018. Trojaning Attack on Neural Networks. ↩︎\nBolunWang,YuanshunYao,ShawnShan,HuiyingLi,BimalViswanath,Haitao Zheng, and Ben Y Zhao. 2019. Neural cleanse: Identifying and mitigating backdoor attacks in neural networks. ↩︎\n","date":1585575277,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585575277,"objectID":"3a7c053bed226d014223f41ed318be03","permalink":"https://yangleisx.github.io/post/paper-abs-nn/","publishdate":"2020-03-30T21:34:37+08:00","relpermalink":"/post/paper-abs-nn/","section":"post","summary":"论文题目：ABS: Scanning Neural Networks for Back-doors by Artificial Brain Stimulation\n会议：CCS2019\n作者：Y. Liu .etc from Purdue University\n链接：原文链接\n","tags":["Neural Network","Trojan"],"title":"【论文】ABS: Scanning Neural Networks for Back-doors by Artificial Brain Stimulation","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文标题：CloudLeak：Large-Scale Deep Learning Models Stealing Through Adversarial Examples\n会议：Network and Distributed Systems Security (NDSS) Symposium 2020\n论文背景和目标 基于云的机器学习服务（Cloud-Based MLaaS）是指将训练好的深度神经网络部署在云上并通过应用程序接口（API）提供分类和预测任务服务。尽管MLaaS被构建成基于云的黑盒服务，攻击者仍然可以通过精心构建的对抗样本来窃取网络参数。\n论文中实现了一种使用对抗样本窃取网络参数的方法“FeatureFool”，并且证明其相对于其他攻击模型具有更少的请求次数。论文中通过结合几种比较新颖的算法可以达到非常好的效果。\n相关的概念包括：\n迁移学习(Transfre Learning)：识别并将在一个任务上学到的能力应用于另一个不同的任务。文章中通过结合VGG19和DeepID的迁移学习，在具有较好的性能的同时加快了模型窃取的速度。详见Y. Sun等的Deep Learning Face Represatation from Predictiing 1000 CLasses。\n对抗攻击(Adversarial Attack)：在初始输入上增加一个小的扰动使得模型得到错误的预测结果。包括白盒攻击和黑盒攻击。文章中使用DNN内部特征来生成对抗样本的方法，主要通过恶意的特征构建对抗样本并求解可以减小置信度的网络参数。\n模型提取攻击(Model Extraction Attack)：通过目标模型的输入和对应的输出标签/置信度来提取参数并得到一个等效的模型。文章使用迁移学习和对抗样本结合的方法提取网络模型。\n主动学习(Active Learning)：模型选择并推送关键的样本（难以分类）要求用户打上标签，从而提高训练呢和预测效率。文章通过对抗样本的构建，解决了主动学习中边界样本趋于相同的问题，\n基于云的机器学习服务平台(Cloud-based MLaaS Platform)：指为终端用户提供提供机器学习解决方案的平台，包括模型训练、预测分析等。文章重点介绍了五个MLaaS Platform即Microsoft、Face++、IBM、Google、Clarifai。这些服务通常要求用户提供已标注的数据，由平台训练后提供API用于预测。整个过程是黑盒服务，用户不能接触到训练好模型内部的细节。\n相关工作 其他人的成果 一方面通过攻击可以盗取网络内部参数，称为模型提取攻击（Model Extraction Attack）。\n例如2016年，F. Tramèr等实现了第一个模型提取攻击方法Stealing Machine Learning Models vis Prediction APIs，通过模型预测结果和输入数据来学习模型内部参数。\n其他的工作还有B. Wang等的Stealing Hyperparameters in Machine Learning、A. Dmitrenko等的Dnn Model Extraction Attacks Using Prediction Interfaces、Y. Shi等的How to Steal a Machine Learning Classifier with Deep Learning。\n另一方面通过攻击可以盗取网络的训练集，称为成员推理攻击（Membership Inference Attack）。\n2017年，R. Shokri等实现了一种成员推理攻击方法Membership Inference Attacks against Machine Learning Models，可以判断目标模型的训练集是否包含某一条特定的数据。\n其他的工作还有Y. Long等的Understanding Membership Inference on Well-generalized Learning Models。\n存在一些应对模型提取攻击的防御方案，大多都是在预测请求过程(query process)中加以处理，但是难以同时满足性能和效率的要求。例如M. Juuti等的Prada: Protecting against DNN Model Stealing Attacks。\n局限性 目前大多数模型攻击方法只能应用于比较简单的小规模机器学习模型中。 目前的攻击方法的请求规模与模型参数成比例。在攻击含有百万量级参数的大型网络时效率低下。 本文解决方案 模型假设 攻击者对网络模型的结构、参数、训练集没有先验的信息。但是可以使用任意输入并得到对应的预测结果。\n模型思路 通过使用对抗样本请求模型预测并得到结果，使用输入输出对（input-output pair）训练从候选库中选择出来的替代模型，从而实现对目标模型参数的窃取。实际上，通过使用预测结果可以大量减少标记成本并得到训练替代模型的数据集。基本流程为：1.生成对抗样本得到合成数据集。2.请求目标模型得到输出结果。3.根据模型输出标记对抗样本。4.使用合成数据集训练替代模型。\n符号定义 目标网络$f_v(x)$的输入为$x$，输出 $[f_v^1(x),f_v^2(x)…]$，学习目标为在构造的数据集 $T={(x, f_v(x))}$上训练一个替代模型（网络）$f_s(x)$使得两者具由基本相同的功能。攻击者对于目标网络的结构$A$、参数$W$、训练集$D$没有任何先验的信息。\n模型实现 数据集生成 基于边界的对抗性主动学习（Margin-based Adversarial AL）：从未标记的样本中选择一组“有用的”样本。即从生成的未标记样本中选择预测置信度最低、预测不确定性最大的样本 $$\\mathit{Q}_{multiclass}^{LC}:\\mathbb{x}_s^* \\in arg\\min\\limits_{x\u0026#39;\\in D_u(x)}k(x\u0026#39;,y,w)$$ 注意这里得到的样本太多，预测时需要大量的请求次数，因此采用进一步采样得到更小的数据集。\n这里的采样方式包括：随机采样（Random Sample，RS）、投影梯度下降（Projected Gradient Descent）、Carlini \u0026amp; Wagner 攻击（Carlini and Wagner Attack，CW）、Feature Adversary（FA）、FeatureFool（FF， 本文提出的算法）。\n在使用上述FF算法求解时使用L-BFGS算法进行优化求解并使用平均测量误差（Average Test Error，ATE）方法衡量数据集质量。其优化流程主要为：1.确定原图像和目标图像。2.原图像加扰动后加入特征提取网络。3.选择网络中指定特征层的输出得到显著图。4.比较显著图与目标图像的显著图并加以优化。\n替代模型训练 随机选择一组初始化数据集，并使用上述各种算法得到一组小规模的对抗样本。这些样本可以很容易地使本地的替代模型得到错误的预测结果。 使用对抗样本请求预测并得到构造数据集。使用几种训练好的模型（AlexNet、VGG19、VGGFace、ResNet50）构建迁移学习框架，使用构造数据集训练并更新上述框架的最后几层全联接的参数。 重复使用本地模型构建对抗样本并请求预测，使用预测结果构建数据集进行训练的过程。最终得到性能足够逼近目标模型的替代模型。 结果 作者选择了三个平台的四种模型进行了攻击演示。经测试，使用文章设计实现的FF算法在多数目标平台上可以实现比较好的效果。而且与现存的三种模型提取攻击相比，具有更高的准确度和相同准确率下更少的请求次数，从而具有更少的学习成本。\n使用现有的PRADA检测机制可以发现，文章实现的算法可以很好的逃避PRADA机制的检测，即相比其他的攻击方式，要想检测到本文实现的攻击需要更多的请求次数。文章推荐的检测方式为通过提取网络每一层的特征数据来区分恶意数据和合法数据的特征分布。\n总结分析-局限性 攻击请求方式的改进：文章实现的方法中，通过对正常数据添加扰动构建攻击样本，造成了数据污染，从而降低了替代模型的预测准确率。\n多标签任务的扩展：文章实现的方法仅能用于单标签的多分类任务，因此需要在数据生成和替代样本结构选择上更加注意。\n其他学习领域的扩展：文章实现的方法仅能用于图像分类任务，因此在处理音频或文字时需要对模型做相应的调整。\n","date":1584428278,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1584428278,"objectID":"a27dcc9185f11801d14c024a4b3ed171","permalink":"https://yangleisx.github.io/post/paper-cloudleak/","publishdate":"2020-03-17T14:57:58+08:00","relpermalink":"/post/paper-cloudleak/","section":"post","summary":"论文标题：CloudLeak：Large-Scale Deep Learning Models Stealing Through Adversarial Examples\n会议：Network and Distributed Systems Security (NDSS) Symposium 2020\n","tags":["Deep Learning"],"title":"【论文】CloudLeak: Large-Scale Deep Learning Models Stealing Through Adversarial Examples","type":"post"},{"authors":[],"categories":["代码学习"],"content":"背景 之前使用过C++和QT开发具有GUI的小工具。考虑到人生苦短，决定转到使用PyQt，因此在mac上搭建PyQt工作环境。由于电脑上已经安装了QtCreator和Qt环境，网上也有很多教程因此不再赘述。\n环境搭建 为了干净我选择使用virtualenv构建用于PyQt的虚拟环境。\n$ virtualenv pyqtenv $ source pyquenv/bin/activate (pyqtenv)$ pip install PyQt5 似乎Qt Creator的python项目默认使用PySide2，但是在新建项目或者文件的时候有一个\u0026#34;Qt Module\u0026#34;的选项可以选择PyQt5或者PySide2。我选择PyQt5。\n需要注意执行前在Qt Creator的项目选项中选择Python解释器，即选择所安装的虚拟环境目录。通常情况下QtCreator会发现并自动生成“pyqtenv virtual environment”，如果没有自动生成则需要在manage选项中手动添加并选择执行路径\u0026#34;/path_to_your_env/pyqtenv/bin/python\u0026#34;。\n测试代码 由于人生苦短，我选择使用Qt Designer进行UI设计，如果是喜欢手撸代码的大佬请跳过以下内容。\n在Qt Creator中选择新建Qt Designer Form得到ui文件，并通过Qt Designer设计界面。得到mainwindow.ui界面文件。此时需要注意要将界面文件导入py项目需要使用PyQt5自带的一个工具pyuic5编译得到UI类。（如果有更好的方法欢迎告诉我，我也不想这么麻烦）\n$ source pyquenv/bin/activate (pyqtenv)$ pyuic5 -o ui_mainwindow.py mainwindow.ui 之后就可以在Qt Creator中添加ui编译得到的py文件，一种方法是使用UI类作为基类之一并使用self.setupUI(self)。还有一种方法是使用UI类作为成员，即self.ui = Ui_MainWindow()。我选择前者，代码如下。\nimport sys from PyQt5.QtWidgets import QApplication, QMainWindow from ui_mainwindow import Ui_MainWindow class MainWindow(QMainWindow, Ui_MainWindow): def __init__(self): super(MainWindow, self).__init__() self.setupUi(self) if __name__ == \u0026#34;__main__\u0026#34;: app = QApplication([]) window = MainWindow() window.show() sys.exit(app.exec_()) 可以正常实现自己设计的UI界面就表明没啥问题了。\n","date":1584241518,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1584241518,"objectID":"22b0c1f66b5b70ec608e86e07988e9d3","permalink":"https://yangleisx.github.io/post/pyqt-env/","publishdate":"2020-03-15T11:05:18+08:00","relpermalink":"/post/pyqt-env/","section":"post","summary":"背景 之前使用过C++和QT开发具有GUI的小工具。考虑到人生苦短，决定转到使用PyQt，因此在mac上搭建PyQt工作环境。由于电脑上已经安装了QtCreator和Qt环境，网上也有很多教程因此不再赘述。\n","tags":["Python","Qt"],"title":"PyQt 工作环境搭建","type":"post"},{"authors":["Lei Yang"],"categories":["代码学习"],"content":"概念 dlib可以检测图像中的人脸，并且可以检测出人脸上的68个关键点，其中后20个点表示了唇部的关键点，因此可以使用dlib检测人脸并通过嘴部关键点得到嘴部图像。\n代码 import dlib import cv2 import numpy as np from PIL import Image # 加载面部检测模型 predictor_path = \u0026#39;.\\\\shape_predictor_68_face_landmarks.dat\u0026#39; detector = dlib.get_frontal_face_detector() predictor = dlib.shape_predictor(predictor_path) # 检测面部并选择 faces = detector(img, 1) face = faces[0] # 检测关键点并选择唇部 points = predictor(img, face) mouth_points = [(point.x, point.y) for point in points.parts()[48:]] # 截取唇部图像 center = np.mean(mouth_points, axis=0).astype(int) rect = cv2.boundingRect(np.array(mouth_points)) ratio = rect[2] / rect[3] # 给定输出规模shape=[width, height] if shape[0] / shape[1] \u0026gt; ratio: shape[0], shape[1] = shape[0] / shape[1] * rect[3], rect[3] else: shape[0], shape[1] = rect[2], shape[1] / shape[0] * rect[2] mouth_img = img[int(center[1] - shape[1] / 2):int(center[1] + shape[1] / 2), int(center[0] - shape[0] / 2):int(center[0] + shape[0] / 2)] # 保存图像 Image.fromarray(mouth_img).save(\u0026#34;img_path\u0026#34;) 参考：张宏伦的知乎专栏\n","date":1584239496,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1584239496,"objectID":"46c75e96b9e9987677241a9abe7123c3","permalink":"https://yangleisx.github.io/post/python-dlib/","publishdate":"2020-03-15T10:31:36+08:00","relpermalink":"/post/python-dlib/","section":"post","summary":"概念 dlib可以检测图像中的人脸，并且可以检测出人脸上的68个关键点，其中后20个点表示了唇部的关键点，因此可以使用dlib检测人脸并通过嘴部关键点得到嘴部图像。\n","tags":["Python","Computer Vision"],"title":"使用dlib提取图像中人的嘴部","type":"post"},{"authors":["Lei Yang"],"categories":["代码学习"],"content":"以STM32F103VET6点亮LED为例简单记录一下STM32的GPIO如何控制。\nGPIO控制原理 片上外设挂载有三条总线，APB1、APB2、AHB。GPIO挂载在APB2总线上。共有七组GPIO（端口），每个GPIO有16个引脚（位）。\nGPIO的行为通过7个寄存器来控制，每个寄存器为32bit。\n七个寄存器分别为CRL（低八位的控制寄存器）、CRH（高八位的控制寄存器）、IDR（输入数据寄存器）、ODR（输出数据寄存器）、BSRR（端口位设置/清除寄存器）、BRR、LCKR。\nCRH和CRL：每四位为一组控制一位的IO。其中低两位控制运行模式（输入、2MHz输出、10MHz输出、50MHz输出），高两位控制IO配置（输入：模拟、浮空、上/下拉。输出：推挽、开漏）。使用宏定义的工作模式时，每一个宏使用8bit数字表示，实际写入的时候写入的是bit[3:2]。\nBSRR（端口位设置/清除寄存器）：低16位触发时表示ODR对应位置1，高16位触发时表示ODR对应位置0。\nBRR（端口位清除寄存器）：低16位触发时表示ODR对应的位置0。\nODR（输出数据寄存器）：对应的位置0或置1表示对应引脚高低电平。\nIDR（输入数据寄存器）：使用上下拉输入的时候保存输入引脚的值0或1。\n需要注意的是，GPIO使用前要进行时钟的使能，此时使用RCC_APB2ENR寄存器激活APB２总线上的对应外设。其中ｂｉｔｓ［８：２］表示七个GPIO。\n使用寄存器操作 开启GPIOB的0号引脚\n// 开启GPIOB的时钟 RCC_APB2ENR |= (1 \u0026lt;\u0026lt; 3); // GPIOB的0号引脚控制位全部置0 GPIOB_CRL \u0026amp;= ~(0x0F \u0026lt;\u0026lt; (4*0)); // GPIOB的0号引脚设置为10MHz推挽输出 GPIOB_CRL |= (1 \u0026lt;\u0026lt; (4*0)); // GPIOB的0号引脚拉低 GPIOB_ODR |= (0 \u0026lt;\u0026lt; 0); 使用标准库操作 使用标准库开启时钟并设置引脚\n// 初始化结构体 GPIO_InitTypeDef GPIO_InitStructure; // 开启时钟 RCC_ARB2PeriphClockCmd(RCC_APB2Periph_GPIOB, ENABLE); // 设置引脚和工作模式 GPIO_InitStructure.GPIO_Pin = GPIO_Pin_0; GPIO_InitStructure.GPIO_Mode = GPIO_Mode_Out_PP; GPIO_InitStructure.GPIO_Speed = GPIO_Speed_50MHz; // 写入工作模式 GPIO_Init(GPIOB, \u0026amp;GPIO_InitStructure); // 引脚置位 GPIO_SetBits(GPIOB, GPIO_Pin_0); GPIO_ResetBits(GPIOB, GPIO_Pin_0); // 或者使用BSRR、BRR、ODR设置 GPIOB-\u0026gt;BSRR |= 0x01; GPIOB-\u0026gt;BRR |= 0x01; GPIOB-\u0026gt;ODR |= 0x01; ","date":1583415424,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583415424,"objectID":"f52199c85ddc40642aa77f0159137e76","permalink":"https://yangleisx.github.io/post/stm32-gpio/","publishdate":"2020-03-05T21:37:04+08:00","relpermalink":"/post/stm32-gpio/","section":"post","summary":"以STM32F103VET6点亮LED为例简单记录一下STM32的GPIO如何控制。\n","tags":["STM32"],"title":"STM32的GPIO处理","type":"post"},{"authors":["Lei Yang"],"categories":"实用工具","content":"在MacOS上使用的包管理软件主要有MacPorts和Homebrew。由于朋友推荐我一直使用Homebrew作为自己的mac的包管理工具。\n安装 在mac的terminal里面直接运行官网提供的安装命令就可以安装。\n# 安装homebrew /usr/bin/ruby -e \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\u0026#34; # 安装homebrew cask brew tap caskroom/cask 安装homebrew的时候有时候会非常慢，可以根据sipeiyouyang的教程更换下载源。\n# 得到安装脚本 curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install \u0026gt;\u0026gt; brew_install # 更改安装脚本中的下载源地址如下： # BREW_REPO = \u0026#34;https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/brew.git\u0026#34;.freeze # 运行 /usr/bin/ruby brew_install 换源 由于官方的brew源网站在外面，由于众所周知的问题，homebrew经常会遇到速度非常慢或者443 timeout。\n其实homebrew比较不好的一点是，brew update命令的可视化比较差，在运行update的时候经常需要把terminal挂在后台跑很久，因此比较推荐使用-v参数。可以看到具体的update过程，这样出现问题也可以容易的发现问题出在哪里。\n# 可视化更新 brew update -v 更换国内中科大的源，根据知乎专栏。\n# 更换源 cd \u0026#34;$(brew --repo)\u0026#34; git remote set-url origin https://mirrors.ustc.edu.cn/brew.git # 更换核心程序源 cd \u0026#34;$(brew --repo)/Library/Taps/homebrew/homebrew-core\u0026#34; git remote set-url origin https://mirrors.ustc.edu.cn/homebrew-core.git # 更换应用软件源 cd \u0026#34;$(brew --repo)\u0026#34;/Library/Taps/caskroom/homebrew-cask git remote set-url origin https://mirrors.ustc.edu.cn/homebrew-cask.git # 更换bottles源 # 使用bash echo \u0026#39;export HOMEBREW_BOTTLE_DOMAIN=https://mirrors.ustc.edu.cn/homebrew-bottles\u0026#39; \u0026gt;\u0026gt; ~/.bash_profile source ~/.bash_profile # 使用zsh echo \u0026#39;export HOMEBREW_BOTTLE_DOMAIN=https://mirrors.ustc.edu.cn/homebrew-bottles\u0026#39; \u0026gt;\u0026gt; ~/.zshrc source ~/.zshrc 基本用法 其实基本的用法还是比较简单的，就和绝大多数包管理工具都差不多。包括update,upgrade,install,uninstall,search,list这些基本的操作都是比较简单的，基本上看看brew –help就可以了。\n新掌握到的两个工具是\n# 清空brew仓库缓存 brew cleanup # 检查brew运行环境，大多数情况下可以不用管 # 可以根据里面的指示换会官方源 brew doctor ","date":1581602462,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581602462,"objectID":"bda6e409172642e687ba8bc87c44827a","permalink":"https://yangleisx.github.io/post/macos-brew/","publishdate":"2020-02-13T22:01:02+08:00","relpermalink":"/post/macos-brew/","section":"post","summary":"在MacOS上使用的包管理软件主要有MacPorts和Homebrew。由于朋友推荐我一直使用Homebrew作为自己的mac的包管理工具。\n","tags":["MacOS","Homebrew"],"title":"Homebrew使用记录","type":"post"},{"authors":["Lei Yang"],"categories":["实用工具"],"content":"闲来无事简单整理了一下电脑上的pip环境。\n由于最近需要学习PyTorch、Tensorflow和Keras的相关知识。需要使用到这几种框架的Python环境。为了更好的管理电脑上的系统环境，对Mac上的pip环境进行了整理。\n在Windows主机上我主要使用anaconda管理虚拟环境。而在macOS上使用virtualenv管理虚拟环境。主要原因在于之前一直是在mac上使用virtualenv，后来发现anaconda配置环境更加简洁，但是又懒得在mac上换了，于是造成了现在这样的一个情况。\n清空pip包 由于将所有的python环境都使用virtualenv在一个专门的目录中进行管理，因此mac上初始python的各种环境就没有必要再留着了，但是删除的时候不太确定到底那些可以删掉。\n# 查看pip已经安装的各种包 pip list # 使用pip删除对应的包 pip uninstall module_name 查阅相关资料找到了知乎上more wang的回答找到了可以清空pip所有包的方法。可以使当前环境中的pip包全部删除，只剩下pip、setuptools、wheel。\n# 删除pip的所有的包，其实就是列出所有的包然后逐个uninstall pip freeze | grep -v \u0026#34;^-e\u0026#34; | xargs pip uninstall -y pip换源 老生常谈的话题了，网上能找到很多教程，比如这个。\npip删除缓存 默认情况下使用pip安装包的时候，会将包缓存在本地的某个目录中，再次安装时会检查缓存，如果缓存存在的话使用缓存安装包，可以节约时间和流量。\n可以在安装的时候指定不使用缓存。\npip install --no-cache-dir nodule_name 搜索发现CSDN上的一个博客，删除缓存时可以直接删除对应的文件夹。\nLinux and Unix\n~/.cache/pip\nOS X\n~/Library/Caches/pip\nWindows\n%LocalAppData%\\pip\\Cache\n","date":1581600392,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581600392,"objectID":"42a3214a0e74e3001318a6b73f44a5f6","permalink":"https://yangleisx.github.io/post/python-pip/","publishdate":"2020-02-13T21:26:32+08:00","relpermalink":"/post/python-pip/","section":"post","summary":"闲来无事简单整理了一下电脑上的pip环境。\n由于最近需要学习PyTorch、Tensorflow和Keras的相关知识。需要使用到这几种框架的Python环境。为了更好的管理电脑上的系统环境，对Mac上的pip环境进行了整理。\n在Windows主机上我主要使用anaconda管理虚拟环境。而在macOS上使用virtualenv管理虚拟环境。主要原因在于之前一直是在mac上使用virtualenv，后来发现anaconda配置环境更加简洁，但是又懒得在mac上换了，于是造成了现在这样的一个情况。\n","tags":["Python","pip"],"title":"pip相关的一些操作","type":"post"},{"authors":["Lei Yang"],"categories":["代码学习"],"content":"PyTorch学习笔记。基于《Deep Learning with PyTorch》，主要为相关语法的笔记。 用来自己写代码的时候参考。Dataset部分还需要进一步完善。\n环境 import torch import torch.optim as optim import torch.nn as nn import torch.nn.functional as F import torch.utils.data as data from torchvision import transforms torch.nn提供常见的神经网络结构\ntorch.util.data用于加载数据（使用Dataset和DataLoader）\ntorch.optim用于优化\ntorch.nn.DataParallel和torch.distributed用于特定平台的加速计算\ntorchvision.transforms提供常见图形格式的转换\nTensor Basic # 生成tensor \u0026gt;\u0026gt;\u0026gt; a = torch.Tensor([[1.,2.],[2.,3.],[3.,4.]]) \u0026gt;\u0026gt;\u0026gt; b = torch.FloatTensor([1.,2.,3.]) # 查看相关信息 \u0026gt;\u0026gt;\u0026gt; print(a.shape) torch.Size([3,2]) # tensor是按维度一次顺序储存（先行后列） \u0026gt;\u0026gt;\u0026gt; print(a.storage()) \u0026gt;\u0026gt;\u0026gt; print(a[0].stride) \u0026gt;\u0026gt;\u0026gt; print(a[0].storage_offset()) # 通常情况下 obj[i][j] = offset+stride[0]*i+stride[1]*j 使用下标得到的subtensor指向原数据，如果不希望更改原本的数据，需要使用.clone()得到数据的拷贝。\n二维向量使用.t()可以转置。实际上储存空间没有变，只更改了stride()高维向量使用.transpose(d_1,d_2)可以交换指定的两个维度值。\n使用.contiguous()重新排布张量的内部存储使其成为contiguous tensor可以提高运算效率。\n使用.dtype查看元素类型。包括int(8、16、32、64)，uint8，float(16、32、64)，即不同大小的整数和浮点数。默认的Tensor生成的是FloatTensor(float32)。可以在torch.tensor(…, dtype=float)直接指明tensor内部类型。或者使用.float()、.to(float)、.to(dtype=float)转换。\n索引方法和python的list差不多。\npytorch的tensor高度兼容numpy。可以使用.numpy()直接转换为numpy的array对象。或者使用torch.from_numpy(array)从numpy的array转化为tensor。\n使用torch.save(p,f)和p=torch.load(f)可以存取tensor。通常后缀名为.t\n部分pytorch函数支持in-place版本，即a = torch.sqrt(a)可以换成a.sqrt_()，减少空间成本。\nDevice 使用CUDA的环境中，可以将tensor保存在GPU中。建议在程序开始是检测系统环境。\ndev = \u0026#39;cuda\u0026#39; if torch.cuda.is_available() else \u0026#39;cpu\u0026#39; 用于GPU的tensor可以使用torch.tensor(…, device=‘cuda’)生成，或者.to(device=‘cuda’)将其转换为CUDA的格式。便于使用CUDA计算。\n在多GPU的环境中，使用’cuda:0’等来表示所使用的GPU。\n（或者os.enrivon[‘CUDA_VISIBLE_DEVICES’] = ‘0’ ? ）\nData 表格数据 可以使用csv.reader或者np.loadtxt处理\ncsv数据 path = \u0026#34;something.csv\u0026#34; data_numpy = np.loadtxt(path, dtype=np.float32, delimiter=\u0026#39;,\u0026#39;, skiprows=1) # 根据文件情况确定delimiter(, or ;) # skiprows跳过表头 col_list = next(csv.reader(open(path), delimiter=\u0026#39;,\u0026#39;)) # 读取到表头 data_tensor = torch.from_numpy(data_numpy) 数值型target可以看作是一个值，也可以转化为独热码。前者存在大小比较的涵义，后者更多用于分类，没有顺序关系。\n需要注意原本数据取值范围是基于1（1～max）还是基于0（0～max-1），前者需要减1（scatter是基于0的）\n# 独热码生成示例 # target是一个long类型的一维tensor,使用unsqueeze增一个维度 target_oneshot = torch.zeros(target.shape[0],10) target_oneshot.scatter_(1, target.unsqueeze(1), 1.0) # 第一个参数表示独热码维数 # 将第三个参数移动到第二个参数表示的位置上 使用zip()可以将多个可迭代数据（list等）打包成元组的list用于迭代。\n时间序列数据 在单个数据的基础上增加了时间维度，具有顺序特性。\npath = \u0026#34;something.csv\u0026#34; data_numpy = np.loadtxt(path, dtype=nnp.float32, delimiter=\u0026#39;,\u0026#39;, skiprows=1,converters={1: lambda x: float(x[8:10])}) # 这里converters表示对第1列用lambda处理 data_tensor = torch.from_numpy(data_numpy) 使用.view()可以改变数据维度，使用-1参数推测维度值\n使用cat((tensor_1, tensor_2), dim=1)可以将多个tensor按照目标维度连在一起(目标维度上长度为两者之和，其他维度长度不变)。\n数值型数据可以映射到0～1（(data-min)/(max-min)）或者-1～1或者转变为标准正态分布(data - mean)/std\n文本数据 两种方式，针对character的处理和针对word的处理。通常将其转换为独热码。\n对于读入的字符串使用.split(’\\n’)切成行。或者.replace(’\\n’,’ ‘).split()直接得到所有的字符。\n使用.lower()可以变为小写，便于分析。使用.strip()删去对应的字符，没有参数时删除首尾空格。\n针对character的处理可以按照其ASCII码的数值变为独热码。使用ord()可以得到ASCII数字（0～127）。\n针对word的处理可以按照字典文件转变为独热码。或者使用embedding。\n# 创建字典示例 with open(\u0026#39;path\u0026#39;) as f: text = f.read() punctuation = \u0026#39;.,;:\u0026#34;!?”“_-\u0026#39;\u0026#39; # 切分单词 word_list = text.lower().replace(\u0026#39;\\n\u0026#39;, \u0026#39; \u0026#39;).split() # 除去标点 word_list = [word.strip(punctuation) for word in word_list] # 除去重复单词并排序 word_list = sorted(set(word_list)) # 得到字典索引 word2index_dict = {word: i for (i, word) in enumerate(word_list)} 使用embedding可以将字典转化为固定长度的浮点数向量。比较理想的方式是将相近含义或距离比较小的单词映射到距离比较近的向量。通常情况理想的embedding是使用神经网络学习生成的。\n（torch.nn.Embedding(num, dim))\n图像数据 导入图像的方法很多，包括imageio.imread()，PIL.Image.open()，cv2.imread()等。\nimport imageio img_arr = imageio.imread(\u0026#39;path\u0026#39;) image_tensor = torch.tensor(img_arr) # image_tensor = torch.from_numpy(img_arr) from PIL import Image image = Image.open(\u0026#39;path\u0026#39;) iamge_tensor = torch.tensor(np.array(image)) import cv2 image = cv2.imread(\u0026#39;path\u0026#39;) image_tensor = torch.tensor(image) PyTorch处理的图像要求是C * H * W结构，默认图像为H * W * C因此需要torch.transpose()转换一下。如果是视频，应该得到N * C * H * W。\nTensorflow的图像要求是H * W * C\n读取多张图片时可以创建N*C*H*W的tensor再依次读取并存入。或者使用stack()创建。\n图像可以根据网络需求进行缩放，旋转和剪切。\n通常要进行适当的正规化。\n三维数据 例如CT扫描数据，具有三个空间维度。\n通常使用5D的tensor表示 N*C*D*H*W。D、H、W表示三个空间维度。C表示通道（通常为一维通道，类似灰度图像）\nModel 构建模型\nModel Basic 主要成分包括Model(前向传播)、Loss Function、Gradient(反向传播)。\npytorch的tensor提供了requires_grad=True可以自动求导/梯度。指定了自动求导的张量参与的计算会被记录（计算图中的叶子结点），便于求梯度反向传播。拥有.grad成员，默认为None。\n指定自动求导的张量参与计算得到的张量（计算图上层节点）拥有.backward()成员，之后原张量（叶子结点）的.grad成员为该张量（上层节点）对应的梯度。\n注意这里的.grad梯度值为累计得到，使用完毕需要使用.zero_()归零，防止过分累积。同时新的一次计算时使用.detach()将其从计算图中分离\n# 自动梯度举例 def training_loop(n_epochs, learning_rate, params, source, target): for epoch in range(1, n_epochs+1): if params.grad is not None: params.grad.zero_() predict = model(source, *params) loss = loss_fn(predict, target) loss.backward() params = (params - learning_rate * params.grad) \\ .detach().requires_grad_() return params 同样，显示输出结果等对结果进行操作时必须使用detach()从计算图中分离。\nOptim 模型的参数被传入优化器，每当给定输入后计算反向传播和梯度并按照优化器策略自动更新。\n优化器包括zero_grad和step成员，前者清空梯度，后者更新参数。\nimport torch.optim as optim # 创建优化器 params = torch.tensor([1.0,0.0], requires_grad=True) learning_rate = 1e-5 optimezer = optim.SGD([params], …","date":1581501937,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581501937,"objectID":"89d2eb400f24e8ddcd7889738117dfc8","permalink":"https://yangleisx.github.io/post/pytorch/","publishdate":"2020-02-12T18:05:37+08:00","relpermalink":"/post/pytorch/","section":"post","summary":"PyTorch学习笔记。基于《Deep Learning with PyTorch》，主要为相关语法的笔记。 用来自己写代码的时候参考。Dataset部分还需要进一步完善。\n","tags":["PyTorch","Deep Learning"],"title":"PyTorch学习笔记","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文题目: Attention is All You Need\n开源项目地址:github\n主要内容 文章实现了一种仅使用attention机制，完全去除卷积网络和循环网络的结构，称为Transformer网络。\n在实现比较高的准确性的基础上，具有较低的计算成本。\n背景 目前常用的序列处理模型通常使用一个编码器和一个解码器，在两者的连接中使用attention机制，而且编码器和解码器的实现使用复杂的CNN和RNN。\n由于RNN结构引入的时序逻辑不利于并行计算，引入比较高的计算成本。因此Transformer结构中除去了RNN而仅使用attention结构来学习序列前后的相关性。\n在transformer中仅使用self-attention机制来学习序列中不同元素之间的关系。\n实现 使用self-attention和full connect实现。\n编码器的实现中，使用若干个块，每个块包括一个multi-head attention层和一个全联接的feed foward层，其中每一层都引入了残差连接和正规化，构成$LayerNorm(x + Sublayer(x))$的结构。\n解码器的实现中，同样使用若干个块，每个块为编码器的基本块之前加上一个masked multi-head attention结构。同时将上一时刻的输出作为下一个时刻的输入，使得输出仅由之前的输入决定。\nScaled Dot-Product Attention的结构为将Q(uery)、K(ey)、V(alue)映射得到输出。输入为$d_k$维的Key向量和$d_v$维的Value向量，计算方法为矩阵相乘的结果缩放后再Softmax得到Value元素对应的权重，即$Attention(Q,K,V) = Softmax(\\frac{QK^T}{\\sqrt{d_k}})V$。使用矩阵乘法的实现计算更快。\nMulti-head Attnetion为多个Attention层组合得到。通过将V、K、Q线性投影到h个attention网络，将其结果通过concat组合之后再线性投影得到结果，即$MultiHead(Q,K,V) = Concat(head_1,hed_2…)W^O$，其中$head_i = Attention(QW^Q_i, KW^K_i, VW^V_i)$。\n注意解码器的Q来自解码器上一输出经过Masked Multi-Head Attention的结果，K、V来自编码器的输出。而编码器的Q、K、V来自上一层的输出。\n在Masked Multi-Head Attention中，SoftMax的输出被屏蔽（设置为$-\\infty$）。\n在Attention之后的Feed Forward网络中，使用两次ReLU得到$FFN(x) = max(0, xW_1+b_1)W_2+b_2$。\n对于输入，还需要进行embedding和positional encoding操作。使用learned embeddings将输入转化为向量。后者引入顺序和位置信息，使用$PE_{(pos,2i)} = sin(pos/10000^{2i/d_{model}})$和$PE_{(pos,2i+1)} = cos(pos/10000^{2i/d_{model}})$，其中pos为位置，i为维数。\n对于输出，使用线性转换（learned linear transformation）和softmax将输出转变为概率。这里的线性转换和输入的embeddings使用相同的权重（embedding中乘$\\sqrt{d_{model}}$,即向量规模的平方根）。\n评价 使用attention相比直接使用卷积或循环，计算复杂度比较低，同时更有利于并行计算。\n同时attention结构更有助于学习长句子，能学习到距离较远的信息。\n","date":1580805641,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580805641,"objectID":"5ebb063cc1b576d5dc5d5651be221bd3","permalink":"https://yangleisx.github.io/post/paper-transformer/","publishdate":"2020-02-04T16:40:41+08:00","relpermalink":"/post/paper-transformer/","section":"post","summary":"论文题目: Attention is All You Need\n开源项目地址:github\n","tags":["Deep Learning","Machine Translate"],"title":"【论文】Attention is All You Need","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"Deep Residual Learning for Image Recognition\n主要内容 构建了一种残差网络结构，有利于深度神经网络的训练，同时证明了该残差网络结构更容易优化并且在深度增加时仍能实现较高的准确率。同时训练了一个152层的网络用语图像识别。\n背景 传统的用于图像识别的DCNN通过增加深度可以提高识别性能。但是会出现梯度爆炸/消失的现象（vanishing/exploding gradient）。\n通过引入正则化等方法可以使深度网络实现收敛（SGD）。尽管可以收敛，但深度增加时会出现性能下降（degradation）。\n因此文中实现了一种残差网络deep residual learning，用来解决degradation问题。\n主要方式为：要学习得到H(x)，构造F(x)=H(x)-x并学习，最终得到F(x)+x即为所学习的目标。这里的+x可以使用短接（shortcut connection：跳过若干层的连接）来实现。这样的操作相当于恒等映射，没有引入新的参数或计算复杂度。\n实现 通过使用短接可以使得非线性的网络更好的拟合恒等映射，即令网络参数为0。\n因此构造的网络形如 $y = F(x,{W_i})+x$ 。使用两层网络和ReLU构造网络块得到 $F = W_2\\sigma(W_1x)$，其中 $\\sigma$表示ReLU，最终的输出为 $\\sigma{y}$。可以添加一个矩阵 $W_s$ 用于将F的输出和x的规模对齐。\n这里F的结构可以使用两层或三层网络，但是不能只有一层（实际上构成一个线性单元）。同时每一层的结构可以是全联接层也可以是卷积层。\n类比VGG-19网络，构造一个34层的深度卷积神经网络，以及其对应的深度残差网络。其中后河通过在前者的网络结构中每隔两层添加一个短路连接得到。\n评价 相对于普通的深度网络，深度残差网络更容易训练。\n相对于相同深度的网络，深度残差网络可以得到更高的准确度。\n当网络深度增加时，使用深度残差网络可以缓减错误率上升的情况。\n短路连接使用不同的方式（直接映射/规模不同时使用矩阵/全部使用矩阵）可以带来轻微的性能提升，但直接映射的复杂度比较低。\n","date":1580723174,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580723174,"objectID":"90e49ab48dbab06faaa8a4f22c4b1178","permalink":"https://yangleisx.github.io/post/paper-resnet/","publishdate":"2020-02-03T17:46:14+08:00","relpermalink":"/post/paper-resnet/","section":"post","summary":"Deep Residual Learning for Image Recognition\n","tags":["Deep Learning","Computer Vision"],"title":"【论文】Deep Residual Learning for Image Recognition","type":"post"},{"authors":["Lei Yang"],"categories":["实用工具"],"content":"TMUX 使用\n参考网上一些博客的教程1。同时参考了一些自主定制tmux功能的教程2。\n仅用于使用参考。\n关键概念 会话 session：用户和终端的交互。允许创建多个会话，关闭时内部进程不会终止，允许再次进入，直至被终止。\n窗口 window：每个会话可以创建多个窗口，可以相互切换。\n窗格 pane：每个窗口可以创建多个窗格，用于同时处理多个命令行界面。\n前缀：所有操作的快捷键要求以ctrl+b启动。\n安装和启动 使用对应平台的包管理工具直接安装\n# 启动第一个会话 $ tmux # 查看快捷键 $ tmux list-keys # 查看命令 $ tmux list-commands # 查看会话信息 $ tmux info 会话管理 功能 命令 快捷键 注意 创建会话 tmux new -s \u0026lt;name\u0026gt; 默认会话名为基于0的数字 分离会话 tmux detach ctrl+b d 会话和进程在后台运行 查看会话 tmux ls ctrl+b s 查看被分离的会话 接入会话 tmux attach -t \u0026lt;name\u0026gt; 杀死会话 tmux kill-session -t \u0026lt;name\u0026gt; 建议在会话内部使用exit 切换会话 tmux switch -t \u0026lt;name\u0026gt; 重命名会话 tmux rename-session -t \u0026lt;name\u0026gt; \u0026lt;new name\u0026gt; ctrl+b $ 窗格操作 功能 命令 快捷键 注意 上下划分 tmux split_window ctrl+b \u0026#34; 左右划分 tmux split_window -h ctrl+b % 移动光标 tmux select-pane -[UDLR] ctrl+b 方向键 参数表示上下左右移动 交换窗格位置 tmux swap-pane -[UDLR] ctrl+b [{ } ctrl+o alt+o] 参数表示上下左右移动交换 切换窗格 ctrl+b [o;] 参数表示按编号上下移动 关闭窗格 ctrl+b x 也可以在窗格内使用exit 窗格拆分为窗口 ctrl+b ！ 调整窗格大小 ctrl+b ctrl+方向键 查看窗格序号 ctrl+b q 窗口操作 功能 命令 快捷键 注意 创建窗口 tmux new-window -n \u0026lt;name\u0026gt; ctrl+b c 切换窗口 tmux select-window -t \u0026lt;name\u0026gt; 重命名窗口 tmux rename-window \u0026lt;name\u0026gt; ctrl+b , 为当前窗口重命名 切换窗口 ctrl+b [pn] 表示按编号上下切换 切换窗口 ctrl+b \u0026lt;number\u0026gt; 切换到指定窗口 选择窗口 ctrl+b w 阮一峰的日志 ↩︎\nTmux教程——打造完美的Linux终端 ↩︎\n","date":1580717096,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580717096,"objectID":"ed0245509242521de69530ded7047674","permalink":"https://yangleisx.github.io/post/tmux/","publishdate":"2020-02-03T16:04:56+08:00","relpermalink":"/post/tmux/","section":"post","summary":"TMUX 使用\n参考网上一些博客的教程1。同时参考了一些自主定制tmux功能的教程2。\n仅用于使用参考。\n","tags":["tmux"],"title":"TMUX 使用方式简单记录","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文笔记:Effective Approaches to Attention-based Neural Machine Translation\n开源项目地址：stanford.edu或者github\n主要内容 NMT使用RNN的架构来实现序列到序列的学习。Attention机制被广泛用于训练神经网络并提升其性能。\n因此可以使用attention机制通过聚焦于输入序列的某一部分来提高NMT的性能。\n文中构建了两种使用attention的NMT模型：global模型和locol模型。前者注意输入序列全体，后者每次针对输入序列的一个子集。两种模型的结构都很简单，而且后者的计算成本更低。\n背景 传统NMT模型包括一个编码器和一个解码器，前者将输入映射到固定长度的向量$\\mathbf{S}$，后者将向量映射到输出序列。\n其具体实现有CNN-RNN结构，也有RNN-RNN结构（包括LSTM-LSTM，GRU-GRU等）。\n其他的实现中使用$\\mathbf{S}$作为初始化解码器的工具，而使用attention机制的模型在整个翻译过程中都将$\\mathbf{S}$用做参考。\n实现 使用深度LSTM作为编码器和解码器。\n目标函数为$J = \\sum _{(x,y)\\in \\mathbb{D}}-logp(y|x)$其中$\\mathbb{D}$为训练数据。\nglobel和locol两种不同的模型区别在于内容向量$c_t$的生成方式不同。当内容向量$c_t$生成后，即可计算输出。\n即首先计算attentional hidden state:$\\tilde{h}_t = tanh(W_c [c_t;h_t])$。\n然后得到预测向量 $p(y_t|y_{\u0026lt; t}, x) = softmax(W_s \\tilde{h}_t)$ 。\nglobal attention 考虑到编码器的所有隐含状态，通过编码器状态$\\bar{h}_s$和解码器状态$h_t$通过score()函数得到global align weights即$a_t$，这里的向量$a_t$为可变长度的。最终使用$a_t$对$\\bar{h}_s$加权得到$c_t$从而得到$\\hat{h}_t$.\n具体score函数见文献原文。\nglobal attention考虑到所有的输入符号，计算成本比较高，而且无法处理较长的序列。\nlocol attention 借鉴soft和hard attention的思想1，使用加窗的方式，考虑一部分的隐状态。\n首先确定位置$p_t$，然后根据位于$[p_t-D,p_t+D]$的编码器状态使用相同的score()函数得到$a_t$。不同的是这里的$a_t$为固定长度($2D+1$)的向量。\n关于位置$p_t$的确定有不同的方法。\nlocol-m方法：令$p_t = t$,使用前述方法计算$a_t$。\nlocol-p方法：通过学习到的参数预测，即令$p_t = S·sigmoid(v_p^Ttanh(W_p h_t))$，其中 $v_p$ 和 $W_p$为学习得到的参数，S为输入序列长度。同时计算$a_t = align(h_t,\\bar{h}_s) exp(- \\frac{(s-p_t)^2}{2\\sigma^2})$，其中$\\sigma = \\frac{D}{2}$。\ninput-feeding 将上一输出作为输入传入网络用于产生下一输出。\n具体实现 使用WMT的英语-德语双向翻译任务，共4.5M句子，包括116M英语单词110M德语单词。\n选择其中的50k单词作为训练的单词表。每个LSTM具有四层，每层1000单元，每个单元为1000维张量。\n评价 global attention和local attention相比其他人的实现2更加简单\n通过input-feeding使得之前学习得到的结果得到充分利用，这一方法也可以用于非attention的其他RNN架构的网络中。\n最终训练结果在WMT上得分23.0超过了最好的系统。\n论文实现的系统具有更低的test cost。可以更好的处理长句子。\nShow,Attend and Tell:Neural Image Caption Generation with Visual Attention ↩︎\nNeural Machine Translation by Jointly Learning to Align and Translate ↩︎\n","date":1580653776,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580653776,"objectID":"d9c300df1810c8d2a803047306d986e3","permalink":"https://yangleisx.github.io/post/paper-attention/","publishdate":"2020-02-02T22:29:36+08:00","relpermalink":"/post/paper-attention/","section":"post","summary":"论文笔记:Effective Approaches to Attention-based Neural Machine Translation\n","tags":["Deep Learning","Machine Translate","Attention"],"title":"【论文】Effective Approaches to Attention-based Neural Machine Translation","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文笔记:Sequence to Sequence Learning with Neural Networks\n主要内容 使用一个深度LSTM网络将输入序列映射到固定长度的向量，再使用另一个深度LSTM网络将该向量映射（decode）到目标序列。\n背景 DNN在语音识别和视觉识别领域有非常好的效果，但是仅能用于输入和输出可以化为（encode）相同的固定规模（known and fixed）的向量。很多实际问题中输入和输出需要用未知长度的向量表示。\nLSTM可以在具有长期时间相关性（long range temporal dependencies）的数据中具有比较好的学习效果，因此用于在输入序列和相应的输出序列之间进行学习。\n同时通过在训练中反转输入序列引入短期依赖便于训练和优化。\n实现方式 原理 使用单个RNN由给定输入序列$(x_1,x_2,…,x_t)$计算输出序列$(y_1,y_2,…,y_t)$的方法如下：\n$h_t = sigm(W^{hx}x_t + W^{hh}h_{t-1})$、$y_t = W^{yh}h_t$。但是并不能用于不同长度的输入和输出序列。\n因此使用两个LSTM取代两个RNN来实现长期时间相关性的学习。\n在LSTM中使用条件概率的计算方法如下：\n$p(y_1,…,y_{T’}|x_1,…,x_T) = \\prod_{t=1}^{T’}p(y_t|v,y_1,…,y_{t-1})$，其中v是输入序列的一种表示。\n具体实现中，==使用两个深度LSTM网络，每个网络具有4层，用于训练的输入序列反转。==\n每个LSTM通过最大化对数几率进行训练，目标函数为$\\frac{1}{|S|}\\sum_{(T,S)\\in \\mathbb{S}} logp(T|S)$，其中$\\mathbb{S}$为训练集。\n预测时依据$\\hat{T} = arg max_{\\mathbf{T}} p(T|S)$，使用自左向右的Beam Search算法1得到翻译结果。\n输入序列反转后，训练的性能提高（原文使用“最小时滞 minimal time lag”加以解释：输入序列和输出序列的开头几个单词的距离减小）。可以认为输出序列的前半部分正确率较高而后半部分表现比较差。\n实现 使用WMT\u0026#39;14 英语-法语数据库进行训练。\n每个LSTM网络有4层，每层1000个单元，每个数据使用1000维张量表示。\n输入词汇量160000，输出词汇量80000。输出时使用8000输入的softmax。共有384M参数。\n为了防止梯度爆炸，每一个batch训练结束后对梯度正规化。\n评价 结果 训练结果使用BLEU打分，在WMT‘14数据库上得到37.0分\n结果评价 使用深度LSTM网络实现的sequence到sequence模型在机器翻译问题上取得了不错的效果。\n其在较长的句子上性能比较好。并且可以处理主动语态和被动语态。\n参考 Beam Search ↩︎\n","date":1580653573,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580653573,"objectID":"f86e2b6a0fa5443d1e142cb88535d2ef","permalink":"https://yangleisx.github.io/post/paper-seq2seq/","publishdate":"2020-02-02T22:26:13+08:00","relpermalink":"/post/paper-seq2seq/","section":"post","summary":"论文笔记:Sequence to Sequence Learning with Neural Networks\n","tags":["Deep Learning","Machine Translate"],"title":"【论文】Sequence to Sequence Learning with Neural Networks","type":"post"},{"authors":["Lei Yang"],"categories":["代码学习"],"content":"使用Verilo HDL设计FSM并在MacOS下仿真和生成状态图\nVerilog课程大作业有一个题要求设计FSM并生成状态图。按要求是使用ModelSIM，但是一方面配置Win7并使用ModelSIM太烦了，另一方面由于设计中为了更好的可读性，没有使用ModelSIM要求的可综合的编程规范（我猜大概是这个原因），所以使用ModelSIM的FSM View并不能生成想要的状态图，于是在MacOS中探索了FSM仿真和状态图的生成。\nFSM编写 使用FSM监测0110和1101序列，其中时钟下降沿触发，同步复位。代码如下\nmodule seq_detect(output reg flag, input din, clk, rst_n); reg [8:0] state; parameter IDLE = 9\u0026#39;b0_0000_0001, A0 = 9\u0026#39;b0_0000_0010, A1 = 9\u0026#39;b0_0000_0100, A2 = 9\u0026#39;b0_0000_1000, A3 = 9\u0026#39;b0_0001_0000, B0 = 9\u0026#39;b0_0010_0000, B1 = 9\u0026#39;b0_0100_0000, B2 = 9\u0026#39;b0_1000_0000, B3 = 9\u0026#39;b1_0000_0000; always @(negedge clk) begin if (!rst_n ) begin state \u0026lt;= IDLE; flag \u0026lt;= 1\u0026#39;b0; end else begin case(state) IDLE: if(din) begin state \u0026lt;= A0; flag \u0026lt;= 1\u0026#39;b0; end else begin state \u0026lt;= B0; flag \u0026lt;= 1\u0026#39;b0; end A0: if(din) begin state \u0026lt;= A1; flag \u0026lt;= 1\u0026#39;b0; end else begin state \u0026lt;= B0; flag \u0026lt;= 1\u0026#39;b0; end A1: if(din) begin state \u0026lt;= A1; flag \u0026lt;= 1\u0026#39;b0; end else begin state \u0026lt;= A2; flag \u0026lt;= 1\u0026#39;b0; end A2: if(din) begin state \u0026lt;= A3; flag \u0026lt;= 1\u0026#39;b1; end else begin state \u0026lt;= B0; flag \u0026lt;= 1\u0026#39;b0; end A3: if(din) begin state \u0026lt;= B2; flag \u0026lt;= 1\u0026#39;b0; end else begin state \u0026lt;= B0; flag \u0026lt;= 1\u0026#39;b0; end B0: if(din) begin state \u0026lt;= B1; flag \u0026lt;= 1\u0026#39;b0; end else begin state \u0026lt;= B0; flag \u0026lt;= 1\u0026#39;b0; end B1: if(din) begin state \u0026lt;= B2; flag \u0026lt;= 1\u0026#39;b0; end else begin state \u0026lt;= B0; flag \u0026lt;= 1\u0026#39;b0; end B2: if(din) begin state \u0026lt;= A1; flag \u0026lt;= 1\u0026#39;b0; end else begin state \u0026lt;= B3; flag \u0026lt;= 1\u0026#39;b1; end B3: if(din) begin state \u0026lt;= A3; flag \u0026lt;= 1\u0026#39;b1; end else begin state \u0026lt;= B0; flag \u0026lt;= 1\u0026#39;b0; end default: begin state \u0026lt;= IDLE;flag \u0026lt;= 1\u0026#39;b0; end endcase end end endmodule 仿真 在macOS使用icarus-Verilog仿真器和Scansion查看波形。测试台模块如下：\n`include \u0026#34;seq_detect.v\u0026#34; `timescale 10ns/ 1ns module tb_seq_detect(); wire p_flag; reg p_din, p_clk, p_rst_n; reg [35:0] data = 36\u0026#39;b0000_1100_0010_0110_1001_1011_0010_0001_1101; seq_detect dec(.flag(p_flag), .clk(p_clk), .din(p_din), .rst_n(p_rst_n)); initial begin p_clk = 1\u0026#39;b1; forever #5 p_clk = ~p_clk; end integer k; initial begin p_rst_n = 1\u0026#39;b0; p_din = 1\u0026#39;bx; #7 p_rst_n = 1\u0026#39;b1; for(k = 0; k \u0026lt; 36; k = k + 1) begin #10; p_din = data[35]; data = data \u0026lt;\u0026lt; 1; end #20 $finish; end initial begin $monitor($time, \u0026#34; rst = %b, din = %b, flag = %b\u0026#34;, p_rst_n, p_din, p_flag); $dumpfile(\u0026#34;tb_seq_detect.vcd\u0026#34;); $dumpvars(0, tb_seq_detect); end endmodule 仿真步骤如下，可以得到Monitor输出和vcd波形文件\niverilog tb_seq_detect.v vvp a.out open -a Scansion tb_seq_detect.vcd 生成状态图 可以使用Graphviz工具根据dot文件生成状态图。\ndot文件的基本格式如下，即定义图的边以及标签。\ndigraph fsm { \u0026#34;IDLE/flag=0\u0026#34; -\u0026gt; \u0026#34;A0=1/flag = 0\u0026#34; [ label = \u0026#34;0\u0026#34; ] \u0026#34;IDLE/flag=0\u0026#34; -\u0026gt; \u0026#34;B0=0/flag=0\u0026#34; [ label = \u0026#34;0\u0026#34; ] \u0026#34;A0=1/flag = 0\u0026#34; -\u0026gt; \u0026#34;A1=11/flag=0\u0026#34; [ label = \u0026#34;0\u0026#34; ] \u0026#34;A0=1/flag = 0\u0026#34; -\u0026gt; \u0026#34;B0=0/flag=0\u0026#34; [ label = \u0026#34;0\u0026#34; ] \u0026#34;A1=11/flag=0\u0026#34; -\u0026gt; \u0026#34;A1=11/flag=0\u0026#34; [ label = \u0026#34;0\u0026#34; ] \u0026#34;A1=11/flag=0\u0026#34; -\u0026gt; \u0026#34;A2=110/flag=0\u0026#34; [ label = \u0026#34;0\u0026#34; ] \u0026#34;A2=110/flag=0\u0026#34; -\u0026gt; \u0026#34;A3=1101/flag=1\u0026#34; [ label = \u0026#34;0\u0026#34; ] \u0026#34;A2=110/flag=0\u0026#34; -\u0026gt; \u0026#34;B0=0/flag=0\u0026#34; [ label = \u0026#34;0\u0026#34; ] \u0026#34;A3=1101/flag=1\u0026#34; -\u0026gt; \u0026#34;B2=011/flag=0\u0026#34; [ label = \u0026#34;0\u0026#34; ] \u0026#34;A3=1101/flag=1\u0026#34; -\u0026gt; \u0026#34;B0=0/flag=0\u0026#34; [ label = \u0026#34;0\u0026#34; ] \u0026#34;B0=0/flag=0\u0026#34; -\u0026gt; \u0026#34;B1=01/flag=0\u0026#34; [ label = \u0026#34;0\u0026#34; ] \u0026#34;B0=0/flag=0\u0026#34; -\u0026gt; \u0026#34;B0=0/flag=0\u0026#34; [ label = \u0026#34;0\u0026#34; ] \u0026#34;B1=01/flag=0\u0026#34; -\u0026gt; \u0026#34;B2=011/flag=0\u0026#34; [ label = \u0026#34;0\u0026#34; ] \u0026#34;B1=01/flag=0\u0026#34; -\u0026gt; \u0026#34;B0=0/flag=0\u0026#34; [ label = \u0026#34;0\u0026#34; ] \u0026#34;B2=011/flag=0\u0026#34; -\u0026gt; \u0026#34;A1=11/flag=0\u0026#34; [ label = \u0026#34;0\u0026#34; ] \u0026#34;B2=011/flag=0\u0026#34; -\u0026gt; \u0026#34;B3=0110/flag=1\u0026#34; [ label = \u0026#34;0\u0026#34; ] \u0026#34;B3=0110/flag=1\u0026#34; -\u0026gt; \u0026#34;A3=1101/flag=1\u0026#34; [ label = \u0026#34;0\u0026#34; ] \u0026#34;B3=0110/flag=1\u0026#34; -\u0026gt; \u0026#34;B0=0/flag=0\u0026#34; [ label = \u0026#34;0\u0026#34; ] } 使用Graphviz生成文件具体命令如下\ndot -Tpng fsm.dot \u0026gt; fsm.png circo -Tpdf fsm.dot \u0026gt; fsm.pdf 需要注意Graphviz的输出默认输出到stdcout，因此需要重定向写入到文件。其中-T可以指定输出文件的格式。而dot和circo分别为不同的状态图风格，具体的使用方法可以参见man dot。\n部分内容如下(详细内容自行查看)：\nNAME dot - filter for drawing directed graphs neato - filter for drawing undirected graphs twopi - filter for radial layouts of graphs circo - filter for circular layout of graphs fdp - filter for drawing undirected graphs sfdp - filter for drawing large undirected graphs patchwork - filter for squarified tree maps osage - filter for array-based layouts ... Traditionally, Graphviz supports the following: -Tdot (Dot format containing layout information), -Txdot (Dot format containing complete layout information), -Tps (PostScript), -Tpdf (PDF), -Tsvg -Tsvgz (Structured Vector Graphics), -Tfig (XFIG graphics), -Tpng (png bitmap graphics), -Tgif (gif bitmap graphics), -Tjpg -Tjpeg (jpeg bitmap graphics), -Tjson (xdot information encoded in JSON), ... ","date":1574565274,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574565274,"objectID":"78262099dc764c2caf41e2f00d0db0e6","permalink":"https://yangleisx.github.io/post/verilog-fsm/","publishdate":"2019-11-24T11:14:34+08:00","relpermalink":"/post/verilog-fsm/","section":"post","summary":"使用Verilo HDL设计FSM并在MacOS下仿真和生成状态图\n","tags":["Verilog HDL","Graphviz"],"title":"使用Verilog设计FSM并生成状态图","type":"post"},{"authors":["Lei Yang"],"categories":["代码学习"],"content":"使用Verilog设计电路的一些思路\n注意事项:\n时序逻辑电路使用非阻塞赋值\n组合逻辑电路使用阻塞赋值\n组合逻辑电路 概念：输出仅由当前的输入决定 注意：不能蕴含触发器的逻辑，即==不具有记忆功能==（case语句的default子句、连续赋值语句、电平敏感的always语句） 常见的组合逻辑电路：复用器、译码器、编码器、三态缓冲器、比较器、加法器、乘法器。 实现方法： 使用assign连续赋值语句（数据流级）和==电平敏感==的always行为语句（行为级） 使用always引导的语句块实现对于中间变量的逻辑运算 使用assign引导的连续赋值语句实现==简单变换和多路输出==（如果有的话） 注意：always的使用的中间变量为reg型，assign和子模块使用的中间变量为wire型 设计思路： 给定==电路原理图==：使用门原语和模块实例 给定布尔方程：使用连续赋值语句和==布尔运算==（真值表得到布尔方程） 给定模块功能/IO（==真值表==）：使用行为级描述（if/case配合真值表） 可采用的设计模式： assign连续赋值语句 + 条件表达式（？：） + 布尔运算 always语句块 + 条件表达式（？：） always语句块 + 条件语句（if/case） assign连续赋值语句 + 函数（function [automatic]）可以在数据流语句中引入行为级语句逻辑 always语句块 + 函数（function [automatic]） always语句块 + 任务（task [automatic]） 建议不直接修改输出变量，而是使用中间变量，在输出时使用assign实现（综合好像能得到一个buf） 时序电路 概念：输出由当前输入和内部的状态决定 注意：具有记忆功能，内部包含==锁存器latch（电平敏感）和触发器flip-flop（边沿敏感）==等储存器件，case语句的default子句可以为空 常见时序电路：锁存器latch、触发器flip-flop 实现方法： 使用always引导的语句块（电平敏感或边沿敏感）实现逻辑运算 使用assign引导的连续赋值语句实现简单变换和多路输出（例如assign qbar=～q） ==不能使用门原语==，门原语定义的时序电路不可综合（例如使用两个与非门实现的RS锁存器） 时序逻辑： 同步控制（复位/置位）： 只有在时钟信号的有效跳变沿状态才能改变 always的事件控制列表没有复位/置位信号 语句块中先检查复位/置位信号，然后执行其他逻辑。使用嵌套的if-else可以控制复位/置位/输入逻辑的优先级（==复位\u0026gt;置位\u0026gt;其他逻辑==） 异步控制（复位/置位）： 复位/置位信号激活时立即响应 always的控制列表中包括时钟边沿和复位/置位信号边沿 语句块中先检查是时钟触发的还是复位/置位信号触发的，并执行相应的逻辑。使用嵌套的if-else指定优先级（==复位\u0026gt;置位\u0026gt;其他逻辑==） 可综合电路 关键：使用Verilog HDL中的可综合子集 可综合的Verilog HDL结构 端口：input, inout, output 参数：parameter 模块定义：module 信号和变量：wire, reg, tri 允许向量 实例调用：module instance primitive gate instance 函数任务：function, task 不考虑时序结构 过程：always, if, then, else, case ==不支持initial== 过程块：begin, end, named block, disable 数据流：assign ==不考虑#延迟信息== 循环：for, while, forever 需要包含@(posedge clock)或@(negedge clock) 使用复位机制取代initial进行初始化 赋值 组合逻辑电路使用阻塞赋值= 时序电路使用非阻塞赋值\u0026lt;= 同时描述时序和组合逻辑使用非阻塞赋值\u0026lt;= 编码风格 有意义的信号和变量名 ==避免混合使用上升沿触发和下降沿触发== 使用圆括号而不是运算优先级 条件语句中说明所有的可能情况 不要多个always对同一变量赋值 常见改错题思路 变量类型错误 注意input和output的端口类型检查 变量位宽 赋值方式 阻塞赋值和非阻塞赋值 敏感量列表 always的敏感量列表是电平触发还是边沿触发 位运算/逻辑运算 ","date":1573913499,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573913499,"objectID":"c9f19ff5d2a029d117c07257fc6434c7","permalink":"https://yangleisx.github.io/post/verilog-design/","publishdate":"2019-11-16T22:11:39+08:00","relpermalink":"/post/verilog-design/","section":"post","summary":"使用Verilog设计电路的一些思路\n","tags":["Verilog HDL"],"title":"Verilog电路设计思路","type":"post"},{"authors":["Lei Yang"],"categories":["代码学习"],"content":"简单记录一下verilog的语法，用于日后复习或者参考。\n模块框架 module 模块名 (端口列表); // 端口声明 input input_port; output output_port; // 参数声明 parameter param; // 数据流语句 assign a = b \u0026amp; c; // 模块实例和门原语 subModule Mod1(port1, port2); subModule Mod2(.port1(PORT1),.port2(PORT2)); nand (out, in1, in2); // 过程语句块 always @(*) 过程语句 initial 过程语句 endmodule 基本概念 数字声明：\u0026lt;size\u0026gt;’\u0026lt;base format\u0026gt;\u0026lt;number\u0026gt;\n可以在’之后加s表示有符号数\n建议使用_分割为四个二进制数一组\n使用[begin:end]选择向量的部分位\n使用{a,b,c[3:0]}表示变量拼接\n位宽大的数向位宽小的数赋值：获得低位并截断\n位宽小的数向位宽大的数赋值：高位补0。例如reg[4:0]a;a = 2’bx;得到00xx。\n位扩展时根据最高位扩展x和z。例如4’bx0和4’bz1得到xxx0和zzz1。\n常用系统函数：\n$ time 返回仿真时间\n$ display 显示输出\n$ monitor 监控值的变化，通常第一个参数为$ time，格式类似printf\n$finish 结束仿真\n结构域描述 子模块连接 端口连接规则：\n输入：外界net或reg，内部net 输出：外界net，内部net或reg 双向：外界net，内部net 允许按端口列表顺序相连或者按名字相连 模块也可以定义成实例数组\n通常设计测试台包括四个部分：定义外部与端口相连的变量（通常输入用reg输出用wire），定义模块并相连，initial初始化并控制驱动信号，显示monitor信息等。\n门级建模 门原语属于模块一级，相当于并发语句。\n只能驱动wire型的变量。\nand/or门 包括and,nand,or,nor.xor,xnor六种\n一个输出端和多个输入端，第一个参数为输出端\n真值表中有x/z时，输出通常为x\nbuf/not门 包括buf,not两种\n一个输入端和多个输出端，最后一个参数为输入端\n三态门 包括bufif1,bufif0,notif1,notif0四种\n控制信号是最后一个参数，输入信号是倒数第二个参数\n***要求：***当控制信号关断时，输出信号必须为z。\n控制信号为x/z时，或者输入信号为x/z时，输出通常为x。\n延迟指定 门原语后使用#(上升 下降 关断)制定\n使用#(最小:典型:最大 最小:典型:最大 最小:典型:最大)指定延迟\n上升延迟指变为1，下降延迟指变为0，关断延迟指变为z\n行为域描述 数据流级 连续赋值 连续赋值语句assign，左值一定为net类型\n总是激活，时刻监控，描述组合逻辑\n普通延迟 在assign之后使用#指定延迟\n惯性延迟右端信号保持的持续时间必须大于延时宽度才能使左值改变\n线网延迟 声明wire变量时使用#指定线网延迟\n实际延迟为线网延迟和赋值语句延迟之和\n信号保持的时间要大于两者的最大值\n操作符 向量参与逻辑运算时，首先进行缩减或操作得到逻辑值，使用逻辑值运算\n逻辑等价(== !=)对于含有x/z的操作数结果为x。\ncase等价(=== !==)对于含有x/z的操作数严格的逐位比较。\n三目条件运算符（cond）？expr1:expr2；若cond为1或0，则分别执行expr1和expr2。若cond为x，则诸位比较expr1和expr2，相同的位得到该位的值，不同的位得到x。\n行为级 过程语句块中绝对不能出现连续赋值语句\n过程语句 主要有两种过程语句initial和always\n相互不能嵌套，都是模块级的语句\n要求：initial用于仿真，always用于设计\n不要在不同的语句块中对同一变量进行操作（过程语句的并发性）\ninitial 从时刻0开始执行，只执行一次 所有的initial语句块并发执行 可以使用initial foreveer实现always的功能 always 从时刻0开始执行，无限循环 可以定义局部变量，但是不能定义的同时赋初值 可以用always @(*)实现assign的功能 语句块 不建议两种块混合使用\n可以在begin/fork后用：为块命名\n可以使用disable禁止块的运行\n顺序块 begin-end 顺序执行，延迟是相对于上一语句结束时 并行块 fork-join 并发执行，延迟是相对于整个块 时序控制 基于延迟 常规延迟： #delay a = b; 遇到该语句时，等待delay时间后执行 内嵌延迟 a = #delay b+c 遇到该语句时计算右边，等待delay时间后赋值 零延迟： #0 表示在当前时间步结束时执行 基于事件 常规事件控制（边沿触发） @(posedge clock)、@(negedge clock)、@(clock) 表示正向跳变、反向跳变、值改变 数组中任意一个值变化 OR事件控制 @(cond1 or cond2 or cond3)三个条件满足其一 @(*)语句块中任意元素值改变 命名事件 定义一个事件event aEvent; 满足条件触发事件-\u0026gt; aEvent; 事件触发执行always @(aEvent) 电平敏感（电平触发） 等待条件为真时 wait(cond)\ncond为数组时，使用逻辑值判断\n过程控制 只能用在过程语句块中，不能用于模块一级\nif…else… 多条语句使用begin-end组成一块 case…cond1:…default…endcase 建议必须添加default 逐位比较 casex…cond1:..default…endcase 候选式使用x和z表示无关值 casez…cond1:..default…endcase 候选式使用z表示无关值 while(condition) for(count = 0; count \u0026lt; 128;count = count+1) repeat(times) 以上三种都要在外部声明reg型的循环变了 forever 遇到$finish停止 可以被disable关闭 赋值语句 仅能实现对寄存器的操作\n要求：时序逻辑电路使用非阻塞赋值，组合逻辑电路使用阻塞赋值\n严禁：在always块中混合使用阻塞和非阻塞\n顺序块中的非阻塞赋值和并行块中的阻塞赋值的效果类似，推荐前者。\n阻塞赋值 串行块中，按序执行，有延迟时停止 并行块中，并发执行 非阻塞赋值 串行块中，并发执行，不影响后面的语句 内嵌赋值语句被延迟到在目标时间步结束时执行赋值 并行块中，并发执行 任务和函数 定义在模块内部\n内部不能出现always或initial，只有行为语句\n函数（相当于同名的reg变量 要声明位宽） 可以调用函数，不可以调用任务，出现在assign、always、initial中 遇到即执行，一定不包含延迟和时序控制 返回一个值，不能有output 任务 可以调用函数和任务，出现在initial、always中 可以延迟或时序控制 不返回值，有多个output 行为级语句，处理reg型变量 生成块 在模块一级，使用if，case，while等过程控制来控制门原语、模块调用、数据流赋值等语句生成 使用临时变量genvar控制 使用generate和endgenerate表示开始和结束 循环生成时内部的begin-end块需要命名，以便使用层次命名访问 UDP用户定义原语 格式 primitive upd_and(output y, input a); table // a b : y 0 0 : 0; 0 1 : 0; 1 0 : 0; 1 1 : 1; endtable endprimitive 可以使用？表示无关匹配 ","date":1571754571,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571754571,"objectID":"a1006419e3015b69778e6d806a386a91","permalink":"https://yangleisx.github.io/post/verilog-grammar/","publishdate":"2019-10-22T22:29:31+08:00","relpermalink":"/post/verilog-grammar/","section":"post","summary":"简单记录一下verilog的语法，用于日后复习或者参考。\n","tags":["Verilog HDL"],"title":"Verilog HDL语法参考","type":"post"},{"authors":["Lei Yang"],"categories":["实用工具"],"content":"常见的服务的iptables规则设置\n注意：配置规则时注意协议的双向性\n在安全性更高的系统中可以为每一条命令具体指定双方的IP地址。\n基本设置 使用脚本配置规则时要首先清空所有规则\n同时建议将默认规则设置为DROP，即使用白名单\n# flush all rules iptables -F -t filter iptables -F -t mangle iptables -F -t nat # set default rules iptables -P INPUT DROP iptables -P OUTPUT DROP iptables -P FORWARD DROP HTTP服务 http服务默认使用tcp协议的80端口\n# I.open http port:80 iptables -t filter -A INPUT -p tcp --dport 80 -j ACCEPT iptables -t filter -A OUTPUT -p tcp --sport 80 -j ACCEPT ping命令 ping命令使用icmp协议\n发送方发送icmp-type=8，即icmp-request， 接收方发送icmp-type=0，即icmp-reply\n注意方向性，可以只放行一个方向的ping命令\n# II.open ping # 1. open outbound iptables -t filter -I INPUT -p icmp --icmp-type 0 -j ACCEPT iptables -t filter -I OUTPUT -p icmp --icmp-type 8 -j ACCEPT # 2. open inbound iptables -t filter -I INPUT -p icmp --icmp-type 8 -j ACCEPT iptables -t filter -I OUTPUT -p icmp --icmp-type 0 -j ACCEPT FTP服务 FTP可以按主动模式或者被动模式运行，客户端登录时指定运行模式\n统一使用TCP协议，使用21端口发送控制命令。\n抓包分析可以发现，FTP的连接和传输过程主要分为三部分：控制连接建立和命令传输，文件传输，控制端口释放。 因此在iptables规则的设计要根据FTP协议的工作方式确定。\n主动模式 使用20端口传输数据。\n# III.open ftp active # 1. open control port:21 iptables -t filter -A INPUT -p tcp --dport 21 -j ACCEPT iptables -t filter -A OUTPUT -p tcp --sport 21 -j ACCEPT # 2. open data port:20 iptables -t filter -A INPUT -p tcp --dport 20 -j ACCEPT iptables -t filter -A OUTPUT -p tcp --sport 20 -j ACCEPT 被动模式 使用随机生成的端口发送数据，端口范围可以在/etc/vsftpd.conf指定。\n因此要使用状态监测来放行相关的端口。\n# IV.open ftp passive # 1. open control port:21 iptables -A INPUT -p tcp --dport 21 -j ACCEPT iptables -A OUTPUT -p tcp --sport 21 -j ACCEPT # 2. open data port:random port\u0026gt;=1024 iptables -A INPUT -p tcp --sport 1024: --dport 1024: -m state --state NEW,RELATED,ESTABLISHED -j ACCEPT iptables -A OUTPUT -p tcp --sport 1024: --dport 1024: -m state --state RELATED,ESTABLISHED -j ACCEPT SSH连接 默认使用TCP协议的22端口。\n同样可以只放行一个方向的数据。\n# V. open ssh port:22 # 1. open ssh inbound iptables -A INPUT -p tcp --dport 22 -j ACCEPT iptables -A OUTPUT -p tcp --sport 22 -m state --state ESTABLISHED,RELATED -j ACCEPT # 2. open ssh outbound iptables -A OUTPUT -p tcp --dport 22 -j ACCEPT iptables -A INPUT -p tcp --sport 22 -m state --state ESTABLISHED,RELATED -j ACCEPT ","date":1571552692,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571552692,"objectID":"1b6cd8ee969ba564d1919fa8a62c9508","permalink":"https://yangleisx.github.io/post/iptables-rules/","publishdate":"2019-10-20T14:24:52+08:00","relpermalink":"/post/iptables-rules/","section":"post","summary":"常见的服务的iptables规则设置\n","tags":["Linux","iptables"],"title":"iptables常用规则","type":"post"},{"authors":["Lei Yang"],"categories":["实用工具"],"content":"使用较低配置的orange pi作为树莓派的替代品\n可以在内网搭建web服务器，ftp服务器等用于学习\n基本配置 下载镜像 最开始使用ubuntu core for orange pie 但是ubuntu SSO账号设置有问题 总是密码错误无法登陆\n后来下载armbian镜像 MacOS端使用软件Etcher写入内存卡中\n开机 插卡 上电 使用网线与路由器连接 等灯常亮 查看mac地址和IP地址\n连接 armbian默认的用户为root 密码为1234\n使用ssh连接 根据引导更改密码 创建新的用户 设置密码\n根据指示 使用armbian-config设置Wi-Fi\n更改/etc/sudoers文件为自己的用户设置管理员权限（可选）\n更新软件 apt update 和 apt upgrade\n在主机设置 ssh-copy-id username@address 并输入密码设置ssh公钥免密登陆\n基本软件安装 常用软件大多系统内置 例如vim，make，g++等\n还需要安装一些常用的软件(自选)：\n基本软件：ssh tree less vnc git\nweb服务器：apache2/nignx\nMySQL数据库：mysql-server mysql-client libmysqlclient-dev\nPHP支持：php\n项目编译：cmake make\nJAVA环境：default-jre default-jdk\nPython环境：python python3 python3-pip virtualenv\nNodeJS环境：npm\n…\nmysql需要切换至root登陆 然后添加新用户并发放权限\nCREATE USER ‘username’@’localhost’ IDENTIFIED BY ‘passwd’\nGRANT ALL ON *.* TO ‘username’@’localhost’\nSET PASSWORD FOR ‘username’@’localhost’ = PASSWORD(“passwd”)\nSET PASSWORD = PASSWORD(“passwd”)\n路由器设置 将Wi-Fi动态DHCP设置为静态IP地址分发 确定一个合适的IP地址\n设置端口转发 将路由器的22端口转发板子的22端口用于外网ssh连接\n将路由器的80端口转发板子的80端口用于外网对web服务器的访问\n或者直接使用路由器的DMZ功能\n","date":1571136416,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571136416,"objectID":"060ee18b01d4370b24de91379fc6aaef","permalink":"https://yangleisx.github.io/post/orange-pi/","publishdate":"2019-10-15T18:46:56+08:00","relpermalink":"/post/orange-pi/","section":"post","summary":"使用较低配置的orange pi作为树莓派的替代品\n可以在内网搭建web服务器，ftp服务器等用于学习\n","tags":["Linux","Orange Pi"],"title":"Orange Pi的使用","type":"post"},{"authors":["Lei Yang"],"categories":["实用工具"],"content":"iptables的使用方法简单记录.\n数据包的传递 发往本机 网卡接收 mangle的PREROUTING nat的PREROUTING（做DNAT转换） 路由判断本机/转发 mangle的INPUT filter的INPUT 到达应用程序 发往外部 生成数据，路由判断 mangle的OUTPUT nat的OUTPUT filter的OUTPUT mangle的POSTROUTING nat的POSTROUTING（SNAT转换） 转发 网卡接收 mangle的PREROUTING nat的PREROUTING 路由判断 mangle的FORWARD filter的FORWARD mangle的POSTROUTING nat的POSTROUTING（SNAT转换） 命令使用 命令格式\niptables -t TABLE [-operation] CHAIN [-matches ] -j TARGET 即主要内容五部分：表、操作、链、匹配、目标动作\nTABLE包括：filter，nat，mangle\nCHAIN包括：INPUT，OUTPUT，FORWARD，PREROUTING，POSTROUTING\nTARGET包括：ACCEPT、DROP、SNAT、DNAT\noperation包括：-A(ppend添加) -I(sert插入) -D(elete删除) -R(eplace替换) -L(ist显示所有) -P(默认策略) -X(删除链) -N(新建链) -F(清空规则) -Z(清空计数器)\nmatch包括：-p(rotocol协议) -s/d(源/目标IP) –s/dport(源/目标端口) -i/o(interface进出网络接口)\n","date":1570979497,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570979497,"objectID":"aa9a63ce348fc427e066cec293e355f9","permalink":"https://yangleisx.github.io/post/iptables/","publishdate":"2019-10-13T23:11:37+08:00","relpermalink":"/post/iptables/","section":"post","summary":"iptables的使用方法简单记录.\n","tags":["Linux","iptables"],"title":"iptables基础使用","type":"post"},{"authors":["Lei Yang"],"categories":["实用工具"],"content":"命令行编辑器vim的使用方法。 vim应该是linux最常用的编辑器。基本的使用方法如下。\n普通模式 打开文档后的默认模式\n按键 功能 h/j/k/l 光标移动（左下上右） ctrl+F/B 上一页/下一页 G 最后一行 行号+G 指定行 gg 第一行 基本编辑操作 按键 功能 x 删除字符 dd 删除整行 dw 删除单词 d$ 删除该行光标后的部分 J 删除换行符 u 撤销命令 a/i 插入（ESC退出） A 在行尾插入 r 替换单个字符 R 使用新的字符替换/覆盖（ESC退出） o 下一行插入空行并进入插入模式 O 前一行插入空行 % 在配对的括号件移动 m 添加书签（使用单个小写字符作为书签名） ’ 跳转到目标书签 v 可视化选择 大部分命令前加数字表示连续操作多次\n复制粘贴操作 dd+p可以用来剪切（p表示取回删除的数据） y+p 命令表示复制粘贴 可以用 v（可视模式）选择文本 按y复制 按p粘贴\n查找数据 斜线后加所要查找的字符 例如 /name 光标移动到向下遍历的找到的第一个数据 找到多个匹配时 按 n 表示下一个（next）\n命令行模式 命令 功能 :q! 取消修改并退出 :wq 保存并退出 :w !sudo tee % 强制保存修改只读文件 :w 保存（加文件名为另存为） :s/old/new/g 全文替换 :n,ms/old/new/g 替换n-m行 :s/old/new/gc 替换前询问 :%s/old/new/g 替换整个文件 基本使用 使用vim命令打开文件，如果文件名不存在则会创建空文件\n使用a/s/i进入插入模式（insert）输入代码，使用ESC退出\n使用行数+G直接到达debug信息指定的行号\n编辑结束，使用:wq退出\n","date":1570793662,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570793662,"objectID":"7647f2fb76c52f5d537fce18db125c2c","permalink":"https://yangleisx.github.io/post/linux-vim/","publishdate":"2019-10-11T19:34:22+08:00","relpermalink":"/post/linux-vim/","section":"post","summary":"命令行编辑器vim的使用方法。 vim应该是linux最常用的编辑器。基本的使用方法如下。\n","tags":["Linux"],"title":"Vim使用简单记录","type":"post"},{"authors":["Lei Yang"],"categories":["实用工具"],"content":"在MacOS上使用Icarus Verilog时实现编程语言接口PLI\n定义系统函数模块 // Icarus Verilog使用的头文件 # include \u0026lt;vpi_user.h\u0026gt; // 编译时函数 static int hello_compiletf(char* user_data) { return 0; } // 调用时函数 static int hello_calltf(char* user_data) { vpi_printf(\u0026#34;Hello, World!\\n\u0026#34;); return 0; } // 注册函数，注册编译时函数和调用时函数 void hello_register() { s_vpi_systf_data tf_data; tf_data.type = vpiSysTask; tf_data.tfname = \u0026#34;$hello\u0026#34;; tf_data.calltf = hello_calltf; tf_data.compiletf = hello_compiletf; tf_data.sizetf = 0; tf_data.user_data = 0; vpi_register_systf(\u0026amp;tf_data); } // 加载模块时运行函数 void (*vlog_startup_routines[])() = { hello_register, 0 }; 仿真加载PLI模块时，首先检查函数指针数组startup，用0作为数据结束符。\n接着运行startup中指定的函数，通常为register函数，注册对应的系统函数。\ncompiletf函数为vvp加载模块自动编译时执行，通常用于监测param参数状态。也可以留空。\ncalltf指函数为verilog中每次调用PLI执行的结果。\n注意 vpi_子程序是存取子程序(acc_)和实用子程序(tf_)的拓展集合。\n编译PLI模块 使用GCC编译 # 编译目标文件.o gcc -c -fpic hello.c # 编译得到模块文件.vpi gcc -shared -o hello.vpi hello.o -lvpi 前提：安装有vpi_user.h和vpi的动态链接库\n使用Icarus编译 # 编译得到.o和.vpi文件 iverilog-vpi hello.c 调用系统函数 在verilog中调用自定义系统函数\nmodule main; initial $hello; endmodule 运行系统仿真\n# 编译verilog文件得到仿真文件.vvp iverilog -ohello.vvp hello.v # 运行仿真 vvp -M. -mhello hello.vvp 参数-M指定搜索路径 在这里为当前文件夹\n参数-m指定系统函数模块名 在这里为hello\n","date":1570769786,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570769786,"objectID":"cba5cc301fc88d5f29193316e46ea6bf","permalink":"https://yangleisx.github.io/post/verilog-vpi/","publishdate":"2019-10-11T12:56:26+08:00","relpermalink":"/post/verilog-vpi/","section":"post","summary":"在MacOS上使用Icarus Verilog时实现编程语言接口PLI\n","tags":["Verilog HDL"],"title":"Verilog编程语言接口","type":"post"},{"authors":[],"categories":["实用工具"],"content":"LaTeX图片、表格、参考文献和代码部分\n图片部分 \\usepackage{graphicx} (graph包) ​\\usepackage{caption} (标注包) \\usepackage{graphics} \\usepackage{float} 添加图片\n% 图片和标注环境 \\begin{figure}[htbp] % 居中命令 \\centering % 添加图片 \\includegraphics[参数]{图片名} % 参数包括 宽width=3.00in,高height=4.00in ​ % 图片必须和.tex文件位于同一路径 % 图片编号和标注 \\caption{Figure #:balabala} % 图片标签 \\label{} \\end{figure} 多图片环境\n​\\begin{figure}[htbp] \\begin{minipage}[t]{0.5/textwidth} \\includegraphics[参数]{图片名} \\caption{Figure #:balabala} \\end{minipage} \\end{figure} 表格部分 % 表格环境 \\begin{tabular} \\end{tabular} % 表格宽度在begin后加{|c|p{4.5in}\u0026lt;{\\centering}|}表示第二列宽4.5寸且居中 % 竖表格线在begin后加 {|c|c|} 竖线表示表格线 c表示居中 l表示左对齐 r表示右对齐 % 横表格线在任一行加 \\hline 表示在前后两部分之间加横线 % 居中环境(不标序号) \\begin{center} \\end{center} % 引用环境（标序号） \\begin{equation} \\end{equation} 表格每个单元格高度修改\n\\usepackage{array} \\renewcommand\\arraystretch{倍数} 即高度变为默认的n倍 复杂表格\n\\usepackage{multicol} \\usepackage{multirow} ​\\multicolumn{列数}{|c|}{内容} ​\\multirow{行数}{内容} 多行多列单元格合并\\multicolumn{列数}{|c|}{\\multirow{行数}{*}{内容}} 表格填充颜色\n\\usepackage{colortbl} \\usepackage{color} \\usepackage{array} \\cellcolor[gray]{灰度值}{内容} \\cellcolor{颜色(例如 bule)}{内容} \\columncolor \\rowcolor 参考文献 引用宏包\n\\usepackage{cite} % 引用编号为上标用 \\usepackage[superscript]{cite} % 引用编号为上标加中括号用 \\usepackage[super,square]{natbib} 设置参考文献\n\\begin{thebibliography}{最大标号值} % 参考文献条目 \\bibitem{标签} %强调期刊名称为斜体 \\emph{} \\end{thebibliography} % 使用参考文献时 \\cite{标签} 代码部分 \\usepackage{listings}宏包 \\begin{lstlisting}{language = } 会保留代码的格式，更改代码字体，语法高亮 保留缩进 \\end{lstlisting} ","date":1570709667,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570709667,"objectID":"55812ab3a759c2611b54a0e579560ac8","permalink":"https://yangleisx.github.io/post/latex-tfbc/","publishdate":"2019-10-10T20:14:27+08:00","relpermalink":"/post/latex-tfbc/","section":"post","summary":"LaTeX图片、表格、参考文献和代码部分\n","tags":["LaTeX"],"title":"LaTeX图片、表格、参考文献和代码","type":"post"},{"authors":["Lei Yang"],"categories":["实用工具"],"content":"LaTeX数学公式的基本格式 与大多数数学公式编辑器基本相同\n基本部分 引用数学公式包\n\\usepackage{amsmath} (math包) ​\\usepackage{amssymb} (symble包) 基本的数学符号的表示\n% 数学公式(一行内容) \\$内容\\$ %数学公式（多行内容） \\[ 内容 可换行 \\] % 希腊字母 \\读音 (如\\alpha \\beta) % 分式 \\frac{分子}{分母} % 斜分数 \\usepackage{xfrac} \\sfrac{1}{2} % 根式 \\sqrt{底数} % 上标（幂） \\$底数^指数\\$ %下标 \\$主体_下标\\$ %偏导符号 \\partial %向量头顶箭头 \\vec %加粗 \\mathbf %对时间求导（头顶圆点） \\dot % 正负号 \\pm （plus+minus） % 乘（叉乘） \\times %除 \\div (divide) %点乘 \\cdot %交集 \\cap %并集 \\cup %大等于 \\geq %小等于 \\leq %不等于 \\neq %约等于 \\approx %恒等于 \\equiv %属于 \\in %不属于 \\notin % 求和（∑） \\sum %连乘（π） \\prod %极限 \\lim %积分 \\int \\iint \\iiint \\idotsint %体积较大的运算符可以用 \\limit 压缩体积 分隔符 %括号 () %方括号 [] %花括号 \\{ \\} %尖括号\u0026lt;\u0026gt; \\langle \\rangle %绝对值(单竖线) \\lvert \\rvert %向量绝对值（双竖线） \\lVert \\rVert %大小调整符（由大到小） 放在符号前调整大小 \\Biggl\\biggl\\Bigl\\bigl \\Biggr\\biggr\\Bigr\\bigr %空格 \\ % 半个字符宽 \\quad %一个字符宽 \\qquad 矩阵、行列式、方程联立 两侧符号 \\left符号 \\right符号 常见环境 %矩阵环境 \\begin{array} {lcr}内容左对齐 {right}右对齐 {center}中对齐 不同行的中间加\\\u0026amp; 自动将每一行的\\\u0026amp;对齐在同一列 \\end{array} ​ %公式对齐环境(不需加\\[ \\]) \\begin{align} ​ 将每一行中加的\\\u0026amp;对齐在同一列 \\end{align} %方程联立环境(必须加\\[ \\]) \\begin{aligned} ​ 左侧大括号\\left\\{ 右侧对应有\\right.（这里有句号） \\end{aligned} 特殊矩阵环境： pmatrix 括号 bmatrix 方括号 Bmatrix 尖括号 vmatrix 单竖线 Vmatrix 双竖线 smallmatrix 小矩阵 ","date":1570709054,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570709054,"objectID":"c22d2a3bb820f0f4981123ca7a9c6adf","permalink":"https://yangleisx.github.io/post/latex-math/","publishdate":"2019-10-10T20:04:14+08:00","relpermalink":"/post/latex-math/","section":"post","summary":"LaTeX数学公式的基本格式 与大多数数学公式编辑器基本相同\n","tags":["LaTeX"],"title":"LaTeX数学公式","type":"post"},{"authors":["Lei Yang"],"categories":["实用工具"],"content":"LaTeX基础部分的使用方法\n文章框架 % 指定文章类型 \\documentclass[a4paper]{article} % ctex为中文环境 \\documentclass[a4paper]{ctexart} % 如不支持则使用 % \\usepackage{ctex} % 指明作者 \\author{} % 文章标题 \\title{} % 指定时间 \\date{} % 可用参数 \\today 括号内什么都不写则标题里不会写时间 % 文章开始 \\begin{document} % 文章结束 \\end{document} % 写标题 \\maketitle % 目录 \\tableofcontents % 章节1 \\section{} % 章节1.1 \\subsection{} % 章节1.1.1 \\subsubsection{} % 段落开头加粗名词介绍 \\paragraph{名词} % 此段落加粗名词介绍 \\subparagraph{名词} % 换行 \\\\ % 翻页 \\newpage % 加粗黑体 \\textbf{} % 垂直间距 \\vskip1.0cm 添加目录树 超链接包\\usepackage{hyperref}\n可以在pdf中生成目录树和超链接 点击目录和参考文献可以自动跳转\n默认情况下超链接通过红色边框标明 Colorlinks命令可以使超链接通过颜色标明 后接linkcolor=red citecolor=green可以指明不同种类链接的颜色\n如果不想有颜色可以指明颜色为black，超链接功能仍适用 该方法可以不显示红色边框\n列举条目 列举包\\usepackage{enumerate}\n条目环境\\begin{itemize} \\end{itemize} ​每一条目用\\item （必须加空格）\n列举环境\\begin{enumerate}[参数] \\end{enumerate} ​也需要用\\item (加空格) ​参数标明序号格式 例 [part 1][i][\u0026lt;1\u0026gt;]\n页面边框 边框包\\usepackage{geometry}\n​指定边框\\geometry{left = cm, right = cm, top = cm, bottom = cm}\n局部字体大小 \\Huge \\huge \\LARGE \\large \\normalsize \\small \\footnotsize \\scriptsize \\tiny\n单页竖排 使用landscape包 \\usepackage{lscape}\n\\begin{landscape}\\end{landscape}\n居中环境 \\begin{center}\\end{center}\n或者在环境内加入 \\centering\n页码设置 页码样式\\pagestyle{type}\n本页面样式\\thispagestyle{type} 无页码empty 无页眉页脚为页码plain 无页脚页眉有章节和页码headings 无页脚页眉只有页码myheadings\n手动设置页码\\setcounter{page}{number} 页码风格\\pagenumberingstyle{style} 数字arabic 小写罗马字roman 大写罗马字Roman 小写字符alph 大写字符Alph\n","date":1570708345,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570708345,"objectID":"776aa9558d1a659ce461b77e6cfadab4","permalink":"https://yangleisx.github.io/post/latex-basic/","publishdate":"2019-10-10T19:52:25+08:00","relpermalink":"/post/latex-basic/","section":"post","summary":"LaTeX基础部分的使用方法\n","tags":["LaTeX"],"title":"LaTeX基础部分简单记录","type":"post"},{"authors":["Lei Yang"],"categories":["基础知识"],"content":"通常可以使用系统的包管理程序安装 也可以使用源码安装\n便捷安装 使用PMS（package management system）包管理系统\ndpkg 基于Debian的包管理系统命令 aptitude 最常用的基于dpkg命令行的包管理系统实例\n包括ubuntu、armbian等debian系的系统\n$ apt #aptitude命令 update #更新apt upgrade #更新所有软件 show #查看程序包信息 search #通过关键词搜索软件包 install #安装 safe-upgrade #安全更新 remove #删除软件包 保留数据 purge #彻底删除软件包和数据 文件/etc/apt/source.list是软件仓库\n通常不需要更改，默认的软件仓库基本可以满足需求\n有需要时在其他软件仓库官网上复制仓库信息并加入仓库配置文件中\nrpm 基于RedHat的包管理系统 yum 最常用的基于rpm命令行的包管理系统\n包括centOS、fedora等redhat系的系统\n$ yum #yum命令 install #安装 list installed #查看已安装 provides #查看文件对应的软件包 remove #删除软件包 保留数据 erase #删除软件包和数据 repolist #可以显示软件来源仓库 可以手动下载rpm文件并用yum的localinstall命令本地安装\n有时存在软件包库依赖关系损坏的情况 一般先clean all后updae 或者用deplist显示库依赖后手动修改 最终也可以update - -skip-broken\n源码安装 不用包管理系统 从源码安装软件\n下载tar文件（一般从官网下载 .tar.gz文件）\n用tar -zxvf解压后 阅读README文件\n一般根据README文件的指示 make或者make install命令可以将软件安装\n","date":1570705623,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570705623,"objectID":"bedb8ce7e1deb1c16c52443b747a85fd","permalink":"https://yangleisx.github.io/post/linux-software/","publishdate":"2019-10-10T19:07:03+08:00","relpermalink":"/post/linux-software/","section":"post","summary":"通常可以使用系统的包管理程序安装 也可以使用源码安装\n","tags":["Linux"],"title":"Linux下软件安装","type":"post"},{"authors":["Lei Yang"],"categories":["基础知识"],"content":"Linux基础操作\n学会查看帮助文档！\n使用man或help或info查看具体使用方法\n文件/目录操作 $ pwd # 显示当前目录 $ ls # 查看当前目录内容 # 常用方法为加-alF或者-as或者-li -i # 显示文件编号 -d # 显示dir本身 --color # 颜色显示 $ touch # 创建空文件,也能刷新修改时间 $ cp # 复制文件 -i # 询问是否覆盖 -r # 可递归复制目录所有内容 $ ln # 创建硬链接 -s # 创建符号链接 $ readlink -f # 查看链接文件的最末端 $ mv # 移动或者重命名(重命名后修改时间和文件编号都不变) # -i询问是否覆盖 $ rm # 删除文件 -i # 询问是否确认删除 -r # 向下递归所有子目录 -rf # 强制删除整个目录 $ mkdir # 创建目录 $ rmdir # 删除空目录 $ tree # 查看目录信息(一个工具 需要apt安装) $ file # 查看文件类型 $ cat # 查看文件内容 -n # 内容全部加行号 -b # 有字的内容加行号 $ more # 分页显示文本内容 $ less # 分页显示文本内容（需要apt安装） $ tail # 查看文件末尾内容 -n # 指明行数 -f # 自动刷新(实时监测log文件末尾) $ head # 查看文件头 $ cmp # 比较文件 $ diff # 逐行显示文件区别 # 分别表示为a添加c改变d删去 $ gzip # 压缩文件.gz $ zcat # 查看压缩文件.gz $ gunziq # 解压文件.gz $ tar # 归档命令 -cvf # 创建 显示 输出文件 .tar -tf # 列出内容但是不提取 -xvf # 提取全部文件 显示 .tar -zxvf # 解压.tgz的文件[gzip+tar] $ grep # 搜索数据 -v # 反向搜索（不含某字段的行） -n # 显示行号 -c # 显示匹配到的数量 -e # 添加多个搜索的字段 # 匹配模式默认支持正则表达式 进程操作 $ ps # 监测系统进程 -ef # 所有进程的详细信息 -l # 扩展信息 -f # 显示较详细信息 --forest # 用tree的方法表明父子进程 $ top # 实时监测系统进程 $ basename # 剥离路径名 显示文件名 $ killall # 中断进程 与kill类似 $ kill # 向进程发出信号 默认为TERM # 后加进程代码和信号参数 -s # 强制发送信号 ###################################### # kill的信号参数： # KILL 无条件终止【SIGKILL信号】 # HUP 挂起【SIGHUP信号】 # INT 中断【SIGINT信号】 # TERM 尽可能终止【SIGTERM信号】 ###################################### 系统操作 $ mount # 挂载媒体命令 # 默认输出已挂载设备列表 -t # 手动挂载时指定type 包括vfat，ntfs类型等 $ umount # 卸载设备 $ df #查看磁盘空间 -h # 用M和G表示磁盘空间 $ du # 显示目录下所有文件占用的空间 -c # 显示总大小 -h # 用M和G表示磁盘空间 $ date #显示时间 +%y%m%d # 按照两位数年月日显示 +%H%M%S # 按照时分秒显示 # 其他格式参见man文件 $ who # 显示登录信息 $ uptime # 显示系统登陆时间信息 $ tty # 显示登陆所用终端文件路径 $ cal # 显示日历 $ write # 用户间单方面传递信息 # 可以重定向文件 $ talk # 用户间建立交互式信息传递 $ wall # 对所有用户传递信息 $ mesg # 通信设置（是否接受他人信息等） $ telnet # 链接网络上的远程主机 # 后接URL或者IP地址和端口 ","date":1570532873,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570532873,"objectID":"6a4d343ae143d01a20a45b2fc806d270","permalink":"https://yangleisx.github.io/post/linux-basic/","publishdate":"2019-10-08T19:07:53+08:00","relpermalink":"/post/linux-basic/","section":"post","summary":"Linux基础操作\n学会查看帮助文档！\n使用man或help或info查看具体使用方法\n","tags":["Linux"],"title":"Linux基础操作记录","type":"post"},{"authors":["Lei Yang"],"categories":["实用工具"],"content":"使用hexo搭建个人博客的过程。希望能够帮助到有需要的人。\n2024/02/06 因为一些原因,已经迁移到了使用Hugo和Academic-cv结合Github Pages重构了本站点.\n本地环境 nodeJS环境 brew install node 初始化Hexo # 安装依赖环境 $ npm install -g hexo-cli $ npm install hexo-deployer-git --save # 创建博客目录 $ mkdir Blog $ cd Blog # 博客初始化 $ hexo init $ npm install Hexo使用 # 新建页面 $ hexo new page categories $ hexo new page tags # 新建并发布草稿 $ hexo new draft my_draft $ hexo publish my_draft # 新建文章 $ hexo new post my_post # 开启本地服务器 $ hexo server (--debug) # 生成静态文件 $ hexo generate $ hexo g # 部署到服务器 $ hexo deploy $ hexo d 密钥生成和提交 # 生成公钥和私钥 $ cd ~/.ssh $ ssh-keygen # 将公钥复制到服务器 $ ssh-copy-id username@address 服务器环境 环境搭建 # 软件安装 $ apt install nginx $ apt install nodejs $ apt install git # 新建git用户 # 并添加到 /etc/sudoers $ adduser git $ vim /etc/passwd # 修改git用户的默认shell为/ysr/bin/git-shell # 禁止git用户用ssh登陆 仓库设置 # 来到仓库位置 $ cd /home/git # 创建空仓库 $ git init --bare Blog.git # 创建临时文件夹 $ mkdir tmp/Bog # 设置git钩子 $ vim Blog.git/hooks/post-receive # 设置权限 $ chmod +x Blog.git/hooks/post-receive $ chown -R git:git Blog.git $ chmod 777 -R Blog.git 使用的hooks脚本\n#!/bin/bash -l GIT_REPO=/home/git/Blog.git TMP_GIT_CLONE=/home/git/tmp/Blog PUBLIC_WWW=/var/www/blog rm -rf ${TMP_GIT_CLONE} git clone $GIT_REPO $TMP_GIT_CLONE rm -rf ${PUBLIC_WWW} cp -rf ${TMP_GIT_CLONE} ${PUBLIC_WWW} 另一个可选的脚本\n#!/bin/sh git --work-tree=/var/www/blog --git-dir=/home/git/Blog.git checkout -f web服务器设置 # 创建静态文件目录 $ rm -rf /var/www/html $ mkdir /var/www/blog $ chmod 777 /var/www # 设置nginx $ vim /etc/nginx/site-available/default $ mkdir /home/git/nginxlog $ touch /home/git/nginxlog/blog_access.log $ touch /home/git/nginxlog/blog_error.log # 重启web服务器 $ service nginx restart nignx配置\nserver { listen 80 default_server; listen [::]:80 default_server; server_name _; access_log /home/git/nginxlog/blog_access.log; error_log /home/git/nginxlog/blog_error.log; root /var/www/blog; index index.html location / { try_files $uri $uri/ =404; } } 虚拟主机配置\n$ cd /etc/nginx/sites-available # 修改虚拟主机配置 # 单物理主机多虚拟主机 $ vim new_server $ mkdir /var/www/new_server $ touch /home/git/nginxlog/new_server_access.log $ touch /home/git/nginxlog/new_server_error.log # 链接激活 $ ln /etc/nginx/sites-available /etc/nginx/sites-enable # 检查web服务器 $ service nginx status $ service nginx restart git自动部署 修改部署配置 deploy: type: git message: post-receive repo: git@address:/home/git/blog.git branch: master 接下来可以正常部署\n$ hexo deploy # 或者 $ hexo d 使用github pages github提供了免费的github pages\n可以创建一个仓库，仓库名为username.github.io\n然后将静态文件上传即可使用\n在deploy设置中更改对应的repo地址即可\n","date":1570418609,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570418609,"objectID":"17191868a05c6e640fe35c9d79aaca96","permalink":"https://yangleisx.github.io/post/blog-hexo/","publishdate":"2019-10-07T11:23:29+08:00","relpermalink":"/post/blog-hexo/","section":"post","summary":"使用hexo搭建个人博客的过程。希望能够帮助到有需要的人。\n","tags":["Hexo"],"title":"使用Hexo搭建个人博客并部署到私人服务器","type":"post"},{"authors":["Lei Yang"],"categories":["代码学习"],"content":"CSV是一种一行中使用逗号分隔的数据表格格式\n数据读取 直接读取 # 打开文件并读取 得到字符串 file = open(\u0026#34;name.csv\u0026#34;,\u0026#34;r\u0026#34;) data = file.read() # 切分成行 data_line = data.split(\u0026#34;\\n\u0026#34;) data_conp = [] # 每一行划分成list for line in data_line: data_conp.append(line.split(\u0026#34;,\u0026#34;)) 使用csv包读取 # 导入CSV库 import csv file = open(\u0026#34;name.csv\u0026#34;,\u0026#34;r\u0026#34;) # 获得reader对象 reader = csv.reader(file) # 每次调用返回一行数据 headline = next(reader) # 返回所有数据\u0026lt;list of list\u0026gt; data = list(reader) 通常情况下，数据表格中含有表头，需单独处理\n# 直接读取数据时要去掉表头 raw_data = list(reader) header = raw_data[0] data = raw_data[1:] for index, item in enumerate(header): print(index.item) ","date":1570258781,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1707032658,"objectID":"8de2a71dd86588ac0e613aeb3d51b45d","permalink":"https://yangleisx.github.io/post/python-csv/","publishdate":"2019-10-05T14:59:41+08:00","relpermalink":"/post/python-csv/","section":"post","summary":"CSV是一种一行中使用逗号分隔的数据表格格式\n","tags":["Python"],"title":"CSV数据处理","type":"post"},{"authors":["Lei Yang"],"categories":["代码学习"],"content":"使用方法类似于Matlab\n数据基于 class ’numpy.ndarray\u0026#39;\n也可以基于 class ’list\u0026#39;\n导入库 # 导入库 import matplotlib.pyplot as plt import numpy 数据的导入 # 基于ndarray的数据 x = np.array([1,2,3,4,5]) y = np.array([6,7,8,9,0]) # 基于list的数据 z = [1,4,3,5,6,7] 绘图 # 绘图函数的使用方法与Matlab相同 # 颜色/线型/标记的设置和Matlab相同 # 或者使用名值对指定绘图参数 # 折线图 plt.plot(x,y) # \u0026#39;r-x\u0026#39; # 红色 单实线 ‘x’标记 # linewidth = 5 # 线粗为5 # 条形图 plt.bar(x,y) # 火柴图 plt.stem(x,y) # 散点图 plt.scatter(x,y) # s = 40 # size # c = \u0026#39;red\u0026#39; # color # c = (0,0,0.87) # RGB color # c = y,cmap = plt.cm.Blues # 颜色映射 不同的值深度不同 # edgecolor=\u0026#39;none\u0026#39; # 数据点轮廓 图像设置 通常情况下可以理解为状态机参数的调整\n因此后面的语句会覆盖之前的代码\n坐标轴 # 设置x,y轴的显示范围 plt.xlim((-1,1)) plt.ylim((0,3)) # 也可以用axis设置 plt.axis([-1,1,0,3]) 图表标题 # 设置图表标题 pl.title(\u0026#34;title\u0026#34;) 坐标轴标签 plt.xlabel(\u0026#39;xname\u0026#39;) plt.ylabel(\u0026#39;yname\u0026#39;) # 设置字体 fontproperties=\u0026#39;SimHei\u0026#39; # 设置字号 fontsize=14 坐标轴刻度 # 设置坐标轴的刻度 # 使用numpy，设置-1到1，均分成5份 # 当范围大于xlim指定的范围时会扩展 plt.xticks(np.linespace(-1,1,5)) # 使用字符串list命名 plt.yticks([-5,0,5], [\u0026#34;negative\u0026#34;,\u0026#34;neutral\u0026#34;,\u0026#34;positive\u0026#34;]) # 可以设置标记刻度的样式 plt.tick_params(axis=\u0026#34;both\u0026#34;, labelsize=14) 四边边框设置 # 获得四边边框对象 ax = plt.gca() # 设置颜色，设置为none可以隐藏 ax.spines[\u0026#39;top\u0026#39;].set_color(\u0026#39;none\u0026#39;) # 设置坐标轴位置，可以设置横轴经过数据的0点 ax.spines[\u0026#39;bottom\u0026#39;].set_position((\u0026#39;data\u0026#39;,0)) # 设置坐标轴的位置，可以设置纵轴在最右端 ax.spines[\u0026#39;left\u0026#39;].set_position((\u0026#39;axes\u0026#39;,1)) # 设置坐标轴上标注的位置，可以设置在纵轴的右侧 ax.spines[\u0026#39;left\u0026#39;].set_ticks_position(\u0026#39;right\u0026#39;) 图例设置 # 方法一：在plot绘图时指定label的内容 lab_sin = \u0026#34;this is a sinesoidal wave\u0026#34; plt.plot(x,y,label = lab_sin) plt.legend() # 方法二：在plot绘图时获得句柄，在legend中指定内容 han1,=plt.plot(x,y) han2,=plt.plot(x,z) plt.legend(handles=[han1,han2], labels=[\u0026#34;y_values\u0026#34;,\u0026#34;z_values\u0026#34;]) # loc=\u0026#39;best\u0026#39; # 指定图例的位置,‘best’自动分配最佳位置 图像输出 # 显示图像 # 在plt.show()之前的部分会画在一张图里 没有plt.show()不画图 plt.show() # 修改图像的输出 plt.figure(figsize=(10,6)) # dpi = 128 # 屏幕分辨率 # 保存图像 plt.savefig(\u0026#34;file_name.png\u0026#34;) # bbox_inches=\u0026#39;tight\u0026#39; # 将图像边缘白边裁掉 ","date":1570244708,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570244708,"objectID":"54647862e78a79c2d5c24e1e256e710b","permalink":"https://yangleisx.github.io/post/python-matplotlib/","publishdate":"2019-10-05T11:05:08+08:00","relpermalink":"/post/python-matplotlib/","section":"post","summary":"使用方法类似于Matlab\n数据基于 class ’numpy.ndarray'\n也可以基于 class ’list'\n","tags":["Python","Matplotlib"],"title":"使用Matplotlib绘图","type":"post"},{"authors":["Lei Yang"],"categories":["实用工具"],"content":"这学期的Verilog课程要求使用ModelSim仿真软件。 实在不想再开一个win7的虚拟机了。 于是探索了一下如何在MacOS中进行Verilog的仿真和波形监测。\n环境搭建 仿真工具 # 使用icarus-verilog进行仿真 brew install icarus-verilog 波形工具 # 使用Scansion查看波形 brew cask install scansion 仿真过程 仿真 # 生成vvp仿真程序 # 默认生成a.out iverilog stimulus.v -o stimulus.vvp # 执行仿真 ./stimulus.vvp # 或者 vvp stimulus.vvp 波形观察 生成波形文件 需要在verilog文件中生成波形\ninitial begin // 指明文件名 $dumpfile(\u0026#34;stimulus.vcd\u0026#34;) // 指明监控的module，这里表示stimulus及下面的所有module $dumpvar(0,stimulus) /* * 如果stimulus只调用了一个counter模块 * $dumpvar(1, stimulus) * $dumpvar(0, stimulus.counter) * 两者等价 */ end 查看波形 使用命令行查看\n# 使用xCode的cmd-tools 在terminal中打开Scansion软件 open -a Scansion stimulus.vcd 或者直接在Scansion中打开vcd文件\n或者直接双击vcd文件\n","date":1570172298,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570172298,"objectID":"b9799477019a8873fe471b9071f73a7e","permalink":"https://yangleisx.github.io/post/verilog-macos/","publishdate":"2019-10-04T14:58:18+08:00","relpermalink":"/post/verilog-macos/","section":"post","summary":"这学期的Verilog课程要求使用ModelSim仿真软件。 实在不想再开一个win7的虚拟机了。 于是探索了一下如何在MacOS中进行Verilog的仿真和波形监测。\n","tags":["Verilog HDL"],"title":"Verilog on MacOSX","type":"post"},{"authors":["Lei Yang"],"categories":["实用工具"],"content":"简单了解了正则表达式在python和C++中的使用方法\n基本元素和规则 符号 含义 ^ 句首 $ 句尾 . 匹配单个字符 * 多次出现（$\\geq0$） + 多次出现（$\\geq1$) ? 零次或一次出现 {n,m} 表示匹配n-m次 \\ 匹配转义字符 () 匹配子串并获取 | 匹配两项之间的一个 / / 表示pattern匹配 [] 表示多个可选项 其中的^表示非 非打印字符的匹配 字符 含义 \\cx 控制字符control+x，这里的x必须是A-Z \\f 换页符号 \\n 换行符 \\r 回车键 \\s 空白字符 类似[\\f\\n\\r\\t\\v] \\S 非空白字符 \\t 制表符 \\v 垂直制表符 定位符 符号 含义 \\b 单词边界（单词和空格交界处） \\B 非单词边界 常用的匹配 匹配 含义 \\d 匹配一个数字 相当于[0-9] \\w 匹配一个字符 相当于[A-Za-z0-9_] 预查 符号 含义 (?:pattern) 匹配但是不获取（缓存） a(?=pattern) 匹配pattern之前的a a(?!pattern) 匹配后面没有pattern的a (?\u0026lt;=pattern)b 匹配前面有pattern的b (?\u0026lt;!pattern)b 匹配前面没有pattern的b 在各种环境中使用正则表达式 C++中使用正则表达式REGEX // 引入头文件 #include\u0026lt;regex\u0026gt; // 定义一个正则表达式 std::regex pattern(\u0026#34;([0-9]+)\u0026#34;); // 声明匹配结果变量,结果变量要和字符串形式相对应 std::match_results\u0026lt;const char*\u0026gt; cResult; // 简化定义std::cmatch std::match_results\u0026lt;std::string::const_iterator\u0026gt; sResult; // 简化定义std::smatch // 定义待匹配的字符串 char cStr[] = \u0026#34;hello\u0026#34;; std::string sStr = \u0026#34;123abc\u0026#34;; // 进行匹配 // regex_match(string, result, pattern) // 其中string可以是迭代器指明的区间 // result可以省略 bool cValid = regex_match(cStr, cResult, pattern); bool sValid = regex_match(sStr, sResult, pattern); // 返回匹配结果 cResult.size(); //返回匹配的子串个数 for(int i = 0; i \u0026lt; cResult.size();i++){ cResult[i]; cResult.str(i); //显示匹配的部分子串 } /* * 同样支持 * regex_search(string, result, pattern) * regex_replace(string, pattern, substr) * 可以用$1 $2 %3指括号匹配到的子串 */ Java中正则表达式的类库 import java.util.regex.* // 实际上包含了Pattern、Matcher、PatternSyntaxException三个类 javascript中使用正则表达式 var re = new RegExp(pattern, modifiers); python中使用正则表达式 # 引用正则表达式包 import re 正则表达式标志位\n标志 含义 re.I 忽略大小写 re.M 多行模式 re.L 特殊字符集依赖于当前环境 re.S 任意字符 re.U 特殊字符依赖于Unicode re.X 忽略空格和注释 匹配函数：match # 匹配函数 obj = re.match(pattern, string, flags=0) # 返回一个re匹配对象 # 匹配失败返回None obj.span() # 显示匹配到的子串的位置 obj.groups() # 显示括号匹配到的子串 obj.group(num=0) # 显示匹配到的整个字符串 obj.start() # 显示匹配到的子串的起始位置 obj.end() # 显示匹配到的子串的结束位置 # 可以使用?P\u0026lt;name\u0026gt;为子串命名并用group取出 pattern=\u0026#34;:(?P\u0026lt;port\u0026gt;[0-9]+)\u0026#34; obj.group(\u0026#34;port\u0026#34;) 查找函数：research re.search(pattern, string, flags=0) 区别：\nmatch()从头开始匹配，不满足返回None\nsearch()匹配整个字符串直到找到一个匹配\nfindall()匹配所有\nfinditer()返回迭代器（list？）\nsplit()按子串分割原字符串\n替换函数：sub # 查找并替换 re.sub(pattern, repl, string, count=0, flags=0) # 将满足pattern的部分换成repl，count指明替换的次数 注意：\n这里的repl可以是一个函数，函数参数为matched\nmatched匹配对象，可以使用group取出匹配到的子串并做相应的处理\n编译函数：compile 将pattern编译为一个对象，具有match和search的成员函数\n其他环境 C#中正则表达式的类库\nusing System.Text.RegularExpressions; ","date":1570172118,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570172118,"objectID":"0de98038a2157344e7881408fa554c06","permalink":"https://yangleisx.github.io/post/reg-exp/","publishdate":"2019-10-04T14:55:18+08:00","relpermalink":"/post/reg-exp/","section":"post","summary":"简单了解了正则表达式在python和C++中的使用方法\n","tags":["Regular Expression"],"title":"正则表达式的使用","type":"post"},{"authors":[],"categories":["代码学习"],"content":"C++已经实现了常见的各种数据结构\n每种数据结构的实现被称为容器，定义迭代器作为容器中对象的指针\n迭代器被定义为公有内嵌类，类名为iterator或const_iterator\n借助容器储存数据的容器称为容器适配器(栈和队列)\n查找表容器通常称为关联容器\n建议：直接查看头文件中的函数声明，使用关键字检索\n线性表容器 vector：用动态数组实现的线性表#include\u0026lt;vector\u0026gt;\nlist：用双链表实现的线性表#include\u0026lt;list\u0026gt;\ndeque：经过优化的线性表，兼具两者特点，用于实现栈和队列\n线性表变量声明 std::vector\u0026lt;int\u0026gt; vc; std::vector\u0026lt;int\u0026gt;::iterator itr; std::list\u0026lt;int\u0026gt; ls; std::list\u0026lt;int\u0026gt;::iterator its; 两者的共有操作 int size() const; //元素个数 void clear(); //清空元素 bool empty(); //判断是否为空 void push_back(const object \u0026amp;x); //添加到表尾 void pop_back(); //删除表尾元素 const object \u0026amp; front () const; //第一个元素 const object \u0026amp; back() const; //最后一个元素 特有操作 list可以在表头操作\nvoid push_front(const object \u0026amp;x); //表头添加元素 void pop_front(); //表头删除元素 vector可以实现类似数据的特征\nobject \u0026amp;opeator[](int idx); //下标运算符重载，无检查 object \u0026amp;at(int idx); //返回指定位置元素，有下标检查 int capacity(); //数组容量 void reseave(int newCapacity); //指定数组容量 迭代器相关操作 iterator begin(); //表头位置 const_iterator begin(); iterator end(); //表尾位置 const_iterator end(); iterator insert(iterator pos,const object \u0026amp;x); //插入元素 iterator erase(iterator pos); //删除元素 iterator erase(iterator start,iterator end); //删除区间[start,end-1) 迭代器操作 itr ++; //下一位置 * itr; //取出元素 //STL中定义了distance函数，可以确定两个iterator之间的距离 std::distance(exp.begin(),itr);//可以得到itr指向的元素的下标 其他操作 int max_size(); //vector的最大范围 void resize(size); //显式指定数组空间 void resize(size,fill); //显示指定扩大数组空间，并填充 iterator rbegin() const; //反转后的表头（实际的表尾） iterator rend() const; //反转后的表尾 void swap(vector \u0026amp;obj); //与另一个vector交换数据 vector减少空间的方法被称为“收缩到合适（shrink to fit）”\n使capacity收缩到size（capacity默认为2的指数）\nvector\u0026lt;int\u0026gt;(vc).swap(vc); //使用vector的拷贝构造函数，复制已有的数据，释放多余的空间 栈容器 stack栈容器，#include\u0026lt;stack\u0026gt;\n栈变量声明 stack\u0026lt;int,vector\u0026lt;int\u0026gt;\u0026gt; stack1;//借助vector储存数据 stack\u0026lt;int,list\u0026lt;int\u0026gt;\u0026gt; stack2;//借助list储存数据 栈基本操作 bool empty(); //检查栈是否为空 reference top(); //返回栈顶元素 void pop(); //出栈 void push(type \u0026amp;x); //压栈 void push(const type \u0026amp;x); //压栈 队列容器 queue队列容器，#include\u0026lt;queue\u0026gt;\n队列变量声明 queue\u0026lt;int\u0026gt; queue1; //使用deque实现的队列（默认） queue\u0026lt;int,deque\u0026lt;int\u0026gt;\u0026gt; queue2; //使用deque实现的队列（默认） queue\u0026lt;int,list\u0026lt;int\u0026gt;\u0026gt; queue3; //使用list实现的队列 队列基本操作 void push(type \u0026amp;x); //入队 void push(const type \u0026amp;x); //入队 void pop(); //出队 reference front(); //返回队头（下一出队元素） reference back(); //返回队尾（上一入队元素） bool empty() const ; //是否为空 size_type size() const; //队列规模 优先级队列容器 priority_queue优先级队列容器，#include\u0026lt;queue\u0026gt;\n（内部使用二叉树实现）\n变量声明 priority_queue\u0026lt;int,vector\u0026lt;int\u0026gt;,less\u0026lt;int\u0026gt;\u0026gt; pq1; //默认使用vector实现，内部降序排列，最大值出队 priority_queue\u0026lt;int,vector\u0026lt;int\u0026gt;,greater\u0026lt;int\u0026gt;\u0026gt; pq2;//vector实现，升序排列，最小值出队 priority_queue\u0026lt;int,deque\u0026lt;int\u0026gt;,less\u0026lt;int\u0026gt;\u0026gt; pq3;//使用deque实现 第三个参数为仿函数，即使用一个类，实际上完成一个函数的作用\n基本操作 void push(const type \u0026amp;x); //入队 const type \u0026amp; top() const; //返回队首值 void pop(); //出队 bool empty(); //检查是否为空 void clear(); //清空队列 查找表容器 set“集合”：数据只有一个字段键的查找表#include\u0026lt;set\u0026gt;\nmap“映射”：数据为键值对的查找表#include\u0026lt;map\u0026gt;\npair类型：键值对类型，map的元素#include\u0026lt;utility\u0026gt;\n注：set和map中不允许key出现重复，需要出现重复的key时可以使用multiset和multimap\n查找表变量声明 set\u0026lt;int\u0026gt; s; map\u0026lt;string,string\u0026gt; m; pair\u0026lt;string,string\u0026gt; p; 查找表基本操作 pair makr_pair(class1 obj1,class2 obj2); //生成pair变量，元素类型自动推断 p.first; p.second; //pair变量的内容 bool empty(); //判断是否为空 size_type size(); //容器规模 void clear(); //清空容器 size_type count(const key_type\u0026amp; key) const; //计数键出现的次数（判断键是否存在） iterator erase(iterator position); //删除某位置元素 iterator erase(iterator begin,iterator end); //删除一段元素 size_type erase(const key_type\u0026amp; key); //删除键为某值的元素 iterator find(const key_type\u0026amp; key); //查询键的位置（找不到时返回end） iterator insert(value_type\u0026amp; value); //插入（map中value_type为pair） mapped_type at(const key_type\u0026amp; key); //查找key对应的值 //map中可以直接使用下标运算，效果和at相同。但是如果目标不存在时会被创建并初始化 查找表迭代器相关操作 iterator begin(); //返回头部 iterator end(); //返回尾部 iterator lower_bound(key_value\u0026amp; key); //返回值不小于key的第一个迭代器 iterator upper_bound(key_value\u0026amp; key); //返回大于key的第一个迭代器 pair\u0026lt;iterator,iterator\u0026gt; equal_range(key_value\u0026amp; key); //返回等于key的范围 //找不到的时候返回end 特点：\nmap中的key是不可以修改的，但是每个key对应的value可以通过迭代器修改。\nset中只有key，因此不可以通过迭代器修改key的值\nmap中的元素默认按key升序排列\n","date":1570171945,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570171945,"objectID":"14a3cb7e853012cd9da95f2ad24318da","permalink":"https://yangleisx.github.io/post/cpp-stl/","publishdate":"2019-10-04T14:52:25+08:00","relpermalink":"/post/cpp-stl/","section":"post","summary":"C++已经实现了常见的各种数据结构\n每种数据结构的实现被称为容器，定义迭代器作为容器中对象的指针\n迭代器被定义为公有内嵌类，类名为iterator或const_iterator\n借助容器储存数据的容器称为容器适配器(栈和队列)\n查找表容器通常称为关联容器\n建议：直接查看头文件中的函数声明，使用关键字检索\n","tags":["C/C++"],"title":"C++中的STL数据结构","type":"post"},{"authors":[],"categories":["基础知识"],"content":"简单了解make的用法。\n格式 target(生成文件名): source(依赖文件名) command(指令) 步骤 步骤一：所有的目标文件和静态库文件连接成可执行文件\nmain : file1.o file2.o ... lib1.a lib2.a ... g++ file1.o file2.o...lib1.a lib2.a... -o main 步骤二：指定的目标文件打包为静态库文件\nlib.a : libfile1.o libfile2.o ... ar libfile1.o libfile2.o... -r lib.a 步骤三：所有的源码编译为目标文件\nfile.o : file.cpp g++ -c file.cpp 步骤四：指定clean内容\nclean: rm main file1.o ... libfile1.a ... 使用 make指令：依据makefile的要求进行编译\nmake clean指令：依据makefile的clean指令删除指定的文件\n[注意]\n不需要指定头文件(可写可不写)\n不过建议加在对应的依赖文件处 如main.o : main.cpp lib1.hpp\n编译预处理时#include “file.hpp”的含义为在本文件夹中寻找头文件并链接到该位置\n编译预处理时#include \u0026lt; iostream \u0026gt; 的含义为在C++标准库中寻找头文件并链接到该位置\n","date":1570110967,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570110967,"objectID":"5421293b94d1f364fdc94a8d81ccb49e","permalink":"https://yangleisx.github.io/post/makefile-base/","publishdate":"2019-10-03T21:56:07+08:00","relpermalink":"/post/makefile-base/","section":"post","summary":"简单了解make的用法。\n","tags":["C/C++","Make"],"title":"Make简单使用","type":"post"},{"authors":["Lei Yang"],"categories":["基础知识"],"content":"简单介绍C/C+静态库和动态库的编译方法。\n静态库 静态库的命名格式：libname.a\n即以lib为前缀，.a作为后缀\n生成 打包为库的工具为ar\nar -crv libtest.a test.o #或者 ar -cr libtest.a test.o 使用 g++编译时需要指明路径和名字\ng++ main.cpp -L . -l test -o main #静态库名不需要加前缀和后缀 动态库 linux的动态库的命名格式：libname.so\n即以lib为前缀，.so为后缀\n动态库生成 使用编译器创建动态库\ng++ -f PIC -c test.cpp#为了生成多程序共享的动态库 g++ -shared -o libtest.so test.o#创建链接 #或者合并为一句 g++ -f PIC -shared -o libtest.so test.cpp 动态库使用 具体使用方法与静态库一样\n但是需要注意 必须显式指明动态连接库的位置\n#查看库的位置 pwd #编辑ld配置文件 sudo vim /etc/ld.so.conf#在最后一行加入库目录 sudo ldconfig#重建库的位置文件 #使用动态连接库 g++ main.cpp -L . -l test -o main ./main #如果没有指明库的路径 编译时没有问题但是运行可执行文件会报错 ","date":1569840669,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569840669,"objectID":"bc8f98b5a1c68148b58fa556b78718b5","permalink":"https://yangleisx.github.io/post/cpp-build/","publishdate":"2019-09-30T18:51:09+08:00","relpermalink":"/post/cpp-build/","section":"post","summary":"简单介绍C/C+静态库和动态库的编译方法。\n","tags":["C/C++"],"title":"C++库的编译","type":"post"}]