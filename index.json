
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":" Lei Yang received the B.Eng. degree from Shanghai Jiao Tong University in 2021. He is currently pursuing the Ph.D. degree with the SEIEE, SJTU. His research interests include computer vision, visual speech recognition, and semantics segmentation.\n","date":1710460800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1710460800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Lei Yang received the B.Eng. degree from Shanghai Jiao Tong University in 2021. He is currently pursuing the Ph.D. degree with the SEIEE, SJTU. His research interests include computer vision, visual speech recognition, and semantics segmentation.","tags":null,"title":"Lei Yang","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Hugo Blox Builder’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://yangleisx.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Hugo Blox Builder's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Yi He","Lei Yang","Hanyi Wang","Yun Zhu","Shilin Wang"],"categories":null,"content":" In this paper, we propose a novel speaker-adaptive lipreading model. For front-end network, conv-based LoRA modules are used to adapt to speaker’s space features. For back-end network, a plug-and-play TAWL module is designed to learn temporal characteristics. An Adapter module is finally employed to bridge the adaptation knowledge from front-end and back-end. The experiments show that the proposed method achieve the state-of-the-art performance on both word-level and sentence-level dataset with fewer training parameters.\n","date":1710460800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1710460800,"objectID":"df2a78da2aa4ef86955dcc5be7591d49","permalink":"https://yangleisx.github.io/publication/icassp-udp/","publishdate":"2024-01-19T00:00:00Z","relpermalink":"/publication/icassp-udp/","section":"publication","summary":"A novel speaker-adaptive lipreading model is proposed.","tags":null,"title":"Speaker-Adaptive LipReading via Spatio-Temporal Information Learning","type":"publication"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文题目： Improving Semantic Segmentation in Aerial Imagery via Graph Reasoning and Disentangled Learning\n作者：Ruigang Niu, Xian Sun, Yu Tian, Wenhui Diao, Yingchao Feng, Kun Fu\n会议/时间：TGRS2021\n链接: ResearchGate\n论文目标 在航空影像分割问题中，由于存在前景背景不平衡，类内数据差异较大以及密集/小目标的存在，性能受到限制。文章通过引入Graph Reasoning 图推理和Disentangled Representation Learning 解耦表示学习的思路，提升在航空影像上分割的效果。\n为了提取丰富的上下文信息，之前的工作使用了FCN、ASPP等方式，也可以使用基于Attention 注意力机制的方式。为了进一步增加上下文信息，可以使用Graph Reasoning 图推理的方式。\n对于密集目标、小目标等容易出现特征含糊不清的问题，引入了解耦的多分支的结构。使用多任务学习的方式来解决分割和边缘检测的问题。\n相关工作 使用GR的算法中，GloRe使用1D卷积在全连接图上实现图卷积，SPyGR直接在像素空间上做图卷积，忽略了像素空间和语义空间之间的语义差异。CDGC引入了从粗检测到精细化的方式（有点类似OCRNet？）DisenGCN将GCN和Disentangled Learning两者相结合。\n本文方法 整体结构图下。首先使用FPN得到层次特征，使用GR模块处理特征。将特征送入双分支解耦学习模块，分别进行前景估计和边缘对齐，最后将所有的特征融合到一起进行预测。\n这里的图卷积模块，吸收了HBP 层次双线性池化的思想，将相邻的三个不同分辨率的特征图进行缩放之后计算Hadamard积然后映射到若干个点，然后进行图卷积，最后使用卷积得到的结果对原本的特征相乘在映射回到原本的像素空间中。\n使用HBP 层次双线性池化进行映射的时候有如下公式进行池化。 $$G_{proj}(F^2, \\mathcal{U}(F^1), \\mathcal{U}(F^3)) = \\frac{1}{H_2W_2}\\sum\\limits_{i=1}^{H_2W_2} f^2_i\\circ f’^1_i\\circ f’^3_i$$\n最后按通道分成g组，即 $C = g\\times d$ ，可以认为分成了g个节点，每一个节点的特征维度为d（可以认为是d个像素空间的点构成了一个图空间的点）。在进行图卷积的时候，令 $H = \\sigma(A_g X W_g)$ ，其中 $A_g\\in R^{N\\times N},X\\in R^{N \\times C},W_g\\in R^{C\\times F}$ ，这里的$N$就是上面的$g$，$C$就是上面的$d$。\n在邻接矩阵的设计上，使用了四种不同的策略，分别是固定为一跳邻居、单位阵初始化的可学习参数、正态分布初始化的可学习参数、均匀分布初始化的可学习参数。\n最后在反向映射的过程中，采用了类似SE-Net的方式，将图卷积得到的结果作为通道注意力与原始数据相乘。\n在前景估计分支，作者使用了贝叶斯理论, 实际结构是学习得到一个分割图然后concat起来。使用了 $B = \\delta(M_{fg} \\cdot I\\parallel (1-M_{fg}) \\cdot I \\parallel I)$ 的拼接方式。\n在边界对齐模块，作者号称使用了类似Optical Flow 光流的思想，学习得到一个类似光流的边界检测图然后与原本的特征相结合。\n在最后损失函数设计上，对于最后的分割使用Cross Emtropy 交叉熵，前景使用BCE_Loss和Dice Loss，添加了类似PSPNet中的辅助Loss。\n结果分析 在iSAID数据集和Vaihingen、Cityscapes数据集上测试了性能。 基本模型结构使用预训练的ResNet-50/101。\n简单看一下Ablation Study的效果。\n总结 使用了图推理的方式提取上下文信息。这一部分的论文还蛮多的，这里用了一种分组的方式来进行处理。比直接使用像素点的节约时间和空间，用通道注意力的方式进行反向映射的方式也成本比较低。\n使用了多分支的模型，分别学习分割图和边缘检测。利用边缘检测增强分割效果的想法蛮常见的。例如【论文】Boundary-aware Graph Reasoning for Semantic Segmentation或者【论文】Real-time Scene Text Detection with Differentiable Binarization|。\n","date":1707032869,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1707032869,"objectID":"00ab540ea76a9b07f28b66c5eebb6813","permalink":"https://yangleisx.github.io/post/paper-pgr/","publishdate":"2024-02-04T15:47:49+08:00","relpermalink":"/post/paper-pgr/","section":"post","summary":"论文题目： Improving Semantic Segmentation in Aerial Imagery via Graph Reasoning and Disentangled Learning\n作者：Ruigang Niu, Xian Sun, Yu Tian, Wenhui Diao, Yingchao Feng, Kun Fu\n会议/时间：TGRS2021\n链接: ResearchGate\n","tags":["Semantic Segmentation","Graph Reasoning","Disentangled Learning"],"title":"【论文】Improving Semantic Segmentation in Aerial Imagery via Graph Reasoning and Disentangled Learning","type":"post"},{"authors":["Yi He","Lei Yang","ShilinWang","Alan Wee-Chung Liew"],"categories":null,"content":" In this paper, we proposed a visual speaker authentication system using the random prompt text scheme to meet the requirements of mobile applications. Lip features are disentangled into three parts, i.e. the static identity features, the dynamic identity features and the content features by the proposed TDVSA-Net. The experiment results show that the content features obtained the lowest WER in speaker- independent lip-reading compared with other lipreading models, and the identity features had comparable performance with the state-of-the-art methods on detecting human imposters and DeepFake imposters and exhibits more robustness when facing different image qualities. Therefore, our VSA system can be a feasible solution for today’s widely used mobile applications.\n","date":1704844800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704844800,"objectID":"5fd4b6501903f192356210148aa1e793","permalink":"https://yangleisx.github.io/publication/tcsvt-vsa/","publishdate":"2024-01-20T00:00:00Z","relpermalink":"/publication/tcsvt-vsa/","section":"publication","summary":"Lip features are disentangled into three parts, i.e. the static identity features, the dynamic identity features and the content features by the proposed TDVSA-Net.","tags":[],"title":"Lip Feature Disentanglement for Visual Speaker Authentication in Natural Scenes","type":"publication"},{"authors":["Lei Yang","ShilinWang","Alan Wee-Chung Liew"],"categories":null,"content":" In this paper, we proposed a new lip segmentation method based on fuzzy convolutional neural network with graph reasoning that can learn high-level semantics. The fuzzy learning module and the fuzzy graph reasoning module help the deep convolutional neural network to handle uncertainties around ambiguous boundaries, capture global information, and improve multi-class lip region segmentation. In addition, a fine-grained lip region dataset is released for multi-class segmentation studies. Our proposed approach achieved satisfactory performance on the test set, with 94.36% pixel accuracy and 74.89% mIoU. The experiment results have demonstrated that the proposed method can be applied in many lip-related applications to obtain accurate and robust lip region segmentation in natural scenes.\nHowever, the proposed network cannot achieve satisfactory results in certain scenarios, specifically in cases of occlusion or extreme lighting conditions. This limitation can be attributed to the FLRSeg dataset, which is derived from the VSA dataset that was collected for speaker authentication and thus required unobstructed lip movements. In our future work, we will further improve the segmentation performance in various situations and explore the potential of leveraging the segmentation results in downstream tasks, such as lip reading and visual speaker authentication, to enhance performance and accelerate converge.\n","date":1690156800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690156800,"objectID":"94f8e2e9184f2654bf74ce49a32462c5","permalink":"https://yangleisx.github.io/publication/tfs-lip-seg/","publishdate":"2024-01-20T00:00:00Z","relpermalink":"/publication/tfs-lip-seg/","section":"publication","summary":"A new lip segmentation method based on fuzzy convolutional neural network with graph reasoning that can learn high-level semantics is proposed.","tags":[],"title":"Fine-Grained Lip Image Segmentation using Fuzzy Logic and Graph Reasoning","type":"publication"},{"authors":["Lei Yang"],"categories":[],"content":"Weight Decay权重衰减机制是一个比较常用的训练策略。 但是在某些场景下，需要在训练的时候关闭WeightDecay。\n例如在训练ViT的时候，对于position embedding和class token都是不需要添加WeightDecay的，在训练卷积网络的时候，对于卷积层的bias参数也是可以不添加WeightDecay的。因此需要在创建优化器的时候指明。\n# models.py class ViT(nn.Module): ... def no_weight_decay(self): return {\u0026#34;pos_embed\u0026#34;, \u0026#34;cls_token\u0026#34;} ... class Model(nn.Module): def __init__(self): self.encoder = ViT() def no_weight_decay(self): def append_prefix_no_weight_decay(prefix, module): return set(map(lambda x: prefix + x, module.no_weight_decay())) nwd_params = append_prefix_no_weight_decay(\u0026#34;encoder\u0026#34;, self.encoder) return nwd_params # train.py def train(): ... net = Model() # 获得不需要添加weightdecay的列表 no_weight_decay_list = set(net.no_weight_decay()) decay = [] no_decay = [] # 遍历并区分参数 for name, param in net.named_parameters(): if not param.requires_grad: continue # 对于卷积层中的bias不需要weight decay # 对于模型中指明不需要weight decay的部分 if param.ndim \u0026lt;= 1 or name.endswith(\u0026#34;.bias\u0026#34;) or name in no_weight_decay_list: no_decay.append(param) else: decay.append(param) # 获得多个param_group，指定不同的weightdecay参数 parameters = [ {\u0026#39;params\u0026#39;: no_decay, \u0026#39;weight_decay\u0026#39;: 0.}, {\u0026#39;params\u0026#39;: decay, \u0026#39;weight_decay\u0026#39;: 1e-5} ] # pytorch的优化器允许输入多组参数 optimizer = optim.Adam(parameters, lr=config[\u0026#39;learning_rate\u0026#39;]) ","date":1666665297,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666665297,"objectID":"21ceb3b2bb6f7aab38557cb29ea7b995","permalink":"https://yangleisx.github.io/post/no-weight-decay/","publishdate":"2022-10-25T10:34:57+08:00","relpermalink":"/post/no-weight-decay/","section":"post","summary":"Weight Decay权重衰减机制是一个比较常用的训练策略。 但是在某些场景下，需要在训练的时候关闭WeightDecay。\n","tags":[],"title":"PyTorch中No Weight Decay策略","type":"post"},{"authors":["Lei Yang"],"categories":[],"content":"扫了一些分割方面论文，截止日期2021-12-29\n针对结构的修改 专注于设计新的模块和现有网络结构的扩展。\nCNN Lanyun Zhu在CVPR2021提出的“Learning Statistical Texture for Semantic Segmentation”。基本骨架是普通的CNN提取网络加上[[DeepLab 系列]]中的ASPP。同时引入了两个新的模块TEM和PTFEM，从CNN最底层的特征图中学习纹理特征，TEM进行纹理增强，PTFEM利用计数算子QCO学习金字塔纹理特征。最后上采样得到分类，得到STLNet。\nXing Shen在CVPR2021提出的“DCT-Mask: Discrete Cosine Transform Mask Representation for Instance Segmentation”。使用了基于DCT变换的Mask表示，相比基于像素的表示降低了复杂度和计算量。\nFCN/UNet Chen Guan学长在ITFS2020年发的“Lip image segmentation based on a fuzzy convolutional neural network”。主要是还是在FCN的基础上，在特征融合的部分添加了一个Fuzzy Block进行特征的融合。\nRuigang Niu在ITGRS上发的“Improving Semantic Segmentation in Aerial Imagery via Graph Reasoning and Disentangled Learning”在特征backbone的基础上，不同大小的特征图使用图推断+上采样，进行concate，用双流的结构分别进行前景先验估计和边缘对齐，然后合并进行分割预测。\nXia Li在CVPR2020上发的“Spatial Pyramid Based Graph Reasoning for Semantic Segmentation”也是利用了U-Net和图卷积的方式 {% asset_img pyramid-gr.png pyramid-gr.png %}\n{% asset_img pyramid-gr-module.png pyramid-gr-module.png %}\nYunpeng Chen在CVPR2019上发的“Graph-Based Global Reasoning Networks”设计了一个图推断模块，将特征映射到图空间，使用GCN进行推断然后再映射回到原本的坐标空间中，可以插在FCN模型之后的位置，提升模型性能。\nZilong Zhong在CVPR2020上发的“Squeeze-and-Attention Networks for Semantic Segmentation”对SE-Net中的SE模块进行改进，使得在分割任务中的效果更好。\nYanwei Li在CVPR2020上发的“Learning Dynamic Routing for Semantic Segmentation”使用了动态路径选择的方法，\nTransformer Sixiao Zheng在CVPR2021发的“Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers”提出了SETR，将transformer应用到了图像分割中。首先进行划分patch和linear projection，然后通过24个transformer，最后通过reshape和卷积上采样得到像素级分类结果。\n针对目标场景 3D点云数据 Na Zhao在CVPR2021发的“Few-shot 3D Point Cloud Semantic Segmentation”提出一种Few-Shot的学习方法，结合Attention Learner和Metric Learner得到特征，然后使用图构造进行预测。\n多光谱数据 RGB-T数据，包含可见光和热成像数据，属于多模态学习。\nQiang Zhang在CVPR2021发的“ABMDRNet: Adaptive-weighted Bi-directional Modality Difference Reduction Network for RGB-T Semantic Segmentation”使用双流的方式，首先使用MDRF（Modality Difference Reduction and Fusion）进行Image2Image的转换，减少两个模态数据的差异，然后使用CWF，MSC，MCC三个模块进行合并再解码得到分类结果。MSC（Spatial Context）中使用了ASPP和Non-Local的结构。MCC利用了Channel Context。\n人体语义解析 Tianfei Zhou在CVPR2021发的：“Differentiable Multi-Granularity Human Representation Learning for Instance-Aware Human Semantic Parsing”进行多粒度的人体结构解析。使用自下而上的方式，实现Instance级别的结果。\n视频解析 由于我们的目标是视频数据，传统的做法是使用降采样然后对每一帧进行单独的处理，但是直觉上来看，时序上下文信息应该对于分割有一定的帮助，例如相邻帧的变化比较小的时候，上一帧中嘴唇的位置，在下一帧也大概率是嘴唇。\nPing Hu在CVPR2020发的“Temporally Distributed Networks for Fast Video Semantic Segmentation”提出了一种视频语义分割的快速网络，对每一帧使用轻量级网络提取特征然后在时序上聚合得到完整的特征进行语义分割。\n{% asset_img tdnet.png tdnet.png %}\n{% asset_img tdnet2.png tdnet2.png %}\nSi Liu在CVPR2017发的“Surveillance Video Parsing with Single Frame Supervision”也使用了多帧的光流等信息进行分割性能的增强。\n{% asset_img SVPNet SVPNet %}\nHaochen Wang在CVPR2021发的“SwiftNet: Real-time Video Object Segmentation”使用多帧信息解决VOS（Video Object Segmentation）问题。但是实际上VOS问题的定义是，对于一个视频流，在最开始的一帧分割得到目标，然后自动在后面的t帧中将相同目标检测并分割出来。\n{% asset_img Swiftnet.png Swiftnet.png %}\n针对训练方法 持续学习 模型训练好之后，增加了新的分类类别，称为持续学习。分割领域中称为CSS（Continual Semantics Segmentation）。\nArthur等人在CVPR2021发的“PLOP: Learning without Forgetting for Continual Semantic Segmentation”设计了一种新的蒸馏机制POD，保留了空间信息，在CSS过程中能够不忘记旧数据中的特征。\n元学习/无监督域适应 无监督域适应（Unsupervised Domain Adaption）\nXiaoqing Guo在CVPR2021发的“MetaCorrection: Domain-aware Meta Loss Correction for Unsupervised Domain Adaptation in Semantic Segmentation”设计了一种元学习框架。\nFew-Shot 弱监督半监督 Xun Xu等在CVPR2020上提出的“Weakly Supervised Semantic Point Cloud Segmentation: Towards 10x Fewer Labels”可以只使用几个像素的大致标注信息进行训练。\n损失函数优化 Xiaofeng Liu在CVPR2020上提出的“Severity-Aware Semantic Segmentation with Reinforced Wasserstein Training”为分割过程中的不同类型的误分类指定不同的代价。这个代价矩阵是通过强化学习的方式和Wasserstein距离的定义来导出的。\n","date":1657074755,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657074755,"objectID":"7d07b2317f3793e5742896ee4fa543c3","permalink":"https://yangleisx.github.io/post/survey-segment-2021/","publishdate":"2022-07-06T10:32:35+08:00","relpermalink":"/post/survey-segment-2021/","section":"post","summary":"扫了一些分割方面论文，截止日期2021-12-29\n","tags":["Semantics Segmentation"],"title":"2021分割新进展","type":"post"},{"authors":["Lei Yang"],"categories":[],"content":"Anaconda中的cudatoolkit是什么。\n在使用anaconda安装配置pytorch环境的时候，常常需要安装cudatoolkit。这里的cudatoolkit与CUDA Toolkit\nNVIDIA官网上下载安装的CUDA环境，包含了nvidia驱动程序、CUDA开发环境（包括NVCC编译器、调试器、相关的头文件等）、CUDA文档、CUDA示例等一系列资源。\n而Anaconda提供的cudatoolkit是一系列编译好的动态库文件。将pytorch常用的各种cuda函数编译好提供出来，只要显卡驱动版本适合，就可以直接调用其中的API。\n通常情况下，只需要安装cudatoolkit就可以正常使用。但是如果需要编写Pytorch的CUDA/C++ Extension，即手动通过CUDA实现新的功能（Layer/Operator）等，就必须保证机器上安装了官方的CUDA环境，从而实现动态的编译。\n","date":1657074628,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657074628,"objectID":"7dd9d0ab9fc8c213a42c77c5205554b3","permalink":"https://yangleisx.github.io/post/cudatoolkit/","publishdate":"2022-07-06T10:30:28+08:00","relpermalink":"/post/cudatoolkit/","section":"post","summary":"Anaconda中的cudatoolkit是什么。\n","tags":[],"title":"Anaconda中的cudatoolkit是什么","type":"post"},{"authors":[],"categories":[],"content":"对于离散信号，当所有信源符号出现的概率相等的时候取到最大的熵。\n二元离散信号 对于二元离散信号的证明如下。\n已知二元离散信号，概率为$(p,1-p)$。 信源熵为 $$ H(p) = -p\\log p - (1-p)\\log(1-p) $$\n求导可以得到 $$\\begin{align} \\frac{\\partial H(p)}{\\partial p} =\u0026amp; -(1+\\log p) + (1+\\log(1-p)) \\\\ =\u0026amp; \\log \\frac{(1-p)}{p} \u0026gt; 0 \\end{align}$$ 可以得到在$p \u0026lt; \\frac{1}{2}$时梯度为正，在$p \u0026gt; \\frac{1}{2}$时梯度为负。\n多元离散信号 对于多元离散信号的证明如下。 首先证明信息熵是一个凸函数，然后求解信息熵的最大值。\n严格凸函数 要想证明信息熵是凸函数，相当于证明$H(\\alpha P_1 + (1-\\alpha)P_2) \\geq \\alpha H(P_1) + (1-\\alpha)H(P_2)$\n构建 $$\\begin{align} \u0026amp; \\alpha H(P_1) + (1-\\alpha)H(P_2) - H(\\alpha P_1 + (1-\\alpha)P_2) \\\\ = \u0026amp; - \\alpha\\sum\\limits_{i}p_1(x_i)\\log p_1(x_i) - (1-\\alpha)\\sum\\limits_{i}p_2(x_i)\\log p_2(x_i) \\\\ \u0026amp; + \\sum\\limits_{i}(\\alpha p_1(x_i)+(1-\\alpha)p_2(x_i))\\log (\\alpha p_1(x_i)+(1-\\alpha)p_2(x_i))\\\\ = \u0026amp; \\alpha\\sum\\limits_{i}p_1(x_i)\\log\\frac{\\alpha p_1(x_i)+(1-\\alpha)p_2(x_i)}{p_1(x_i)} \\\\ \u0026amp; + (1-\\alpha)\\sum\\limits_{i}p_2(x_i)\\log\\frac{\\alpha p_1(x_i)+(1-\\alpha)p_2(x_i)}{p_2(x_i)} \\\\ \\leq \u0026amp; \\alpha\\log \\sum\\limits_{i}p_1(x_i)\\frac{\\alpha p_1(x_i)+(1-\\alpha)p_2(x_i)}{p_1(x_i)} \\\\ \u0026amp; + (1-\\alpha)\\log \\sum\\limits_{i}p_2(x_i)\\frac{\\alpha p_1(x_i)+(1-\\alpha)p_2(x_i)}{p_2(x_i)} \\\\ = \u0026amp; 0 \\end{align}$$ 所以 $\\alpha H(P_1) + (1-\\alpha)H(P_2) \\leq H(\\alpha P_1 + (1-\\alpha)P_2)$ 得证。\n考虑到Jensen不等式成立的条件为 $\\forall i, \\frac{\\alpha p_1(x_i)+(1-\\alpha)p_2(x_i)}{p_1(x_i)} = k$ 。 满足等号成立条件的有两种情况，即 $\\alpha=1$ 或者 $p_1(X)=p_2(X)$ ，这与我们 $p_1(X) \\neq p_2(X),0\u0026lt;\\alpha\u0026lt;1$ 的假设不符合。\n最大熵 已知多元离散信号，概率为 $p(x_i)$ ，并且满足约束条件 $\\sum\\limits_{i} p(x_i) = 1$ 。 使用Lagrange Multiplier方法，构建 $$ F = \\sum\\limits_{i}-p(x_i)\\log p(x_i) - \\lambda\\left( \\sum\\limits_{i} p(x_i) - 1\\right) $$\n求导可以得到 $$\\begin{align} \\frac{\\partial F}{\\partial p(x_i)} =\u0026amp; -\\log p(x_i) - 1 - \\lambda = 0 \\\\ p(x_i) =\u0026amp; e^{ -\\lambda - 1} \\end{align}$$ 已知$\\sum\\limits_{i} p(x_i) = 1$和$p(x_i) = e^{ -\\lambda - 1}$可的$p(x_i) = \\frac{1}{N}$。\n","date":1657074363,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657074363,"objectID":"d66cce8ebac113b4c61c31da77dc9770","permalink":"https://yangleisx.github.io/post/max-entropy/","publishdate":"2022-07-06T10:26:03+08:00","relpermalink":"/post/max-entropy/","section":"post","summary":"对于离散信号，当所有信源符号出现的概率相等的时候取到最大的熵。\n","tags":[],"title":"离散信号最大熵定理","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文题目：Tensor Low-Rank Reconstruction for Semantic Segmentation\n作者：Wanli Chen, Xinge Zhu, Ruoqi Sun, Junjun He, Ruiyu Li, Xiaoyong Shen, Bei Yu\n会议/时间：ECCV 2020\n链接: springer\n本文方法 整体结构如下。\n低秩分解可以形式化为 $$A = \\sum\\limits_{i=1}^{r} \\lambda_i v_{ci}\\otimes v_{hi}\\otimes v_{wi}$$\n特征分解模块的定义如下。\n特征重构模块的定义如下。\n论文里面给了矩阵分解和一些传统方法之间的差异。\n","date":1657073530,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657073530,"objectID":"e4bed64e34740be8db9ccebb5126f9d0","permalink":"https://yangleisx.github.io/post/paper-low-rank-sep/","publishdate":"2022-07-06T10:12:10+08:00","relpermalink":"/post/paper-low-rank-sep/","section":"post","summary":"论文题目：Tensor Low-Rank Reconstruction for Semantic Segmentation\n作者：Wanli Chen, Xinge Zhu, Ruoqi Sun, Junjun He, Ruiyu Li, Xiaoyong Shen, Bei Yu\n会议/时间：ECCV 2020\n链接: springer\n","tags":[],"title":"【论文】Tensor Low-Rank Reconstruction for Semantic Segmentation","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文题目：Spatial Pyramid Based Graph Reasoning for Semantic Segmentation\n作者：Xia Li,Yibo Yang, Qijie Zhao, Tiancheng Shen, Zhouchen Lin, Hong Liu\n会议/时间：CVPR2020\n链接: arXiv\n论文目标 通过在基于GCN/UNet的结构中添加Graph Reasoning 图推理来引入长距离的上下文信息依赖。使用Non-Local Block等Attention 注意力机制的解决方案计算复杂度比较高。使用图卷积网络的解决方案通常需要首先将网格状的图像数据转换/映射到图网络数据，这个映射过程的成本比较高，而且可学习的映射可能会损失数据中在空间上的关系。\n通常的图卷积网络定义在非欧式空间中，不能直接添加到现有的CNN结构中，因此论文作者设计了一个数据有关的相似度矩阵作为图卷积中的Laplacian矩阵进行图卷积的计算。\n本文方法 整体结构如下，在FCN特征融合的部分添加GR模块，进行长距离依赖的学习。 $$\\begin{align} Y^{(s+1)} \u0026amp;= GR(X^{(s+1)}) + \\Pi_{up}(Y^{(s)}) \\\\ Y^{(0)} \u0026amp;= GR(X^{(0)}) \\\\ X^{(s)} \u0026amp;= \\Pi_{down}(X^{(s+1)}) \\end{align}$$ 考虑到 $H^{l+1} = \\sigma(\\tilde L H^lW^l)$ 的图卷积网络通用格式，其中 $\\tilde L = I - \\tilde D^{-\\frac{1}{2}} \\tilde A \\tilde D^{-\\frac{1}{2}}$,$\\tilde A = A + I$ ，有 $\\tilde D_{ii} = \\sum_j \\tilde A_{ij}$ 。如果不使用欧式空间到图网络空间的映射，直接在特征图上进行图卷积。需要对模型做相应的修改。\n上式中的 $\\tilde A$ 表示正规化之后的邻接矩阵，或者称为相似度矩阵，在这个论文中使用 $\\tilde A_{ij} = \\phi(X)_i \\tilde\\Lambda(X) \\phi(X)_j^T$ 计算，即使用位置无关但是数据有关的点乘注意力实现。而不是使用训练得到的固定的邻接矩阵。这里的 $\\tilde \\Lambda$ 的计算方式采用类似通道注意力的方式实现，即先进行GAP然后卷积，最后得到对角矩阵。\n使用 $\\tilde D$ 提供了正则化，不需要再进行Softmax操作。\n在之前的图推理方法中，将像素数据映射到Interspace中，得到图结构的节点数量远少于原本的像素数量，本文中直接实现的在像素域上的计算方法计算量比较大，因此引入了简化方法。即在计算 $\\tilde D$ 的时候并不是直接计算 $\\tilde A \\in R^{HW \\times HW}$ ，而是引入一个全1的向量，得到 $\\tilde D = diag(\\tilde A \\cdot \\vec 1) = diag(\\phi(\\tilde\\Lambda(\\phi^T \\cdot \\vec 1)))$ ，将所有的矩阵计算变为和一个向量的运算。计算左乘 $\\tilde L X$ 的时候使用 $\\tilde LX = X - \\tilde D^{-\\frac{1}{2}} \\phi\\tilde\\Lambda\\phi^T\\tilde D^{-\\frac{1}{2}}X = X - P(\\tilde\\Lambda(P^TX))$ ，其中 $P = \\tilde D^{-\\frac{1}{2}}\\phi$ 。\n结果分析 首先进行Ablation Study。对于GR模块提出的Laplacian各个部分进行对比。可以看到效果提升。\n在Cityscapes、Pascal VOC和MS COCO数据集上做了实验。\n","date":1657072905,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657072905,"objectID":"2ff1dda870eaf8034bcc6dea8f8922d8","permalink":"https://yangleisx.github.io/post/paper-spygr/","publishdate":"2022-07-06T10:01:45+08:00","relpermalink":"/post/paper-spygr/","section":"post","summary":"论文题目：Spatial Pyramid Based Graph Reasoning for Semantic Segmentation\n作者：Xia Li,Yibo Yang, Qijie Zhao, Tiancheng Shen, Zhouchen Lin, Hong Liu\n会议/时间：CVPR2020\n链接: arXiv\n","tags":["Semantic Segmentation"],"title":"【论文】Spatial Pyramid Based Graph Reasoning for Semantic Segmentation","type":"post"},{"authors":["Lei Yang"],"categories":[],"content":"ECCV2020提出的一种上下文信息融合方式。\n主要是使用与当前位置类别相同的区域的特征来增强当前位置的表示。与DeepLab中的ASPP相比效果更好。\n在论文中指出这样的方法和使用Transformer 模块的结构相似，都使用了Self-Attention 自注意力。\n图中Soft Object Regions是利用分割Loss监督的K通道粗分割结果，Pixel Representation是Backbone得到的C通道特征，使用矩阵相乘直接得到$B\\times C \\times K$的关系矩阵，使用特征作为Q，关系矩阵作为K和V，通过$softmax(\\frac{Q^TK}{\\sqrt{d_k}})V$计算得到增强后的特征，与原本的特征相连接用于分割。\n这篇论文和HRNet是同一个团队做的，因此HRNet+OCR已经称为一种非常强分割Backbone。代码放到了github。\n在文章中，作者提出了一种改进Segmentation Transformer，同时被NVIDIA的团队改进，提出了《HIERARCHICAL MULTI-SCALE ATTENTION FOR SEMANTIC SEGMENTATION》。\n当SegFix出现之后，也经常使用HRNet+OCR+SegFix作为比赛中常用的分割Backbone。\n","date":1657072719,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657072719,"objectID":"6afaf6d7eeeacea3a3f0754d56c4ca5c","permalink":"https://yangleisx.github.io/post/paper-ocrnet/","publishdate":"2022-07-06T09:58:39+08:00","relpermalink":"/post/paper-ocrnet/","section":"post","summary":"ECCV2020提出的一种上下文信息融合方式。\n主要是使用与当前位置类别相同的区域的特征来增强当前位置的表示。与DeepLab中的ASPP相比效果更好。\n","tags":["Semantics Segmentation"],"title":"OCRNet","type":"post"},{"authors":["Fangqi Li","Lei Yang","Shilin Wang","Alan Wee-Chung Liew"],"categories":null,"content":" This paper presents MTLSign, an MTL-based DNN watermarking scheme. We examine the basic security requirements for the DNN watermark, especially the unambiguity, and propose to embed the watermark as an additional task.\nThe proposed scheme explicitly meets security requirements by corresponding regularizers. With a decentralized consensus protocol, MTLSign is secure against adaptive attacks. It is true that like any other white-box DNN watermarking scheme, MTLSign remains vulnerable to functionality equivalence attacks such as the neuron permutation. This is one of the aspects that require further effort to increase the applicability of DNN watermarks.\n","date":1646006400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646006400,"objectID":"4ef88e8dc053666bc23b5353aadd54ff","permalink":"https://yangleisx.github.io/publication/aaaiw-mtl-watermark/","publishdate":"2024-01-20T00:00:00Z","relpermalink":"/publication/aaaiw-mtl-watermark/","section":"publication","summary":"MTLSign, an MTL-based DNN watermarking scheme","tags":null,"title":"Leveraging Multi-task Learning for Unambiguous and Flexible Deep Neural Network Watermarking","type":"publication"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文题目： Embedding Watermarks into Deep Neural Networks\n作者： Yusuke Uchida, Yuki Nagai, Shigeyuki Sakazawa\n会议/时间：ICMR 2017\n链接: arXiv\n论文目标 目前预训练深度神经网络的应用越来越广，需要一种数字水印技术来保护预训练深度神经网络的知识产权，避免被滥用。论文首先定义了水印技术的场景，并提出了一种水印嵌入技术，可以在模型训练、精调或者蒸馏过程中嵌入到目标模型中且不影响模型性能。并且面对攻击者的精调和剪枝等行为时仍能保留在模型中。\n问题定义 模型水印要求 要求 解释 Fidelity 添加水印之后模型的性能没有明显下降 Robustness 模型经过修改后水印仍存在 Capacity 水印技术应该能够嵌入大量信息 Security 水印应该难以被他人读写和修改 Efficiency 嵌入和提取水印的过程应该足够快 模型水印嵌入方法 在训练过程中嵌入（Train From Scratch） 在精调过程中嵌入（Fine-Tuning） 在蒸馏过程中嵌入（Model Distillation） 攻击方法 精调（Fine Tuning） 模型压缩（Model Compression） 本文方法 主要考虑卷积神经网络中卷积层的参数。对于一个$Kernel-Size=S$，输入通道数为$D$，输出通道数（卷积核数量）为$L$的卷积层，不考虑偏置，其参数为$W \\in \\mathbb{R}^{S\\times S\\times D\\times L}$。计算多个卷积核的均值 $ {\\bar W}_{i,j,k}=\\frac{1}{L}\\sum_l W_{i,j,k,l} $，并展平得到$w \\in \\mathbb{R}^M(M = S\\times S\\times D)$作为嵌入的目标。将$T$-bit的信息$b\\in {0,1}^T$嵌入其中。\n在提取时，使用$b_j = s(\\sum_i X_{ji}\\omega_i)$计算嵌入的信息。其中$\\omega$表示卷积核均值，$X \\in \\mathbb{R}^{T \\times M}$表示嵌入密钥，$s(\\cdot)$为阶跃函数。\n在训练时，为了将信息嵌入模型中，在原本的损失函数上添加了一个权重参数正则项$E(\\omega)=E_0(\\omega)+\\lambda E_R(\\omega)$。\n考虑到上述的模型提取方式类似二分类方法，因此添加的权重参数正则项使用BCE损失，使用训练过程中的参数提取结果作为监督。\n$$\\begin{aligned} E_R(\\omega)=\u0026amp; -\\sum\\limits_{j=1}^{T}(b_j \\log(y_j)+(1-b_j)\\log(1-y_j)) \\\\ y_j =\u0026amp; \\sigma(\\sum_i X_{ji}\\omega_i)\\\\ \\sigma(x) =\u0026amp; \\frac{1}{1+\\exp(-x)} \\end{aligned}$$ 关于密钥$X$的设计，考虑到水印的性能，有三种设计形式：$X^{direct}$的每一行为独热码，直接将信息映射到参数中。$X^{diff}$的每一行包含一个1和一个-1，其他的为0，将信息映射到参数的差值中。$X^{random}$的数字采样于标准正态分布。\n结果分析 Ablation Study 关于密钥$W$的设计，实验证明使用$X^{direct}$和$X^{diff}$嵌入都会造成较大的性能下降。 而且可以看到$X^{random}$不仅不造成性能下降，而且对原始的参数分布影响不大。 经过实验发现，当嵌入的信息量超过卷积层参数数量的时候，嵌入损失和性能下降会变得明显。而且采用直接嵌入的方式会难以在性能下降和嵌入损失之间达到均衡。\nRobustness 实验证实这一方法可以应对Fine-Tuning和迁移学习。 面对剪枝操作时，特别是按照权重升序的剪枝方法时仍然能保留水印。 总结 提出了一种，为权重参数添加正则项的水印嵌入方法，其水印提取是通过矩阵映射的方式实现的。具有一定的鲁棒性。\n","date":1634618181,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1634618181,"objectID":"f036caa6627703d4635b69425b969d4e","permalink":"https://yangleisx.github.io/post/paper-uchida/","publishdate":"2021-10-19T12:36:21+08:00","relpermalink":"/post/paper-uchida/","section":"post","summary":"论文题目： Embedding Watermarks into Deep Neural Networks\n作者： Yusuke Uchida, Yuki Nagai, Shigeyuki Sakazawa\n会议/时间：ICMR 2017\n链接: arXiv\n","tags":["Watermarks"],"title":"【论文】Embedding Watermarks into Deep Neural Networks","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文题目：Look More Than Once: An Accurate Detector for Text of Arbitrary Shapes\n作者：Chengquan Zhang， Borong Liang， Zuming Huang， Mengyi En，Junyu Han，Errui Ding， Xinghao Ding\n会议/时间：CVPR2019\n链接: ieeexplore\n论文目标 现有模型受到感受野的限制，很难实现对于长文本和弯曲文本的准确识别。论文中设计实现了一个LOMO网络，首先通过DR获得粗检测结果，再使用IRM迭代优化结果，最后使用SEM得到任意多边形的文本检测结果。\n相关工作 目前的文本检测有三种思路：\n基于Component，检测到文本部分然后通过后处理合并。例如CTPN、SegLink、WordSup等。 基于Detection，类似通用的目标检测。例如TextBoxes、RRD、RRPN、EAST等。 基于Segmentation，类似语义分割。例如TextSnake、PSENet等。 本文方法 整体的模型结构如下。基本的特征提取部分使用ResNet50和FPN实现。最终得到1/4大小的128通道的特征图。 提取到的图像特征首先经过Direct Regressor得到粗检测结果。这里DR的设计与EAST基本相同，包括test/non-text分类结果和四个边界点的偏移值。在训练分类结果时使用了一种改进的Dice-Loss。其中的权重$w$被设置为与文本框的短边长度称反比。 $$L_{cls} = 1 - \\frac{2 * sum(y * \\hat{y} * w)}{sum(y*w) + sum(\\hat{y} * w)}$$\nIRM的结构如下。首先根据DR的结果，从FPN的特征中使用ROI Transform提取特征，并使用卷积和Sigmoid激活得到四个通道的注意力图（分别为四个边角）。通过Reduce-Sum和卷积得到四个边角的偏移量。对DR的结果进行修正。 IRM部分的损失函数为使用Smoothed-L1来监督。 $$L_{irm} = \\frac{1}{K*8}\\sum\\limits_{k=1}^{K}\\sum\\limits_{j=1}^{8}smooth_{L1}(c_k^j - \\hat{c}_k^j)$$\nSEM的结构如下。根据IRM修正之后的结果，进一步得到多边形框的结果。除去上述检测框中的背景部分。首先同样是使用ROI Transform提取特征，然后经过两次上采样之后，再生成预测结果，包括文本区域、文本中心线（收缩后的文本区域）、边界偏置。 要想得到文本检测结果，需要首先在文本中心线上采样N个点，然后根据边界偏置得到文本行的上下边界上的控制点，相连接得到多边形框。\n在训练时，首先使用生成数据对DR部分进行训练，然后才使用真实数据同时训练三个分支。为了防止训练时DR产生的错误结果影响另外两分支的训练，将DR结果中的50%随机替换为GT。在预测的时候DR的结果经过NMS之后再经过多次IRM，最后通过SEM得到结果。\n结果分析 ablation study显示，IRM迭代次数增加可以提升模型性能，但是相应的处理时间增加，因此权衡之后设置为2。在IRM中，添加四个角点的注意力图也可以提升模型性能。\nablation study显示，添加SEM可以显著提升模型性能（7.17%）。对于SEM结果的处理中，采样点数量增加效果提升并逐渐收敛，因此选择为7。\n在长文本数据集ICDAR2017-RCTW上的效果如下。 在弯曲文本数据集ICDAR2015上的效果如下。 在多语言数据集ICDAR2017-MLT上的效果如下。 总结 设计了IRM在粗检测结果上精调。 设计了SEM实现文本框形状的优化，从四边形变换为任意形状。\n","date":1634285966,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1634285966,"objectID":"533156cf8dcb0763a01451b0f5d9fbe8","permalink":"https://yangleisx.github.io/post/paper-lomo/","publishdate":"2021-10-15T16:19:26+08:00","relpermalink":"/post/paper-lomo/","section":"post","summary":"论文题目：Look More Than Once: An Accurate Detector for Text of Arbitrary Shapes\n作者：Chengquan Zhang， Borong Liang， Zuming Huang， Mengyi En，Junyu Han，Errui Ding， Xinghao Ding\n会议/时间：CVPR2019\n链接: ieeexplore\n","tags":["Text Detection"],"title":"【论文】Look More Than Once: An Accurate Detector for Text of Arbitrary Shapes","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文题目：MOST: A Multi-Oriented Scene Text Detector with Localization Refinement\n作者：Minghang He, Minghui Liao, Zhibo Yang, Humen Zhong, Jun Tang, Wenqing Cheng, Cong Yao, Yongpan Wang, Xiang Bai\n会议/时间：CVPR 2021\n链接: arXiv\n论文目标 传统的文本检测算法对于长文本和小文本的检测效果比较差。为了解决长文本和小文本的检测问题，引入了新的NMS、IoU Loss和特征对齐模块。\n例如在EAST中，由于使用分类输出作为NMS的权重，而且模型感受野比较小，很难获得足够的信息检测到长文本。\n相关工作 现有的文本检测算法主要包括两种思路，自下而上和自上而下。其中前者主要是检测到文本中的部分元素，然后合并得到完整的检测结果，包括SegLink、TextSnake、CRAFT、PSENet等，由于需要复杂的后处理算法处理模型的输出结果，整体的处理效率受限制，而且后处理算法的效果也会影响到整体的结果。后者直接使用模型输出文本边框的检测结果，包括EAST、TextBoxes等。自上而下的又可以分为一阶段的和两阶段的，前者直接输出模型结果，后者包括Mask TextSpotter系列，使用类似Mask R-CNN的思路，首先使用RPN输出Proposal。\n在LOMO模型中，使用了迭代优化模型，使用RoI Transform迭代优化模型结果，从而解决长文本的检测问题。\n本文方法 模型整体结构如下，特征提取模块使用了基于ResNet50的FPN网络，上下两个分支来自EAST中的分类和位置预测图。 来自EAST的两个分支的监督与EAST相同。分类分支使用向内收缩后的文本框表示，位置预测图包括四个通道，表示当前位置距离文本框上下左右的距离。 TFAM的结构如下。首先生成粗检测结果，然后将粗检测结果和特征传入变形卷积层中。其中变形卷积选择采样点有两种方式，分别是Feature-Based Sampling和Localization-Based Sampling。其中，前者是使用额外的卷积来计算采样点的偏移量，后者是直接使用当前点预测的粗检测框的位置作为偏移后的采样点。 本文中提出的Position-awareness NMS与EAST中的locality-awareness NMS不同。在EAST中进行的NMS是，是利用加权平均的方式，使用Text/Non-Text分类的结果作为权值进行加权和然后进行正常的NMS。\n本文中提出的PA-NMS基于一个假设，距离边界越近的点，得到的距离边界的距离越准确，因此在聚合的时候使用的权重为当前点距离边界的位置。当使用边框p和q聚合得到m时，计算过程如下。其中TBLR分别为EAST输出的Geo-Map的四个通道，即Position-Awareness Map。 其中Position-Awareness Map（相当于EAST中的Geo-Map归一化到0-1）的生成方式如下。 在损失函数的选择上，原本EAST中使用IoU-Loss。但是文中提到如下观点。因此引入了Instance-wise IoU Loss。\nthe large text region contains far more positive samples than the small text region, which makes the regression loss bias towards large and long text instances.\n其中$N_t$为Text Instance的数量，$S_j$为每个Text Instance中Positive Sample的数量。（这里我没有很清楚具体Text Instance和Positive Sample的定义，为理解为对于每一个Text/Non-Text分类为真的点都要计算IoU，对于面积比较大的文本计算IoU的次数比较多，导致模型偏重大文本和长文本。） 最终的损失函数定义如下，完整的损失包括分类损失、检测损失、位置损失。分类损失使用BCE-Loss计算，位置损失使用Smoothed L1-Loss计算。在检测损失中包括了检测结果的IoU-Loss和边界框角度的Cosine-Loss。 $$\\begin{align} L \u0026amp;= L_s + \\lambda_{gc} L_{gc} + \\lambda_{gr} L_{gr}+ \\lambda_{p} L_{p} \\\\ L_s \u0026amp;= \\operatorname{BCE-Loss}() \\\\ L_g \u0026amp;= L_{iou} + \\lambda_{i} L_{ins-iou} + \\lambda_{\\theta} L_{\\theta} \\\\ L_{\\theta} \u0026amp;= \\frac{1}{|\\Omega|}\\sum\\limits_{i \\in \\Omega}1-\\cos (\\hat{\\theta_i} - \\theta_i^*) \\\\ L_p \u0026amp;= \\frac{1}{4|\\Omega|}\\sum\\limits_{i \\in \\Omega}\\sum\\limits_{\\Psi \\in \\{L,R,T,B\\}}\\operatorname{SmoothedL1}(\\hat{\\Psi_i}-\\Psi_i^*) \\end{align}$$ 结果分析 在数据集SynthText上预训练，在数据集MLT17、MTWI、IC15、MSRA-TD500(with HUST-TR400)上训练和测试。\n在Ablation Study中，证明Localization-Based Sampling相比Feature-Based Sampling效果更好，而同时结合这两种的效果最好。同时也证明了本文中提出的TFAM、PA-NMS、Instance-wise IoU Loss都能提升模型的性能。 在与SOTA模型的比较中，MOST也都能获得不错的性能提升。\n总结 为了解决长文本的检测问题，引入了TFAM扩展感受野修正粗检测结果。 为了解决不同大小的文本的检测问题，引入了Instance-wise IoU Loss，防止损失函数过度关注大文本和长文本目标。 在NMS阶段引入了Position-Aware NMS，可以更好的合并检测框。\n","date":1625794524,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625794524,"objectID":"292a2d4eecb0108b829cd6216478f966","permalink":"https://yangleisx.github.io/post/paper-most/","publishdate":"2021-07-09T09:35:24+08:00","relpermalink":"/post/paper-most/","section":"post","summary":"论文题目：MOST: A Multi-Oriented Scene Text Detector with Localization Refinement\n作者：Minghang He, Minghui Liao, Zhibo Yang, Humen Zhong, Jun Tang, Wenqing Cheng, Cong Yao, Yongpan Wang, Xiang Bai\n会议/时间：CVPR 2021\n链接: arXiv\n","tags":["Text_Detection"],"title":"【论文】MOST: A Multi-Oriented Scene Text Detector with Localization Refinement","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文题目：Shape Robust Text Detection with Progressive Scale Expansion Network\n作者：Wenhai Wang, Enze Xie, Xiang Li, Wenbo Hou, Tong Lu, Gang Yu, Shuai Shao\n会议/时间：CVPR2019\n链接：arxiv\n论文目标 在当前的文字检测算法在应用时有两个问题：当前的算法通常得到一个四边形边界框，难以检测任意形状的文本；如果两行文本距离比较近，有可能会被框选为同一个边界框。因此提出了PSENet，可以有效的解决上述的两个问题。\n相关工作 现有的基于CNN的文本检测模型可以分为两类：基于回归的方案和基于分割的方案。前者生成四边形的边界框，无法处理任意形状的文本，后者使用像素级的分类得到目标区域，但是很难区分开相聚比较近的目标。\n基于回归的文本检测方案大多是基于通用的目标检测模型，包括Faster R-CNN等。其他的文本检测模型还有TextBoxes、EAST等。大多数这一类的模型都需要设计Anchor而且由多个处理阶段组成，可能会导致性能比较差。基于分割的文本检测方案主要使用FCN，例如通过FCN获得热力图等，再进行后处理获得文本位置。\n本文思路/解决方案 本文提出的PSENet是基于分割的方案，每一个预测的分割称为kernel，形状相似但是大小不同，最后设计了一个基于BFS的渐进扩展算法，将原本的kernel扩展得到最终的预测分割。由于使用渐近扩展式的算法，对于最小尺寸的kernel，可以区分开距离较近的文本，同时也可以解决小尺寸分割难以覆盖完整文本的问题。\n模型结构是基于ResNet的FPN结构，从中选取不同大小的特征图连接得到混合特征图，最后通过卷积等操作得到不同尺寸的多个分割图，再经过尺寸扩展得到预测结果。\n在这个尺寸扩展算法中，首先选择了尺寸最小的分割图进行连通域分析作为kernel，然后将其他的分割图作为输入，通过Scale Expansion算法计算新的扩展后的kernel，最终得到结果。作者提到对于位于多个文本之间的像素，使用先来先服务的方式合并到不同的标签中，同时由于使用了渐进式的方法，这些边界上的重合并不会影响最终的处理结果，这可能也是作者选择多个不同尺寸的分割图渐近处理的原因。\n在训练过程中，为了获得不同尺寸的分割图，需要提供对应的标签供学习，作者使用了Vatti clipping algorithm来将最初的文本框标签收缩一定的像素得到这些标签。算法中使用到的像素值通过下面的公式计算得到。其中m为最小的缩放比例，n为不同尺寸的分割图的个数。\n$$\\begin{aligned} d_i = \\frac{\\mathrm{Area}(p_n)\\times(1-r_i^2)}{\\mathrm{Perimeter}(p_n)}\\notag\\\\ r_i = 1 - \\frac{(1-m)\\times(n-i)}{n-1} \\end{aligned}$$ 在实验中作者使用了Dice Coefficient作为模型的评价指标，使用了完整尺寸的标签和缩放后的标签上的Dice系数作为损失函数来指导模型的学习。其中对于完整尺寸的标签，使用Online Hard Example Mining(OHEM)来获得一个mask协助训练。 $$\\begin{aligned} L \u0026amp;= \\lambda L_c + (1-\\lambda)L_s\\notag\\\\ L_c \u0026amp;= 1 - D(S_n\\cdot M, G_n \\cdot M)\\notag\\\\ L_s \u0026amp;= 1 - \\frac{\\sum\\limits^{n-1} D(S_i\\cdot W, G_i \\cdot W)}{n-1}\\notag\\\\ W_{x,y} \u0026amp;= \\left\\{ \\begin{align} 1,\u0026amp; \\quad if\\ S_{n,x,y} \\geq0.5;\\notag\\\\ 0,\u0026amp; \\quad otherwise\\notag\\\\ \\end{align} \\right. \\end{aligned}$$ 结果 实验包括了四个数据集：CTW1500、Total-Text、ICDAR2015和ICDAR2017MLT。模型使用预训练好的ResNet，在IC17-MLT上训练，而且没有使用另外的人造数据集。实验讨论的结果包括：\n最小尺寸的kernel并不能直接作为模型的输出，模型的F-measure结果比较差，而且文本框内容的识别结果也比较差。 对于最小缩放比例m的选择，选择太大或者太小都会导致性能的下降。 分割图的个数n增加时，性能会有一定的上升，但是不能无限制增大，在n大于5之后性能提升不大。 修改模型骨架，例如增加ResNet的层数也会提升模型的性能。 总结 使用了基于FPN的结构，将不同尺度的特征图上采样并连接在一起。\n获得不同尺度下的分割图，再从小到大渐进式的合并，不仅可以检测到任意形状的文本，也可以避免将距离比较近的文本识别为同一对象。\n","date":1605754555,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605754555,"objectID":"439ed86e8c0f5c7d5db042a857d4da49","permalink":"https://yangleisx.github.io/post/paper-psenet/","publishdate":"2020-11-19T10:55:55+08:00","relpermalink":"/post/paper-psenet/","section":"post","summary":"论文题目：Shape Robust Text Detection with Progressive Scale Expansion Network\n作者：Wenhai Wang, Enze Xie, Xiang Li, Wenbo Hou, Tong Lu, Gang Yu, Shuai Shao\n会议/时间：CVPR2019\n链接：arxiv\n","tags":["Text Detection","Deep Learning","Computer Vision"],"title":"【论文】Shape Robust Text Detection with Progressive Scale Expansion Network","type":"post"},{"authors":["Lei Yang"],"categories":["代码学习"],"content":"最近接手了一个Linux下内核编程的项目，在阅读项目原有代码的基础上，学到了很多新知识，总结一下记录在这里。\n在这个项目中，使用SQLite存储用户数据，因此需要在C语言中实现SQLite的访问和增删改查处理。\n实际上由于C语言不支持面向对象的操作，因此无法使用对象关系模型来进行处理，只能在C语言中使用SQL语句操纵数据库。\n基本操作 打开数据库 需要指定数据库文件的路径，如果不存在的话就会在指定的路径创建一个db文件保存数据库的数据。\n#include \u0026lt;sqlite3.h\u0026gt; sqlite3 * db; // 连接数据库 rc = sqlite3_open(\u0026#34;fvault.db\u0026#34;, \u0026amp; db); if (rc) { printf(\u0026#34;%s\\n\u0026#34;, \u0026#34;SQLITE OPEN ERROR\u0026#34;); sqlite3_close(db); exit(1); } 执行SQL语句 通过将SQL语句写在字符串中，可以执行SQL语句，在执行SQL语句时，可以设置一个回调函数，数据库操作结束后会调用回调函数对数据库返回的数据做响应的处理。\nsqlite3_exec的参数分别为数据库对象、SQL语句、回调函数、互调函数的参数、错误信息指针。\n无回调函数 #define CREATE \u0026#34;CREATE TABLE IF NOT EXISTS fvault\u0026#34;\\ \u0026#34;(\u0026#34; \\ \u0026#34;inode INTEGER PRIMARY KEY,\u0026#34; \\ \u0026#34;owner INTEGER\u0026#34; \\ \u0026#34;)\u0026#34; rc = sqlite3_exec(db, CREATE, NULL, 0, NULL); if (rc != SQLITE_OK) { printf(\u0026#34;%s\\n\u0026#34;, \u0026#34;ERROR\u0026#34;); sqlite3_close(db); exit(1); } 无参数的回调函数 // 回调函数，对于数据库返回的每一行都执行一次 // void* NotUsed 参数保留位置，无参数时不使用 // int argc 返回字段的个数 // char ** argv 每一个字段的值 // char ** azCoolName 字段的名称 static int callback_get_filelist(void * NotUsed, int argc, char ** argv, char ** azColName) { for (int i = 0; i \u0026lt; argc; i++) printf(\u0026#34;%s\\n\u0026#34;, argv[i]); return 0; } // 执行SQL语句 #define SELECT1 \u0026#34;SELECT inode, owner FROM fvault\u0026#34; uid_t owner = 1000; snprintf(sql, 63, SELECT1, owner); rc = sqlite3_exec(db, sql, callback_get_filelist, 0, NULL); if (rc != SQLITE_OK) { printf(\u0026#34;%s\\n\u0026#34;, \u0026#34;ERROR\u0026#34;); sqlite3_close(db); exit(1); } 有参数的回调函数 使用第四个参数传递参数的指针，在回调函数中可以实现赋值。\n// 回调函数，对于数据库返回的每一行都执行一次 // void* result 输入的参数 // int argc 返回字段的个数 // char ** argv 每一个字段的值 // char ** azCoolName 字段的名称 static int callback_get_fileowner(void * result, int argc, char ** argv, char ** azColName) { // 将查询得到的值赋给参数 if (argc == 1) * (uid_t *)result = atoi(* argv); return 0; } // 执行SQL语句 #define SELECT2 \u0026#34;SELECT owner FROM fvault WHERE inode = %lu LIMIT 1\u0026#34; unsigned long inode = 40075; snprintf(sql, 63, SELECT2, inode); rc = sqlite3_exec(db, sql, callback_get_fileowner, \u0026amp; result, NULL); if (rc != SQLITE_OK) { printf(\u0026#34;%s\\n\u0026#34;, \u0026#34;ERROR\u0026#34;); sqlite3_close(db); exit(1); } 关闭数据库 sqlite3_close(db); 编译 安装依赖 需要使用apt安装依赖的库文件\nsudo apt install libsqlite3-dev 指定库 编译时需要指定库文件\ngcc main.c -l sqlite3 -o main 总结 可以参考SQLite的C接口或者参考官网提供的接口文档。\n","date":1605340168,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605340168,"objectID":"1cdf197943901aad33c46a65b9b23630","permalink":"https://yangleisx.github.io/post/sqlite-c/","publishdate":"2020-11-14T15:49:28+08:00","relpermalink":"/post/sqlite-c/","section":"post","summary":"最近接手了一个Linux下内核编程的项目，在阅读项目原有代码的基础上，学到了很多新知识，总结一下记录在这里。\n在这个项目中，使用SQLite存储用户数据，因此需要在C语言中实现SQLite的访问和增删改查处理。\n","tags":["C/C++","Linux","SQL"],"title":"SQLite的C语言接口","type":"post"},{"authors":[],"categories":["代码学习"],"content":"最近接手了一个Linux下内核编程的项目，在阅读项目原有代码的基础上，学到了很多新知识，总结一下记录在这里。\n在这个项目中，编写内核模块进行加解密操作，使用了Linux内核提供的crypto加密API。\n环境 操作系统：Ubuntu18.10（使用Linux 4.18.0-25内核）\n使用的头文件如下：\n#include \u0026lt;crypto/hash.h\u0026gt; #include \u0026lt;crypto/skcipher.h\u0026gt; #include \u0026lt;linux/cred.h\u0026gt; #include \u0026lt;linux/scatterlist.h\u0026gt; 概述 在Linux内核中提供了加密API，通过一组头文件crypto引出。整体的思路为首先创建加密上下文，并且在上下文中注册使用的算法，最后使用内核API完成加解密的操作。这里以散列计算和对称加密为例。\n散列操作 函数目标为通过用户的ID（长度为4Byte）生成长度为32Byte的序列作为对称加密的密钥。\nstatic void generate_key(unsigned char* key) { // 创建散列操作 struct shash_desc sdesc; uid_t uid = current_uid().val; short i; // 申请运算上下文，指定算法为crc32-pclmul sdesc.tfm = crypto_alloc_shash(\u0026#34;crc32-pclmul\u0026#34;, 0, 0); // 这里选择的hash算法每次生成4Byte(32bit)长度的输出 // 满足32Byte(256bit）长度的密钥需要迭代生成 // 每次使用之前生成的部分计算哈希，将结果与之前的结果拼接起来 crypto_shash_digest(\u0026amp;sdesc, (char*)\u0026amp;uid, sizeof(uid_t), key + 28); for (i = 28; i \u0026gt; 0; i -= 4) { crypto_shash_digest(\u0026amp;sdesc, key + i, 32 - i, key + i - 4); } // 释放空间 crypto_free_shash(sdesc.tfm); } 对称加密 函数目标为当读写文件时，使用加密读写，加密是使用的参数来自用户、文件Inode、读写的位置。实现的细节参见注释。\nstatic void transform(char* ubuf, unsigned long inode, loff_t offset, size_t count) { // 创建对称加密操作 struct crypto_skcipher* skcipher = NULL; struct skcipher_request* req = NULL; struct scatterlist sg; // 密钥和初始化向量的空间 unsigned char key[32] = { 0 }; char ivdata[16] = { 0 }; // 处理时以16Byte(128bit)为单位 // 将文件分为16Byte的分段时，偏移量低四位表示位于上一分段的字节数 // 因此需要额外处理，将上一分段读取出来 short pre_len = offset \u0026amp; 0xf; char prefix[15] = { 0 }; // char* buf; buf = (char*)kmalloc(count + pre_len, GFP_KERNEL); copy_from_user(buf + pre_len, (void *)ubuf, count); // 为算法申请内核中运算的上下文 // 在crypto_alg_list链表中查询，找到AES的CTR模式并注册 // 在内核中为该算法的各个函数指针初始化 skcipher = crypto_alloc_skcipher(\u0026#34;ctr-aes-aesni\u0026#34;, 0, 0); // 在该上下文空间中申请数据处理请求 // 实际上完成了后台的内存申请和绑定 req = skcipher_request_alloc(skcipher, GFP_KERNEL); // 创建256bit的密钥，并写入本次运算的上下文内存中 generate_key(key); crypto_skcipher_setkey(skcipher, key, 32); // 创建初始化向量iv generate_iv(ivdata, inode, offset \u0026gt;\u0026gt; 4); // 在内存空间中开辟并维护一段内存 // scatterlist用于维护大段的被多个组件访问的内存（例如，CPU和DMA） // 根据位于上一分段的字节数扩展需要的内存 sg_init_one(\u0026amp;sg, buf, count + pre_len); // 将待加密数据放入本次运算的请求空间 // 第二/三参数分别表示source和destination // 第四/五参数为待加密数据的长度和初始化向量 skcipher_request_set_crypt(req, \u0026amp;sg, \u0026amp;sg, count + pre_len, ivdata); // 开始加密 // 将位于上一分段的数据保护在prefix中，防止被二次加密 memcpy(prefix, buf, pre_len); crypto_skcipher_encrypt(req); memcpy(buf, prefix, pre_len); copy_to_user((void *)ubuf, buf + pre_len, count); kfree(buf); // 清空本次处理的内存，释放空间 skcipher_request_free(req); crypto_free_skcipher(skcipher); } 总结 在Linux内核编程的过程中，需要注意使用的API和数据结构大多与用户态不太相同，这个时候需要查看内核中的相关代码寻找线索。\n可以使用在线文档工具查看相关的函数定义。\n","date":1605253347,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605253347,"objectID":"b10a88138c99153293a40cc11f328b76","permalink":"https://yangleisx.github.io/post/cpp-crypto/","publishdate":"2020-11-13T15:42:27+08:00","relpermalink":"/post/cpp-crypto/","section":"post","summary":"最近接手了一个Linux下内核编程的项目，在阅读项目原有代码的基础上，学到了很多新知识，总结一下记录在这里。\n在这个项目中，编写内核模块进行加解密操作，使用了Linux内核提供的crypto加密API。\n","tags":["C/C++","Linux"],"title":"Linux内核加密模块crypto的使用","type":"post"},{"authors":["Lei Yang"],"categories":["代码学习"],"content":"最近接手了一个Linux下内核编程的项目，在阅读项目原有代码的基础上，学到了很多新知识，总结一下记录在这里。\n在这个项目中，编写内核模块进行操作，与用户态进程之间使用Netlink Socket进行通信。\n用户空间和内核空间相互通信的方式有三种，/proc目录、ioctl和neltink。使用netlink可以很很简单的建立起内核态和用户态的全双工通信，并且可以使用简单的socket语法进行操作，比较简单。需要注意的是，内核中已经定义了多种netlink消息类型/协议，如果不使用现成的消息类型可以添加一个新的协议定义。\n需要注意的是，使用netlink通信的用户态和内核态的语法有些许的不同。而且在netlink的数据传输并不是同步的，而是将报文信息加到了接收者的接受队列中，因此netlink socket支持iov机制，也就是在一次系统调用的过程中，将多个报文信息打包发送。\n环境 操作系统：Ubuntu 18.10（使用Linux 4.18.0-25内核）\n基本数据结构 // Netlink使用sockaddr_nl地址 struct sockaddr_nl { __kernel_sa_family_t nl_family; unsigned short nl_pad; __u32 nl_pid; __u32 nl_groups; }; // struct nlmsghd 是netlink消息头 struct nlmsghdr { __u32 nlmsg_len; __u16 nlmsg_type; __u16 nlmsg_flags; __u32 nlmsg_seq; __u32 nlmsg_pid; }; /* iov_base: iov_base指向数据包缓冲区，即参数buff， iov_len是buff的长度。 msghdr中允许一次传递多个buff，以数组的形式组织在 msg_iov中，msg_iovlen就记录数组的长度 */ struct iovec { void *iov_base; size_t iov_len; }; // msghdr是发送的报文信息的头部 struct msghdr { void *msg_name; socklen_t msg_namelen; struct iovec *msg_iov; size_t msg_iovlen; void *msg_control; size_t msg_controllen; int msg_flags; }; 基本操作 用户态：相关变量 // 创建所需的变量 struct sockaddr_nl src_sockaddr, dest_sockaddr; struct nlmsghdr * nlh = NULL; struct msghdr msg; struct iovec iov; // 变量初始化 nlh = (struct nlmsghdr *)malloc(NLMSG_SPACE(sizeof(unsigned long))); memset(\u0026amp; src_sockaddr, 0, sizeof(struct sockaddr_nl)); memset(\u0026amp; dest_sockaddr, 0, sizeof(struct sockaddr_nl)); memset(nlh, 0, NLMSG_SPACE(sizeof(unsigned long))); memset(\u0026amp; msg, 0, sizeof(struct msghdr)); 用户态：创建socket 如果不使用内核中定义好的协议类型，可以自己增加一个新的协议定义作为socket的初始化参数。\n#define NETLINK_SAFE 30 server_sock = socket(AF_NETLINK, SOCK_RAW, NETLINK_SAFE); 用户态：绑定地址 通常使用进程号作为用户空间的socket地址。实际上只是一个socket的标示号码，可以任意设置，对于同一个进程的不同线程可以使用不同的标示号。\n由于netlink支持多播，还需要指定多播组，指定为0时表示不开启多播功能。\nsrc_sockaddr.nl_family = AF_NETLINK; src_sockaddr.nl_pid = getpid(); src_sockaddr.nl_groups = 0; // 绑定socket和地址 bind(server_sock, (struct sockaddr *)\u0026amp; src_sockaddr, sizeof(struct sockaddr_nl)); 用户态：构建并发送消息 使用netlink通信时需要在消息头部指定通信目标，因此需要首先建立接受方的用户地址，也就是核心态的内核模块。然后依次设置netlink消息头和每一条信息的消息头。\n需要注意使用宏NLMSG_DATA获得netlink报文的实际数据地址。使用宏NLMSG_SPACE获得报文的实际数据大小。\n// 设置核心态用户地址，核心态的pid必须设置为0 dest_sockaddr.nl_family = AF_NETLINK; dest_sockaddr.nl_pid = 0; dest_sockaddr.nl_groups = 0; // 设置netlink socket的信息头部 nlh -\u0026gt; nlmsg_len = NLMSG_SPACE(sizeof(unsigned long)); nlh -\u0026gt; nlmsg_pid = getpid(); nlh -\u0026gt; nlmsg_flags = 0; // 设置iov 可以把多个信息通过一次系统调用发送 iov.iov_base = (void *)nlh; iov.iov_len = NLMSG_SPACE(sizeof(unsigned long)); // 设置接收地址 msg.msg_name = (void *)\u0026amp; dest_sockaddr; msg.msg_namelen = sizeof(struct sockaddr_nl); msg.msg_iov = \u0026amp; iov; msg.msg_iovlen = 1; // 填充消息内容 * (unsigned long *)NLMSG_DATA(nlh) = (unsigned long)0xffffffff \u0026lt;\u0026lt; 32; // 发送和接收消息 sendmsg(server_sock, \u0026amp; msg, 0); recvmsg(server_sock, \u0026amp; msg, 0); 内核态：相关变量 static struct sock* socket; static int pid = 0; static int ino_len = sizeof(unsigned long); static atomic_t sequence = ATOMIC_INIT(0); 内核态：初始化 在内核模块的编写中需要指定初始化函数，在初始化函数中创建内核态的netlink socket。由于使用异步通信，需要在内核态中定义接收回调函数，对于接收到的消息进行处理，内核态接收到的消息类型为sk_buff类型，可以转换为nlmsghdr结构并进一步提取信息。\nstatic void nl_receive_callback(struct sk_buff* skb){ // 转换格式 struct nlmsghdr* nlh = (struct nlmsghdr*)skb-\u0026gt;data; // 获得用户凭证 int pid = NETLINK_CREDS(skb)-\u0026gt;pid; } static int __init netlink_init(void) { // 设置接收到消息的回调函数 struct netlink_kernel_cfg cfg = { .input = nl_receive_callback, }; int i; // 创建内核态netlink套接字 socket = netlink_kernel_create(\u0026amp;init_net, NETLINK_SAFE, \u0026amp;cfg); return 0; } 内核态：资源回收 在内核模块的编写中需要指定出口函数，进行资源的回收。\nstatic void __exit netlink_exit(void) { if (socket) { netlink_kernel_release(socket); } } 内核态：构建和发送数据 // 内核态存储网络结构的数据为sk_buff // 首先创建 sk_buff空间， skb = nlmsg_new(msg_len, GFP_ATOMIC); if (!skb) { return 0; } // 设置netlink消息头部 nlh = nlmsg_put(skb, 0, 0, NLMSG_DONE, msg_len, 0); seq = atomic_inc_return(\u0026amp;sequence); nlh-\u0026gt;nlmsg_seq = seq; memcpy(NLMSG_DATA(nlh), msg_buf, meg_len) // 单播类型发送数据 // 用户态使用pid作为标识符 nlmsg_unicast(socket, skb, pid); 总结 在Linux内核编程的过程中，需要注意使用的API和数据结构大多与用户态不太相同，这个时候需要查看内核中的相关代码寻找线索。\n可以使用在线文档工具查看相关的函数定义。\n","date":1605251964,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605251964,"objectID":"9693d8192cb1c293d189df547e3dfeed","permalink":"https://yangleisx.github.io/post/netlink-socket/","publishdate":"2020-11-13T15:19:24+08:00","relpermalink":"/post/netlink-socket/","section":"post","summary":"最近接手了一个Linux下内核编程的项目，在阅读项目原有代码的基础上，学到了很多新知识，总结一下记录在这里。\n在这个项目中，编写内核模块进行操作，与用户态进程之间使用Netlink Socket进行通信。\n","tags":["C/C++","Linux","Socket"],"title":"Netlink Socket内核通信","type":"post"},{"authors":["Lei Yang"],"categories":["代码学习"],"content":"最近接手了一个Linux下内核编程的项目，在阅读项目原有代码的基础上，学到了很多新知识，总结一下记录在这里。\n在这个项目中，客户端进程和服务器进程在同一台机器上，使用Unix Domain Socket通信。\nsocket是为了网络通信设计的，但是Unix Domain Socket其实是一种进程间通信的机制，实现同一主机上的进程之间的通信，使用socket的方式相比消息、信号、共享内存等进程间通信方式更加的灵活可靠，同时其语法与socket通信基本相同，因此方便使用。\n整体上的代码结构与使用socket进行网络通信相似，唯一的区别在于需要为进程绑定socket文件。\n环境说明 操作系统：Ubuntu 18.10（使用Linux 4.18.0-25内核）\n基本数据结构 // 用于socket通信的通用地址类型 struct sockaddr { unsigned short sa_family; char sa_data[14]; }; // 用于Unix域通信的地址类型 struct sockaddr_un { uint8_t sun_len; sa_family_t sun_family; char sun_path[104]; } 基本操作模块 相关变量 int rc; int server_sock, client_sock; int sockaddr_len; struct sockaddr_un server_sockaddr; struct sockaddr_un client_sockaddr; sockaddr_len = sizeof(struct sockaddr_un); memset(\u0026amp; server_sockaddr, 0, sockaddr_len); memset(\u0026amp; client_sockaddr, 0, sockaddr_len); 创建socket 需要使用AF_UNIX指定socket类型为Unix Domain类型，建立面向连接的通信。\nserver_sock = socket(AF_UNIX, SOCK_STREAM, 0); if (server_sock == -1) { printf(\u0026#34;%s\\n\u0026#34;, \u0026#34;SOCKET ERROR\u0026#34;); exit(1); } 绑定socket文件 在Unix Domain Socket中，不使用IP地址+端口来表示地址，而是使用本地保存的socket文件表示地址，因此需要建立socket到地址的绑定。主要注意在服务器端和客户端都要建立到socket文件的绑定。\n#define SOCK_PATH \u0026#34;/tmp/server.socket\u0026#34; server_sockaddr.sun_family = AF_UNIX; strcpy(server_sockaddr.sun_path, SOCK_PATH); rc = bind(server_sock, (struct sockaddr *)\u0026amp; server_sockaddr, sockaddr_len); if (rc == -1) { printf(\u0026#34;%s\\n\u0026#34;, \u0026#34;BIND ERROR\u0026#34;); close(server_sock); exit(1); } 监听地址等待连接 使用listen将一个socket变为等待被动连接的socket，同时指定了等待队列的长度，从而建立起服务器端的socket。需要注意将socket文件放置于所有用户可见的位置并修改访问权限。\nchmod(SOCK_PATH, 0666); rc = listen(server_sock, 16); if (rc == -1) { printf(\u0026#34;%s\\n\u0026#34;, \u0026#34;LISTEN ERROR\u0026#34;); close(server_sock); exit(1); } 发送连接请求 在客户端，首先要获得服务器端socket地址，也就是socket文件的路径，将其写入Unix的socket地址中，直接发起连接请求。\n#define SERVER_PATH \u0026#34;/tmp/server.socket\u0026#34; server_sockaddr.sun_family = AF_UNIX; strcpy(server_sockaddr.sun_path, SERVER_PATH); rc = connect(client_sock, (struct sockaddr *)\u0026amp; server_sockaddr, sockaddr_len); if (rc == -1) { printf(\u0026#34;%s\\n\u0026#34;, \u0026#34;CONNECT ERROR\u0026#34;); close(client_sock); exit(1); } 接受连接请求 接受请求并建立到请求着的socket通信，将对方的地址保存下来。\nclient_sock = accept(server_sock, (struct sockaddr *)\u0026amp; client_sockaddr, \u0026amp; sockaddr_len); if (client_sock == -1) { close(client_sock); continue; } 接受数据 rc = recv(client_sock, \u0026amp; reqbuf, req_len, 0); if (rc == -1) { printf(\u0026#34;%s\\n\u0026#34;, \u0026#34;RECV ERROR\u0026#34;); close(client_sock); continue; } 发送数据 rc = send(client_sock, \u0026amp; reqbuf, req_len, 0); if (rc == -1) { printf(\u0026#34;%s\\n\u0026#34;, \u0026#34;SEND ERROR\u0026#34;); close(client_sock); exit(1); } 获得通信对象信息 通过getsockopt函数可以获得socket连接的属性，包括通信对象的相关信息，由于在同一主机的不同进程间通信，可以获得进程的身份凭证，包括了进程号、用户ID和组ID。\n/* Defined in Linux/socket.h struct ucred { __u32 pid; __u32 uid; __u32 gid; }; */ struct ucred cr; ucred_len = sizeof(struct ucred); # 使用SO_PEERCRED可以获得对方的身份凭证 # ucred结构体中包含了用户id和进程id if (getsockopt(client_sock, SOL_SOCKET, SO_PEERCRED, \u0026amp; cr, \u0026amp; ucred_len) == -1) { close(client_sock); continue; } 代码框架 服务器端 int server() { listenSocket = socket(); bind(); listen(listenSocket); while(1){ clientSocket = accept(); accept(); recv() or send(); closesocket(clientSocket); } closesocket(listenSocket); } 客户端 int client() { client_socket = socket(); bind(); connect(client_socket, server_sockaddr); recv() or send(); closesocket(clientSocket); } ","date":1605247355,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1605247355,"objectID":"f2942fb81f9f15b6e3da5fab084c85ed","permalink":"https://yangleisx.github.io/post/unix-socket/","publishdate":"2020-11-13T14:02:35+08:00","relpermalink":"/post/unix-socket/","section":"post","summary":"最近接手了一个Linux下内核编程的项目，在阅读项目原有代码的基础上，学到了很多新知识，总结一下记录在这里。\n在这个项目中，客户端进程和服务器进程在同一台机器上，使用Unix Domain Socket通信。\n","tags":["C/C++","Linux","Socket"],"title":"Unix Domain Socket通信","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文题目：Non-local Neural Networks\n作者：Xiaolong Wang, Ross Girshick, Abhinav Gupta, Kaiming He\n会议/时间：CVPR2018\n链接：https://arxiv.org/abs/1711.07971\n论文目标 当前的CNN或者RNN结构中的卷积等操作都是针对数据中的一个小区域（local neighborhood）处理和提取特征，并没有考虑到数据中的长期/远距离依赖关系。因此设计一个non-local操作，可以考虑到输入数据中的每一个位置上的特征和依赖关系，学习到全局信息。\n相关工作 在CNN中通过多次卷积扩大感受野，在RNN中通过设计迭代模型学习到序列中的远距离特征/信息，但是在实际的每一次处理过程中都只考虑到局部的信息。通过重复处理局部信息获得全局信息不仅计算效率低，而且引入了优化的困难。\n参考了传统的CV领域使用的non-local mean operation方法。其他相关的内容包括Graphical models、Feedforward modeling for sequences、self-attention、interaction networks、video classification architectures等。实际上self-attention可以看作是non-local的一种情况。\n本文思路/解决方案 通过考虑特征图中每一个位置的加权和来得到特定位置的响应。\n一方面可以直接学习到数据中远距离的信息，另一方面使用较浅层的网络也能实现比较好的结果，而且作者设计的non-local模块不改变数据的大小，可以方便的插在现有的网络中。\n简单来说，non-local的思路如下，其中$x_i$为输出位置，$x_j$为数据中的每一个点，使用$f(x_i,x_j)$计算两者之间的关系并作为权重计算输入数据特征$g(x)$的加权和。 $$ y_i = \\frac{1}{C(x)}\\sum\\limits_{\\forall j}f(x_i, x_j)g(x_j) $$ 在实际使用过程中，函数$f(\\cdot)$和$g(\\cdot)$有多种选择。后者常选用$1\\times1\\times1$的卷积实现。\nFunction Type Pairwise Function Gaussian $f(x_i,x_j) = e^{x_i^T x_j}$ Embedded Gaussian $f(x_i, x_j) =e^{\\theta(x_i)^T\\phi(x_j)}$ Dot product $f(x_i,x_j) = \\theta(x_i)^T\\phi(x_j)$ Concatenation $f(x_i, x_j) = ReLU(w_f^T[\\theta(x_i),\\phi(x_j)])$\n其中$[\\cdot, \\cdot]$表示连接得向量并经$w_f$变成标量 通过将non-local block定义为残差结构，使得模块输出的形状不发生变化，可以将non-local block插入到已有的预训练模型中，而不改变其性能（$W_z$初始化为0）。通过在较高的特征层加入该block，同时引入降采样，可以减小引入的计算量。 $$ z_i = W_z y_i + x_i $$\n结果 经过测试，添加了non-local block的模型具有更高的预测准确率，在non-local block中选择不同的函数计算数据之间的距离（即$f(x_i,x_j)$）对于最后的模型效果影响不大。而且在模型中添加了时空维度上的nonn-local block后效果相比单纯的时间或空间维度的效果更好。\n总结 提出了一种non-local的结构学习数据中距离比较远的特征的影响。并且实现了一种non-local block可以插入到现有的网络结构中并提升其性能。\n","date":1602396845,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602396845,"objectID":"cbcfa7d275d0f3e06a46c49d26138f3a","permalink":"https://yangleisx.github.io/post/paper-non-local/","publishdate":"2020-10-11T14:14:05+08:00","relpermalink":"/post/paper-non-local/","section":"post","summary":"论文题目：Non-local Neural Networks\n作者：Xiaolong Wang, Ross Girshick, Abhinav Gupta, Kaiming He\n会议/时间：CVPR2018\n链接：https://arxiv.org/abs/1711.07971\n","tags":["Deep Learning","Computer Vision"],"title":"【论文】Non-local Neural Networks","type":"post"},{"authors":["Lei Yang"],"categories":["基础知识"],"content":"说实话查了一些资料还不是很清楚，大概给出一个简单的理解。\nGNU Compiler Collection(GCC)是GNU推出的一套开源编译工具链。包括了make，sed，Emacs，glibc，gdb和gcc等工具，和Linux内核共同构成一套系统。支持C、C++、Obj-C、Fortran、Ada、Go等语言。\nClang/LLVM是一套编译工具链，受到Apple的支持。包括中间语言LLVMIR，调试器，LLVMC++标准库，静态分析工具等。近年来包括Swift、Rust等都在使用LLVM作为编译框架。Clang是Apple开发用来取代GCC的前端编译器，与LLVM兼容性更好。\nVisual C++是微软的一套编译工具链，在Linux平台的支持比较差。\nMinGW(Minimalist GNU for Windows)是一个工具集，在Windows上提供了GNU下的多种工具，包括了GCC等。编译得到的结果运行在Windows系统之上。\nCygwin是位于Windows系统下的POSIX环境。在Windows上提供了Unix\\Linux命令的执行支持环境。将Linux环境的程序迁移到Windows中，实际上通过dll文件在Windows系统中模拟了Linux的系统调用。\nOpenMP是跨平台的并行API，更适用于一台多核机器上的并行处理。通过在代码中添加pragma omp的指令使得编译器自动生成并行执行的代码。\nMPI(Message Passing Interface)是跨平台的并行API，适用于多个运算节点间的通信和并行处理。\nOpenACC是一个计算加速API，支持CPU/GPU结构，可以提供科学计算等各种加速功能。通过在代码中添加pragma acc的指令使得运算得到加速。\n参考资料： GCC和Clang/LLVM的比较\n","date":1601452563,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601452563,"objectID":"3fc2c5561533e146e0bf4275d45b14cc","permalink":"https://yangleisx.github.io/post/toolchain/","publishdate":"2020-09-30T15:56:03+08:00","relpermalink":"/post/toolchain/","section":"post","summary":"说实话查了一些资料还不是很清楚，大概给出一个简单的理解。\n","tags":["C/C++"],"title":"GNU、Clang/LLVM到底是些什么东西","type":"post"},{"authors":["Lei Yang"],"categories":["实用工具","基础知识"],"content":"简单了解了一下gdb的用法。 在已经了解lldb的基础上，再看gdb的用法就简单多了，大部分的操作都是基本一致的。\n编译部分 a. 使用-g选项编译支持调试 导入可执行文件 a. 在开启gdb时指定 b. 或者使用file指令导入 运行可执行文件 a. 使用run开始运行 b. 使用continue继续运行到下一个断点 c. 使用step运行一行（进入函数） d. 使用next运行一行 添加断点 a. 使用break file.c:6在指定文件的指定行添加断点 b. 使用break func在指定函数添加断点 c. 使用info breakpoints显示断点信息 d. 使用delete b_id删除指定断点 添加观察点 a. 观察点在变量值改变时中断程序并显示数据 b. watch var_name为指定变量添加观察点 查看数据 a. 使用print打印变量的值 b. 使用backtrace查看跟踪栈 条件断点： a. 仅在满足某些条件时触发 b. break main.c:6 if I \u0026gt;= ARRAYSIZE ","date":1601451874,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601451874,"objectID":"fd7155cfdb203dd34ae05a2082196baa","permalink":"https://yangleisx.github.io/post/gdb-base/","publishdate":"2020-09-30T15:44:34+08:00","relpermalink":"/post/gdb-base/","section":"post","summary":"简单了解了一下gdb的用法。 在已经了解lldb的基础上，再看gdb的用法就简单多了，大部分的操作都是基本一致的。\n","tags":["C/C++"],"title":"GDB简单用法","type":"post"},{"authors":["Lei Yang"],"categories":["实用工具","基础知识"],"content":"LLDB是一种C/C++程序的调试器工具，可以监控程序的变量值和堆栈的变化情况。在没有IDE情况下调试程序非常实用。网上找到的资料大多都是help信息的简单翻译，要想熟练使用还得经常练习。\n一次执行过程 测试代码 代码功能为获得C语言字符串的长度。\n#include \u0026lt;stdio.h\u0026gt; size_t strlen(const char *s) { const char *sc; for (sc = s; *sc != \u0026#39;\\0\u0026#39;; ++sc) {} return sc - s; } int main() { char str[] = \u0026#34;Hello World, I\u0026#39;m R2-D2.\u0026#34;; int length = strlen(str); printf(\u0026#34;The length of str is %d\\n\u0026#34;, length); return 0; } 编译过程 注意在编译过程中使用-g编译指令支持调试器的工作。\nCC = gcc CFLAGS = -g -std=c11 -Wall SOURCE = test.c OBJECT = $(SOURCE: .c=.o) main: $(OBJECT) $(CC) $(CFLAGS) $(OBJECT) -o $@ clear: rm *.o 基本流程 # 开启调试器 $ lldb main # 或者使用lldb开启调试器 使用file命令导入文件 # # 在指定文件指定行添加断点 (lldb) b test.c:11 # breakpoint set --file test.c --line 11 # breakpoint set -f test.c -l 11 # # 开始运行 (lldb) r # run # # 查看当前函数和调用关系 (lldb) bt # backtrace # # 查看本地变量(当前堆栈帧) (lldb) frame variable # # 步进和运行 (lldb) next (lldb) continue 常用的指令 断点操作 # 在指定文件指定行添加断点 (lldb) b test.c:11 # breakpoint set --file test.c --line 11 # breakpoint set -f test.c -l 11 # 为指定函数添加断点 (lldb) breakpoint set --name strlen # 查看断点 (lldb) breakpoint list # 设置断点命令 即触发断点时执行操作 1.1为断点编号 (lldb) breakpoint command add 1.1 启动和运行操作 # 开始运行 在断点停止 (lldb) r # run # 继续运行 下一个断点停止 (lldb) c # continue # 步进操作 运行下一行 (lldb) n # next # 进入当前行函数 (lldb) step 查看操作 # 查看跟踪栈 即函数调用关系 (lldb) bt # backtrace # 查看栈帧 即局部变量 (lldb) frame variable [variable_name] # 选择栈帧 9为栈帧标号 (lldb) frame select 9 线程操作 上述各种操作在多线程的环境中都可以对某一个线程进行操作\n(lldb) thread backtrace (lldb) thread list # 运行直到12行 (lldb) thread until 12 数据操作 # 修改程序中a的值 (lldb) exp a = 10 参考资料：\nLLDB TUTORIAL\nLLDB调试器的使用\nLLDB 十分钟快速教程\nLLDB使用\n","date":1601089976,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601089976,"objectID":"942de1b46d42f7aababfe7eb67ca802e","permalink":"https://yangleisx.github.io/post/lldb-base/","publishdate":"2020-09-26T11:12:56+08:00","relpermalink":"/post/lldb-base/","section":"post","summary":"LLDB是一种C/C++程序的调试器工具，可以监控程序的变量值和堆栈的变化情况。在没有IDE情况下调试程序非常实用。网上找到的资料大多都是help信息的简单翻译，要想熟练使用还得经常练习。\n","tags":["MacOS","C/C++"],"title":"LLDB的简单使用","type":"post"},{"authors":["Lei Yang"],"categories":["实用工具"],"content":"简单整理Windows安全课堂上讲解和提及的各种安全工具。\nCMD 命令 ver：查看内核版本。\nsysteminfo：查看系统信息，包括版本，补丁等大量信息。\nset：查看所有的环境变量。\nsc：查询服务信息。\nsc query [service name] 查询状态 sc qc [service name] 查询配置 sc start [service name] 启动需要手动启动的服务/驱动 sc stop [service name] 停止服务 sc showsid [service name] 查看服务的SID attrib：修改文件属性\n例如隐藏文件：添加hidden和system属性\n\u0026gt; attrib +h +s file-name whoami：显示域名和用户名（没有加入域时，显示主机名）。\nwhoami /user显示用户名和SID whoami /all显示详细信息（特权、权限、所属组等） whoami /all 显示详细的用户访问控制令牌信息 hostname：查看主机名称\nnet：用户和用户组操作\nnet user [username] 查看用户信息 net user [username] /add 添加新的用户 net user [username] [password] /add添加用户 net user [username] /del net localgroup [groupname] [username] /add 用户加入本地组 makecab：压缩工具\nwusa：补丁安装命令\nnetstat：查看网络连接信息，各种参数参见help信息\nreg：注册表管理工具\nreg save [hkey] [filename] 将注册表导出到文件中 cacls：查看客体的安全访问控制项ACE\n系统工具（cmd+R） regedit：（Registry Editer）注册表查看和编辑。 services.msc：服务控制面板（位于控制面板-系统和安全-管理工具-服务），查看和管理系统服务（只能看到用户态服务）。 secpol.msc：（Security Policy）本地安全策略配置。 syskey：SAM锁定工具，可以将密码存入本地或软盘。 msinfo32.exe：查看所有加载的驱动程序。 control：控制面板 eventvwr：（Event Viewer）审计日志查看器 certmgr.msc：（Certificate Manager）证书管理工具 其他工具 PE文件查看器：\nPE Explorer。 Stud_PE。 PEiD：可以看到加壳工具和编译工具。 DarkRemoteRAT：一个木马软件\nAgony：一个RootKit代码演示工具\nagony -p [进程名] 隐藏进程 agony -f [文件名] 隐藏文件/文件夹 SystInternalsSuite工具集：\nautoruns：查看自启动项（注册表，自启动目录，服务，计划程序等） procexp（process explorer）：查看进程信息（父子进程关系，进程加载的DLL和句柄列表，访问控制令牌，DEP，ASLR，完整性级别，虚拟化等，包括svchost内部的具体服务，进程的网络连接信息） tcpview：查看网络连接、端口、数据等 procmon（process monitor）：检查和记录进程的各种操作 PsGetSid：查看用户的SID（默认显示主机SID） psexec：运行程序 使用-s参数可以使用SYSTEM权限运行程序 使用-l参数可以使用Low完整性级别运行程序 procdump：进程内存导出工具 AccessChk：查看主客体对象的完整性级别 Strings：二进制代码的明文字符串查找 RootKit/BootKit检测工具\nXueTr（XT）：一个RootKit检测查看工具 PowerTool（PT）：可以检测到Bootkit和Rootkit IceSword：不再更新，经典 RootkitUnhooker（RKU） Kaspersky TDSSKiller：可以检测到Bootkit和Rootkit OSR Driver Loader：一个向系统加载驱动的工具。\nnc：一个常见的网络监控和通信工具。“网络的瑞士军刀”\nwireshark：一个开源的网络数据包分析软件。\n沙箱工具（用于动态分析）：\nSSM沙箱：System Safety Monitor，给系统函数加hook Cuckoo：开源的沙箱，使用最多 Anubis沙箱 Norman沙箱 GFI沙箱 OllyDbg：一个常见的动态分析调试工具。\n静态分析工具：\nIDA Pro：高级分析工具 Depends：查看链接库，导入导出表 Dependancy Walker 明文字符串查找：\nBinText：查看明文字符串，包括函数名等 Strings 加壳识别和脱壳：\nVMUnpacker UPX：可以加壳和脱壳 UnPEPack ASPack unpacker 文件格式识别：\nPEid：检查是否加壳，检测编译工具 FileAnalyzer 反病毒引擎扫描：\nVirusScan VirusTool mimikatz：一个获得登陆用户明文密码的工具\nwinhex：二进制读写工具，直接操纵硬盘而不是使用WinAPI\nSAMINside：SAM文件解析和读取工具\n本地密码破解工具：\nL0phtCrack SAMInside Ophcrack Windows本地密码散列导出工具：\nPwdump wce：Windows密码凭证编辑器 gsecdump copypwd QuarksPwDump 提取登录用户明文密码：\nwce：Windows密码凭证编辑器 mimikatz 数据恢复工具：\nEasyRecovery FinalData 参考Github项目 UACME LOLBAS BypassAntiVirus ","date":1593075651,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593075651,"objectID":"01e9a86a4cbb2cba46f217bdfa7d53e5","permalink":"https://yangleisx.github.io/post/win-sec-tool/","publishdate":"2020-06-25T17:00:51+08:00","relpermalink":"/post/win-sec-tool/","section":"post","summary":"简单整理Windows安全课堂上讲解和提及的各种安全工具。\n","tags":["Windows"],"title":"Windows安全管理工具总结","type":"post"},{"authors":["Lei Yang"],"categories":["代码学习"],"content":"刚开始使用Windows提供的各种API函数时，对于函数参数的类型感到非常的迷惑，实际上Windows中对于各种C++数据类型做了封装和处理，得到了一组Windows的变量类型，其中的部分字符和字符串的定义如下。\n其他的类型定义可以在具体使用时搜索查看头文件（例如#include \u0026lt;Windows.h\u0026gt;）或者MSDN。\n字符和字符串类型 变量类型 解释 定义 CHAR ANSI型字符 char WCHAT Unicode型字符 wchar_t TCHAR 自适应字符（ANSI or Unicode） 可变 LPSTR/PSTR ANSI型字符串 char* LPWSTR/PWSTR Unicode型字符串 wchar_t* LPTSTR/PTSTR 自适应字符串（ANSI or Unicode） 可变 LPCSTR/PCSTR 常量ANSI型字符串 const char* LPCWSTR/PCWSTR 常量Unicode型字符串 const wchar_t* LPCTSTR/PCTSTR 常量自适应字符串 可变 其中的前缀LP/P，可以理解为表示指针Pointer（字符串变量为字符数组的首地址指针）。\n字符串函数 绝大多数操作字符串的函数都提供了A和W两种，例如RegOpenExA()和RegOpenExW()，同时提供了自适应的版本RegOpenEx()，A为后缀的函数参数通常为ANSI型，W为后缀的函数参数通常为Unicode型，无后缀的函数使用自适应定义。\n#ifdef UNICODE #define TCHAR Wchar_t #else #define TCHAR char #endif #ifdef UNICODE #define RegOpenEx RegOpenExW #else #define RegOpenEx RegOpenExA #endif 参考MSDN\n","date":1591847254,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591847254,"objectID":"2bc1a42c1b048041b9709272496d3b19","permalink":"https://yangleisx.github.io/post/win-api-type/","publishdate":"2020-06-11T11:47:34+08:00","relpermalink":"/post/win-api-type/","section":"post","summary":"刚开始使用Windows提供的各种API函数时，对于函数参数的类型感到非常的迷惑，实际上Windows中对于各种C++数据类型做了封装和处理，得到了一组Windows的变量类型，其中的部分字符和字符串的定义如下。\n其他的类型定义可以在具体使用时搜索查看头文件（例如#include \u003cWindows.h\u003e）或者MSDN。\n","tags":["Windows","WinAPI","C/C++"],"title":"WinAPI的数据类型(字符串)","type":"post"},{"authors":["Lei Yang"],"categories":["代码学习"],"content":"Winsock就是windows下的socket编程的简称，函数用法与BSD的socket（即unix中的socket）编程基本相同。\n所有的代码实现位于我的Github。\n重要：所有的函数使用、讲解和实例请参考Winsock文档 via Microsoft。\n环境 使用VS开发，需要使用的头文件和库文件如下\n// 头文件 #include \u0026lt;winsock2.h\u0026gt; #include \u0026lt;ws2tcpip.h\u0026gt; // 静态库 #pragma comment (lib, \u0026#34;Ws2_32.lib\u0026#34;) #pragma comment (lib, \u0026#34;Mswsock.lib\u0026#34;) #pragma comment (lib, \u0026#34;AdvApi32.lib\u0026#34;) 基本数据结构 使用比较多的数据结构包括sockaddr，addrinfo等，定义如下。\nstruct sockaddr { ushort sa_family; char sa_data[14]; }; struct sockaddr_in { short sin_family; u_short sin_port; struct in_addr sin_addr; char sin_zero[8]; }; typedef struct addrinfo { int ai_flags; int ai_family; int ai_socktype; int ai_protocol; size_t ai_addrlen; char *ai_canonname; struct sockaddr *ai_addr; struct addrinfo *ai_next; } ADDRINFOA, *PADDRINFOA; 这里的sockaddr_in为IP协议的地址结构体，sockaddr为所有网络层协议的地址结构体，可以保存所有网络层协议的地址数据。当使用IP协议栈时使用sockaddr_in结构体，winsock的函数大多使用sockaddr作为函数参数，从而实现更好的兼容性。（winsock还实现了sockaddr_storage，地址空间更大，兼容性更好）。\n基本函数模块 由于Winsock有完备的错误代码提示，因此养成在每一步操作之后都要检查错误代码的习惯。这里添加一个全局的函数返回值（错误代码）变量用于检测操作是否完成。\nint iResult = 0; Winsock初始化：WSAStartup() Winsock在socket各种函数的基础上实现了一套WSA函数（WinSockApplication），需要在程序前部初始化。\nWORD wVersion = MAKEWORD(2, 2); WSADATA wsaDATA; // initialize winsock iResult = WSAStartup(wVersion, \u0026amp;wsaDATA); if (0 != iResult) { printf(\u0026#34;WSAStartup failed: %d\\n\u0026#34;, iResult); return -1; } Winsock清理： WSACleanup() Winsock在程序推出之前需要使用WSACleanup()函数完成收尾工作，通常位于main函数的return之前。\n获得本地主机名：gethostname() 可以获得本地的主机名\nchar hostname[NI_MAXHOST]; int hostlen = NI_MAXHOST; // 获得本地主机名 gethostname(hostname, hostlen); 获得地址信息：getaddrinfo() 给定主机名和端口号，可以解析得到目标主机的网络地址（例如IP地址），类似ARP协议的作用。需要使用hints传入参数。\n其中第一个参数为NULL时为获得本地主机信息。\n当目标主机存在多个网卡/IP地址时，得到的result为一个链表，使用result-\u0026gt;ai_next连接。\nchar hostname[NI_MAXHOST] = “localhost”; char servname[NI_MAXSERV] = “8080”; struct addrinfo *result = NULL; struct addrinfo hints; // 初始化 ZeroMemory(\u0026amp;hints, sizeof(hints)); hints.ai_family = AF_UNSPEC; hints.ai_socktype = SOCK_STREAM; hints.ai_protocol = IPPROTO_TCP; // 解析地址 iResult = getaddrinfo(hostname, servname, \u0026amp;hints, \u0026amp;result); if (0 != iResult) { printf(\u0026#34;getaddrinfo failed: %d\\n\u0026#34;, iResult); WSACleanup(); return -1; } 获得主机名信息: getnameinfo() 给定目标主机的网络地址，可以解析得到主机名和端口号，类似RARP协议的作用。\nchar hostname[NI_MAXHOST]; char servname[NI_MAXSERV]; struct sockaddr_in sa; int addrlen = sizeof(struct sockaddr); u_short port = 8080; const char* localhost = \u0026#34;127.0.0.1\u0026#34;; // 初始化 inet_pton(AF_INET, localhost, \u0026amp;sa.sin_addr.s_addr); sa.sin_family = AF_INET; sa.sin_port = htons(port); // 获得主机名信息 iResult = getnameinfo( (struct sockaddr*) \u0026amp;sa, addrlen, hostname, NI_MAXHOST, servname, NI_MAXSERV, 0); if (0 != iResult) { printf(\u0026#34;getnameinfo failed: %d\\n\u0026#34;, WSAGetLastError()); WSACleanup(); return -1; } 清空地址信息: freeaddrinfo() 使用getaddrinfo得到的地址消息不再使用时，建议显式清空。\nstruct addrinfo *result; // 非空的地址信息指针 freeaddrinfo(result); 地址信息可视化 想要以可读方式显示地址信息，涉及到大端/小端的转换、二进制和点分十进制的转换等处理。\nstruct addrinfo *result; // 非空的地址信息指针 struct sockaddr_in server_addr; char ipstringbuffer[46]; short port; // 转换地址格式 memcpy(\u0026amp;server_addr, result-\u0026gt;ai_addr, sizeof(server_addr)); inet_ntop(AF_INET, \u0026amp;server_addr.sin_addr, ipstringbuffer, sizeof(ipstringbuffer)); port = ntohs(server_addr.sin_port); // 显示地址信息 printf(\u0026#34;Server Address: %s\\n\u0026#34;, ipstringbuffer); printf(\u0026#34;Server Port Number: %d\\n\u0026#34;, port); 创建套接字: socket() socket编程中核心的部分为套接字socket，创建socket的进程才可以实现不同主机上的进程间通信。\nSOCKET s = INVALID_SOCKET; // 创建套接字 s = socket(AF_INET, SOCK_STREAM, IPPROTO_TCP); if (ConnectSocket == INVALID_SOCKET) { printf(\u0026#34;socket failed : %d\\n\u0026#34;, WSAGetLastError()); WSACleanup(); return -1; } 关闭套接字: closesocket() 套接字使用完毕后，建议手动关闭套接字。\nSOCKET s; // 合法套接字 // 关闭套接字 closesocket(s); 绑定套接字: bind() 在服务器端创建的套接字需要绑定，即建立socket和地址之间的联系。相当于内部地址（进程描述符、套接字描述符）和外部地址（网络地址、端口号）之间建立连接。\nSOCKET s; // 合法的套接字 struct addrinfo local; // 绑定套接字 iResult = bind(s, local-\u0026gt;ai_addr, (int)local-\u0026gt;ai_addrlen); if (iResult == SOCKET_ERROR) { printf(\u0026#34;bind failed: %d\\n\u0026#34;, WSAGetLastError()); freeaddrinfo(local); closesocket(s); WSACleanup(); return 1; } 监听端口: listen() 在服务器端绑定后的套接字可以监听端口，用于连接型的数据传输。类似TCP连接中等待SYN报文。\nSOCKET s; // 合法的套接字 // 监听端口（套接字） iResult = listen(s, SOMAXCONN); if (iResult == SOCKET_ERROR) { printf(\u0026#34;listen failed: %d\\n\u0026#34;, WSAGetLastError()); closesocket(s); WSACleanup(); return 1; } 接受连接请求: accpet() 当服务器端接收到连接请求时（请求队列不为空），接受连接请求并创建连接。类似TCP连接中发送SYN ACK报文。此时创建了用于传输的套接字，与监听套接字分离。\nSOCKET ListenSocket; // 合法的套接字 SOCKET ComSocket = INVALID_SOCKET; struct sockaddr_in client_addr; int addr_len = sizeof(struct sockaddr_in); // 接受连接请求 ComSocket = accept(ListenSocket, (struct sockaddr*)\u0026amp;client_addr, \u0026amp;addr_len); if (ComSocket == INVALID_SOCKET) { printf(\u0026#34;accept failed: %d\\n\u0026#34;, WSAGetLastError()); closesocket(ListenSocket); WSACleanup(); return 1; } 请求连接: connect() 客户端需要向服务器发送链接请求时，使用connect函数。类似TCP连接中发送SYN报文。\nSOCKET s; // 合法套接字 struct addrinfo remote; // 发送连接请求 iResult = connect(s, remote-\u0026gt;ai_addr, (int)remote-\u0026gt;ai_addrlen); if (iResult == SOCKET_ERROR) { printf(\u0026#34;connect failed: %d\\n\u0026#34;, WSAGetLastError()); closesocket(s); s = INVALID_SOCKET; } 关闭连接: shutdown() 通信结束时，不可以直接关闭socket，应该首先关闭连接（关闭发送方向的连接，表示不再发送消息）。类 …","date":1589342192,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589342192,"objectID":"b0ecb995fd75118c4b7d09b3d483e896","permalink":"https://yangleisx.github.io/post/winsock/","publishdate":"2020-05-13T11:56:32+08:00","relpermalink":"/post/winsock/","section":"post","summary":"Winsock就是windows下的socket编程的简称，函数用法与BSD的socket（即unix中的socket）编程基本相同。\n所有的代码实现位于我的Github。\n重要：所有的函数使用、讲解和实例请参考Winsock文档 via Microsoft。\n","tags":["Winsock","Socket"],"title":"Winsock编程记录","type":"post"},{"authors":["Lei Yang"],"categories":["实用工具"],"content":"简单记录SSH的用法\nSSH登陆 首次登录时发送服务器公钥的fingerprint，要求用户确认。\n用户确认后公钥保存到known_hosts，默认可信。\n密钥登陆：ssh -p [port] -i [id_file] [user]@[ip_address]\n公钥登陆：客户端ssh-keygen生成密钥对，ssh-copy-id传输公钥到服务器(自动写入authorized_keys)。\n$ ssh-keygen -t rsa # 生成SSH公私钥对 # -t 使用rsa算法 [dsa|ecdsa|ed25519|rsa] $ ssh-copy-id -i ~/.ssh/id_rsa.pub auth@192.168.1.10 # 将公钥传输到SSH服务器 # -i 指定公钥文件 # user@address 指定SSH服务器的IP地址和公钥对应的用户 # 需要使用口令方式通过认证 私钥登陆：服务器ssh-keygen生成密钥对，将公钥追加到服务器authorized_keys，通过scp或其他安全方式传输私钥到客户端。\nssh-copy-id的替代方式:\nLinux机器：\nssh \u0026lt;user\u0026gt;@\u0026lt;ip_address\u0026gt; \u0026#34;cat \u0026gt;\u0026gt; authorized_keys\u0026#34; \u0026lt; id.pub Windows机器：\n\u0026gt; Get-Content new.pub | ssh \u0026lt;user\u0026gt;@\u0026lt;ip_address\u0026gt; \u0026#34;cat \u0026gt;\u0026gt; authorized_keys\u0026#34; 权限：通常公钥权限644，私钥权限600。authorized_keys权限600，known_hosts权限644。\n服务器端私钥权限为640、644之后，SSH服务器会自动忽略对应密钥对（认为该私钥是不安全的）。\nauthorized_keys权限改为620、622之后，SSH服务器会拒绝读取（认为公钥不安全），只能口令登陆。\n文件：\nauthorized_keys在服务器端保存客户端的公钥。用于密钥登陆时加密随机挑战。防止冒用。\nknown_hosts在客户端保存服务器的公钥。用于公钥的比较确认，口令登录时用公钥加密口令。\nscp：基于SSH的加密文件传输，使用单行命令传输文件。\nsftp：基于SSH的加密文件传输，类似FTP的操作和使用方式。\nSSH连接 信息交换 TCP连接：三次握手建立TCP连接。发送SYN，接收SYN ACK，发送ACK。\n版本协商：双方交换SSH版本。\n算法协商：包括公钥算法，加密算法，MAC（消息验证码）算法，压缩算法列表\n密钥协商：Elliptic Curve Diffie-Hellman Key Exchange\n客户端发送ECDH Key Exchange Init报文。包括客户端交换密钥Q_C。\n服务器发送ECDH Key Exchange Replay报文。包括ECDSA服务器公钥Q和ECDH交换密钥Q_S。\n接下来通过发送New Keys报文表示交换密钥已经建立。\n登陆认证：（传输过程使用交换密钥对称加密）\n口令认证过程：服务器发送公钥。客户端使用服务器公钥加密口令。服务器使用私钥解密验证。\n密钥认证过程：服务器使用客户公钥加密发送随机字符串。客户端使用客户私钥加密。\n防御中间人攻击 中间人拦截客户端的连接请求并发送自己的公钥，从而假冒服务器窃取用户信息。\n客户端首次连接时保存服务器的公钥。中间人攻击时，中间人发送的服务器公钥与保存的公钥不同。 SSH引入了公钥认证机制，通过安全的方式发送公钥保存在服务器的authorized_keys中。 端口转发 socks代理 要求机器A配置socks代理、机器B做代理服务器、访问web服务。\n# 机器A ssh -f -N -D 127.0.0.1:1080 \u0026lt;user\u0026gt;@\u0026lt;addressB\u0026gt; 机器A浏览器设置代理为127.0.0.1:1080即可通过机器B访问网页。\n远程转发 要求机器A访问本地端口、机器B做代理服务器、访问目标网站。\n# 机器A ssh -f -N -R 3456:bbs.fudan.edu.cn:23 \u0026lt;user\u0026gt;@\u0026lt;addressB\u0026gt; 机器A访问localhost:3456会经由机器B访问复旦BBS。\n本地转发 要求机器A访问本地端口、机器B开启web服务并做代理。\n# 机器A ssh -f -N -L 3456:lohalhost:80 \u0026lt;user\u0026gt;@\u0026lt;addressB\u0026gt; 机器A访问localhost:3456实际访问到addressB:80。\nSSH设置 设置规则之后重启服务\nsystemctl restart ssh # 或者使用 service 禁止使用密码登录\n# /etc/ssh/ssgd_config PasswordAuthentication no 拒绝用户登录\n# /etc/ssh/sshd_config DenyUsers user1 设置用户白名单\n# /etc/ssh/sshd_config # 按优先级从高到低 # 指定禁止某用户登录 DenyUsers \u0026lt;user\u0026gt; # 指定仅限某用户登录 AllowUsers \u0026lt;user\u0026gt; # 指定禁止某用户组登录 DenyGroup \u0026lt;group\u0026gt; # 指定仅限某用户组登录 AllowGroup \u0026lt;group\u0026gt; 设置IP白名单\n# 按优先级从高到低 # /etc/hosts.allow sshd:192.168.198.1:allow # /etc/hosts.deny sshd:ALL 禁止登陆root用户，如果使用弱口令的话可能被爆破\n# /etc/ssh/sshd_config PermitRootLogin no 禁止无密码的登录\n# /etc/ssh/sshd_config PermitEmptyPasswords no 更改端口\n# /etc/ssh/sshd_config Port 40121 ","date":1588919251,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588919251,"objectID":"2a9a4ca9e5b7b3d6e6bbc3e3e8d7c4b3","permalink":"https://yangleisx.github.io/post/ssh/","publishdate":"2020-05-08T14:27:31+08:00","relpermalink":"/post/ssh/","section":"post","summary":"简单记录SSH的用法\n","tags":["SSH"],"title":"SSH使用简单记录","type":"post"},{"authors":["Lei Yang"],"categories":["开发经历"],"content":"背景 分别由两个人开发的代码需要被整合进入一个完整的项目并运行。\n其中第一位同学使用Visual Studio开发基于C++和openSSL的加解密的程序，使用vcpkg安装和编译openSSL:x86-windows并且集成到Visual Studio中。另一位同学使用Qt Creator开发基于C++和Qt的GUI程序。\nIDE选择 由于需要将两份代码合成一个完整的项目运行，我首先选择IDE为Visual Studio，但是由于并没有在VS中写过Qt程序，添加的QT VS TOOL插件总是无法正常编译。因此放弃使用Visual Studio作为项目IDE。选择Qt Creator作为开发环境。\n编译 遇到的第一个问题是将openSSL集成到Qt Creator，从网上找到的资料都是从OpenSSL官网下载，并在Qt项目文件中添加库和头文件路径。如下代码所示\nLIBS += \\ -Lpath/lib -lssl \\ -Lpath/lib -lcrypto INCLUDEPATH += path/include 我遇到的问题是，添加头文件正常，但是在编译的时候会出现undefined reference to xxx的报错，仔细一看是openssl库中的函数，在代码中follow symbols可以跳转到头文件中对应的定义，因此猜测是头文件正常但库文件没有正常加载。\n这里涉及到的我尝试过的库文件包括\nlibssl.lib libcrypto.lib libssl.a libcrypto.a libssl.dll.a libcrypto.dll.a libssl-1_1.dll libcrypto-1_1.dll libeay32.dll ssleay32.dll ... 于是开始各种下载和添加库文件。包括但不限于\n使用vcpkg编译x64-windows版本的openssl库并添加（考虑到32位和64位可能产生的冲突） 官网下载openssl安装包（由于下载速度太慢，我选择了64位light版本的安装包，但是light版本安装包没有lib文件，完整版本的安装包就不曾下载成功过） 将lib和include文件copy到项目目录下，再使用上述方法添加路径。 在这个时候，我查到一篇文章说qt本身是包括openssl的但是在编译的时候默认不安装，因此qt的环境下实际上是包括openssl对应的库文件和头文件的。经过一番查找我找到这个路径C:\\Qt\\Qt5.12.0\\Tools\\mingw730_64\\opt。\n这个路径的lib目录下包括了libssl.a、libcrypto.a、libssl.dll.a、libcrypto.dll.a，bin目录下包括libeay32.dll、ssleay32.dll，include目录下包括openssl头文件目录。因此我修改.pro文件如下。\n# 这里的$$quote我也没搞清啥意思，大概是双引号 LIBS += \\ -LC:\\Qt\\Qt5.12.0\\Tools\\mingw730_64\\opt\\lib -lssl \\ -LC:\\Qt\\Qt5.12.0\\Tools\\mingw730_64\\opt\\lib -lcrypto INCLUDEPATH += \\ $$quote(C:\\Qt\\Qt5.12.0\\Tools\\mingw730_64\\opt\\include) 经过多次编译，并注释掉一些无用的函数，终于实现了0 warnigns, 0 errors，呜呼。\n运行 接下来遇到的问题是，程序无法运行。在Qt Creator中直接运行，程序闪退并显示程序异常结束。在Qt Creator中开启Debugger，同样也是闪退，添加的断点直接被无视了。\n刚开始考虑到可能是被杀毒软件杀掉了，因此经过一番操作关闭了Windows Defender，但是仍然无法运行，陷入停滞。\n这个时候查到一篇文章，详细介绍了Qt Creator中的闪退的原因并给出了一个检查的方法，就是找到编译生成的exe文件，直接双击运行。程序自然无法运行并提示缺少许多dll文件，其中包括qt的依赖库例如QtCore.dll等等，因此使用windeployqt.exe(位于C:\\Qt\\Qt5.12.0\\5.12.0\\mingw73_64\\bin)将Qt所有的依赖dll复制到exe对应的路径下，这个时候再次点击exe文件，显示缺少libeay32.dll于是将上述的libeay32.dll和ssleay32.dll（位于C:\\Qt\\Qt5.12.0\\Tools\\mingw730_64\\opt\\bin）复制到这个路径下。\n双击exe，正常运行！！！经过测试，一切正常。每次使用qt编译后，将得到的exe文件拷贝到一个新的路径下，调用windeployqt和复制dll就可以正常运行。\n总结反思 我使用Qt官网下载的安装包安装Qt时，IDE选择了QtCreator，编译环境我选择了MinGW和MSVC，因此在我的安装目录下（C:\\Qt\\Qt5.12.0\\5.12.0）包括了如下四个编译环境，每一个环境中都包含了windeployqt等一系列exe文件，和完整的Qt编译环境（bin + lib + include）。\nmingw73_64\nmsvc2015_64\nmsvc2017\nmsvc2017_64\n但是非常疑惑的一点是，在编译时我检查Qt Cretor的编译输出窗口，发现我编译使用的是Tools目录下的mingw730_64。进一步检查发现Tools目录下（C:\\Qt\\Qt5.12.0\\Tools）包括如下目录。\nmingw730_64\nQtCreator\n前者不是一个完整的Qt编译环境，不包括qt的各种dll，而是包括了ar、ld、gcc、make、objdump等一系列工具，更像是一个编译环境。其opt目录下包括了openssl的编译环境（前文使用到的）。\n那么这两个不同的mingw环境究竟有什么区别呢？后者可不可以换成我之前自己手动安装的MinGW环境呢？\n使用vcpkg编译得到的环境和使用官方安装包以及从GitHub直接下载手动编译的环境有什么区别。\n对于库文件来说存不存在32位和64位的差异，如果不存在的话，那么vcpkg编译时为什么提供了x86-windows和x64-windows的不同的triplets（还包括了arm、linux等其他选择）。\n函数静态库和动态库在使用时一定要同时存在么，即编译时指定lib文件，执行时exe文件路径中要包含对应的dll文件。\nvcpkg编译得到的libssl.lib和mingw730_64的opt路径下的libssl.a文件有什么差异，能不能简单通过改变后缀名来实现适配。同理还有.dll文件和.so文件之间的关系。\n最后的最后，还是感觉任重而道远。上述问题大多都是操作系统和C语言编译的基础知识，还是要努力打好基础。\n","date":1587432404,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587432404,"objectID":"e9b5f547f18a39fadf6db1183c5589c5","permalink":"https://yangleisx.github.io/post/log-qt-ssl/","publishdate":"2020-04-21T09:26:44+08:00","relpermalink":"/post/log-qt-ssl/","section":"post","summary":"背景 分别由两个人开发的代码需要被整合进入一个完整的项目并运行。\n","tags":["Qt","OpenSSL"],"title":"Qt开发OpenSSL程序踩坑","type":"post"},{"authors":[],"categories":["实用工具"],"content":"使用qt编写的GUI程序部署和发布流程。\nPython\u0026amp;PyQt程序部署 使用pyinstaller工具打包部署使用pyqt编写的GUI程序。（适用于Windows和macOS）\n# 使用pip安装pyinstaller工具 $ pip install pyinstaller $ pyinstaller -F -w --noconfirm --icon myicno.ico mainwindow.py # 其中： # -F 表示打包为一个单独的exe文件 # -w 表示exe文件运行时隐藏cmd窗口(黑框) # --icon 表示指定图标 # --noconfirm 表示覆盖原有文件时不询问 运行结束后，在当前目录下会生成两个文件夹build和dist。前者存放编译生成的一些中间文件，后者为distribution的简称，存放打包结束的文件。\n使用-F生成的是单个exe文件，但是文件非常大。不添加-F选项得到的文件夹中包括程序主文件和大量依赖的dll文件。\n不添加-w选项时，上述生成的文件运行时会出现一个cmd窗口，显示程序中的qDebug()信息。因此在最后的发布版本中建议加上-w选项，并注释掉qDebug信息。\n当build和dist文件夹存在时，pyinstaller写入文件时会询问时候覆盖原有的文件，使用–noconfirm表示直接覆盖，不询问用户。\nC++\u0026amp;QT程序部署 使用QT自带的windeployqt.exe工具。通常位于QT的安装路径的/bin下。\n# 将Qt Creator编译生成的release文件夹下的内容复制到一个新的文件夹 # 此时直接点击mainwindow.exe运行失败，因为缺少一些依赖的dll文件 $ windeployqt.exe mainwindow.exe 运行结束后，这个文件夹下包含程序主文件和依赖的dll文件。\n程序发布 可以使用Inno Setup工具将上述部署得到的包含dll和exe的文件夹打包成一个安装包发布。\n可以填写程序名称、版本号、网址、LICENSE文件、README文件、安装包图标，并选择程序主exe文件、选择程序依赖文件夹，Inno Setup工具就会将所有需要的文件打包为一个setup.exe安装包。\n用户可以点击该安装包将文件安装到系统目录(例如C:\\ProgramFiles)中并创建桌面和开始菜单图标。\n","date":1587023981,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587023981,"objectID":"50d283ce89f96c524273f1302e637b9b","permalink":"https://yangleisx.github.io/post/qt-deploy/","publishdate":"2020-04-16T15:59:41+08:00","relpermalink":"/post/qt-deploy/","section":"post","summary":"使用qt编写的GUI程序部署和发布流程。\n","tags":["Qt"],"title":"QT程序打包部署","type":"post"},{"authors":["Lei Yang"],"categories":["基础知识"],"content":"相关概念：SSL、TLS、证书。\nSSL或TLS运行在传输层和应用层之间。（早期称为SSL，后期称为TLS）。用户网络加密通讯。\nHTTPS可以看作HTTP+TLS，包括两个部分：握手协议+记录协议。\n链接流程（握手协议）主要流程：\n客户端HELLO（发送支持的TLS版本） 服务器HELLO（选择TLS版本，发送服务器证书） 客户端检查证书，生成主密钥（随机数）并使用服务器证书加密 服务器解密后对主密钥加密并发回（类似Diffie Hellman交换） 客户端验证主密钥，使用主密钥得到交换密钥用于非对称加密 服务器验证客户端（可选） 主要概念：使用服务器的公钥加密一个信息，服务器使用公钥解密后将该信息以客户端公钥加密后发回。用户客户端和服务器之间的验证。\n记录协议中将应用层数据分段、压缩、添加下层首部（HTTP）、对称加密、添加TLS头部并发送。\n证书包括公钥内容和私钥拥有者的信息。属于可信第三方（公钥基础设施PKI），用于证明公钥内容正确性。\n通常由CA机构使用自己的私钥为服务器的证书请求添加数字签名。拿到证书以后，客户端通过使用CA的公钥解密得到证书内部的服务器公钥。CA使用层次签名，顶级CA的证书使用自签名，其公钥在全网公开。\n","date":1586853245,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586853245,"objectID":"02972ebd0e8d8b1653318352a66ab596","permalink":"https://yangleisx.github.io/post/https/","publishdate":"2020-04-14T16:34:05+08:00","relpermalink":"/post/https/","section":"post","summary":"相关概念：SSL、TLS、证书。\n","tags":["HTTPS"],"title":"HTTPS初步理解","type":"post"},{"authors":["Lei Yang"],"categories":["实用工具"],"content":"openssl的功能主要包括对称加解密、计算哈希（信息摘要）和发布证书。\n加解密 openssl enc -e -aes-128-cbc -in main.c -out main.enc openssl enc -d -aes-128-cbc -in main.enc -out main_out.c 计算摘要 $ openssl dgst -sha1 main.c SHA1(main.c)= cc9bf223848c972e66968fb3846fc7f85721796e $ echo \u0026#34;\\n\u0026#34; \u0026gt;\u0026gt; main.c $ openssl dgst -sha1 main.c SHA1(main.c)= 52019cdc4aea16ee68f4d881465f6b8f03cf1836 自建CA并签发\u0026amp;撤销证书 更改文件目录设置 # CA目录 dir=/home/yanglei/Workspace/ssl # 证书目录 certs=$dir/certs # 证书备份目录 new_certs_dir=$dir/newcerts # CA证书 certificate=$dir/cacert.pem # CA数据库 database=$dir/CA/index.txt # CA序列号 serial=$dir/CA/serial # 吊销证书目录 crl_dir=$dir/crl # 吊销证书编号 crlnumber=$dir/crlnumber crl=$dir/crl.pem # CA私钥目录 privatekey=$dir/private/cakey.pem 创建文件夹certs、newcerts、CA、private、crl\n创建文件crlnumber（注意写入echo 01 \u0026gt; crlnumber）\n创建文件CA/index.txt、CA/serial（注意写入echo 01 \u0026gt; serial）\n创建随机数private/.rand\n证书字段 Country Name（C）国家\nState or Province Name（S）省\nLocatily Name（L）市\nOrganization Name（O）组织名\nOrganization Unit Name（OU）补充\nCommon Name（CN）通常为域名/网址\nEmail Address\n生成自签名证书 # /home/yanglei/Workspace/ssl $ openssl genrsa -out private/cakey.pem 1024 $ openssl req -new -x509 -key private/cakey.pem -out cacert.pem -days 3650 # 或者先生成请求再签名 $ openssl req -new -key xxx.pem -out xxx.csr $ openssl x509 -req -in xxx.csr -signkey cakey.pem -out xxx.crt 签发证书 # /home/yanglei/Workspace/testssl $ openssl genrsa -out user1.pem 1024 $ openssl rsa -in user1.pem -out user1.pub -pubout $ openssl req -new -key user1.pem -out user1.csr -days 365 # /home/yanglei/Workspace/ssl $ openssl ca -in ../testssl/user1.csr -out certs/user1.crt -days 365 $ openssl x509 -in certs/user1.crt -noout -text 撤销证书 # 吊销证书 $ openssl ca -revoke newcerts/01.pem # 发布吊销列表 $ openssl ca -gencrl -out crl/ca.crl # 查看吊销列表 $ openssl crl -in crl/ca.crl -noout -text ","date":1586852958,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586852958,"objectID":"5bbfa1e5544af995558f7786811ef91f","permalink":"https://yangleisx.github.io/post/bash-openssl/","publishdate":"2020-04-14T16:29:18+08:00","relpermalink":"/post/bash-openssl/","section":"post","summary":"openssl的功能主要包括对称加解密、计算哈希（信息摘要）和发布证书。\n","tags":["OpenSSL"],"title":"OpenSSL使用记录","type":"post"},{"authors":["Lei Yang"],"categories":["基础知识"],"content":"由于课程需要，进一步学习了一下make的使用，在之前的基础上添加一些高级知识， 同时提供一个makefile的模版共以后使用。\nMake的内部规则 目标 依赖 规则 x.o x.c cc -c x.c x.o x.s as -o x.s x.o x.y yacc x.y\ncc -c y.tab.c\nrm y.tab.c\nmv y.tab.o x.o x.o x.l lex x.l\ncc -c lex.yy.c\nrm -f lex.yy.c\nmv les.yy.o x.o x.c x.y yacc x.y\nmv y.tab.c x.c x.c x.l lex x.l\nmv les.yy.c x.c x.a x.c cc -c x.c\nar rv x.a x.c\nrm -f x.o 利用上述规则可以简写makefile。\nmain: main.o libylmath.a ylmathp.o cc -o main -L . -l ylmath main.o ylmathp.o libylmath.a: libylmath.a(ylmath.o) ylmathp.o: ylmathp.h Make的内部宏 内部宏 含义 $\u0026lt; 使目标过时的依赖文件（即已更新的文件） $* 不带后缀的依赖文件(常用写法$*.c) $@ 目标文件名，用于显式说明行 $? 类似$\u0026lt; 用于显式说明行 $% 用于处理库文件的依赖文件 这些宏大多用于修改上述隐含规则或创建自己的隐含规则。\n实用技巧 使用一个例子展示如下\n# 使用宏定义增加可移植性 INSTDIR= bin CFLAGS= -O -g LDFLAGS= CC= cc # 文件声明 HEADERS= ylmath.h ylmathp.h SOURCE= main.c ylmathp.c OBJECT= $(SOURCE: .c=.o) # 库声明 LIBSRC= ylmath.c LIBOBJ= ylmath.o LIBDIR= lib # 覆盖默认的.c.o规则，添加-O(优化) -g(调试) .c.o: $(CC) $(CFLAGS) -c $*.c # 连接得到可执行文件 demo: $(OBJECT) libylmath.a $(CC) -o $@ $(OBJECT) -L$(LIBDIR) -lylmath all: demo install # 声明头文件，使用.c.o规则生成 $(OBJECT): $(HEADERS) # 使用.c.a规则生成库并移到lib文件夹 # -开头的命令忽略运行错误和命令返回码，继续执行 libylmath.a: libylmath.a($(LIBOBJ)) -mv $(LIBDIR)/libylmath.a libylmath.a.old -mv libylmath.a $(LIBDIR)/libylmath.a # 更新bin文件夹 install: demo libylmath.a -mv $(INSTDIR)/demo demo.old -mv demo $(INSTDIR)/demo # 删除 clean: -rm *.old demo $(LIBDIR)/libylmath.a # 记录更新信息 # @开头的命令在运行时不显示 print: $(SOURCE) $(OBJECT) @ echo printing modified files @ echo $? \u0026gt; $@ ","date":1586414015,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586414015,"objectID":"5cbe57ccd4a91bfa20d47f22d415f02f","permalink":"https://yangleisx.github.io/post/makefile-plus/","publishdate":"2020-04-09T14:33:35+08:00","relpermalink":"/post/makefile-plus/","section":"post","summary":"由于课程需要，进一步学习了一下make的使用，在之前的基础上添加一些高级知识， 同时提供一个makefile的模版共以后使用。\n","tags":["C/C++","Make"],"title":"Make进阶使用","type":"post"},{"authors":["Lei Yang"],"categories":["代码学习"],"content":"使用Clion+CubeMX开发，开发板为野火指南者，芯片为STM32F103ZET6.\n简单实现使用串口经过STM32与ESP8266通信。\nCube MX设置 串口设置 开发板使用USART1与PC通信，因此设置USART1，使用PA9和PA10端口通信，参数为115200-8-N-1。同时添加RX和TX的DMA设置,NVIC开启串口的global中断。\n板载的ESP8266与STM芯片使用USART3通信,使用PB10和PB11端口,参数为115200-8-N-1.同理也需要添加RX和TX的DMA设置,NVIC开启串口global中断.\n控制引脚设置 ESP8266需要添加片选引脚和复位引脚.板载ESP8266使用PB8作为片选引脚(高电平为使能),PB9作为复位引脚(低电平复位).\n其他设置 SYS中设置调试器模式.\nRCC中设置HSE使用外部晶振,在Clock Configuration中设置时钟.\n生成代码时选择根据外设生成对应的.C/.H文件.\nClion代码 使用DMA接收数据,使用空闲中断处理.将PC发送的数据转发给ESP8266并将ESP8266的回复信息转发到PC.需要注意添加的代码位于指定的user code区间防止被覆盖.\nusart设置 在usart.c中添加必要的变量和缓冲区.\n// BUFFER_SIZE定义在main.h中,不大于200 /* USER CODE BEGIN 0 */ uint8_t usart1_rx_buffer[BUFFER_SIZE]; volatile uint8_t usart1_rx_len = 0; volatile uint8_t usart1_recv_end_flag = 0; uint8_t usart3_rx_buffer[BUFFER_SIZE]; volatile uint8_t usart3_rx_len = 0; volatile uint8_t usart3_recv_end_flag = 0; /* USER CODE END 0 */ 在usart.h中添加变量声明\n/* USER CODE BEGIN Private defines */ extern uint8_t usart1_rx_buffer[BUFFER_SIZE]; extern volatile uint8_t usart1_rx_len; extern volatile uint8_t usart1_recv_end_flag; extern uint8_t usart3_rx_buffer[BUFFER_SIZE]; extern volatile uint8_t usart3_rx_len; extern volatile uint8_t usart3_recv_end_flag; /* USER CODE END Private defines */ GPIO设置 在main.c的while(1)循环之前设置ESP8266使能和复位\n/* USER CODE BEGIN 2 */ // 设置ESP8266选择 HAL_GPIO_WritePin(CH_GPIO_Port, CH_Pin, GPIO_PIN_SET); HAL_GPIO_WritePin(RST_GPIO_Port, RST_Pin, GPIO_PIN_RESET); HAL_Delay(500); HAL_GPIO_WritePin(RST_GPIO_Port, RST_Pin, GPIO_PIN_SET); /* USER CODE END 2 */ 中断响应 在main.c的while(1)循环之前开启接收DMA和空闲中断\n/* USER CODE BEGIN 2 */ // 开启USART的接收DMA传输中断 HAL_UART_Receive_DMA(\u0026amp;huart1, usart1_rx_buffer, BUFFER_SIZE); __HAL_UART_ENABLE_IT(\u0026amp;huart1, UART_IT_IDLE); HAL_UART_Receive_DMA(\u0026amp;huart3, usart3_rx_buffer, BUFFER_SIZE); __HAL_UART_ENABLE_IT(\u0026amp;huart3, UART_IT_IDLE); /* USER CODE END 2 */ 在stm32f1xx_it.c中修改中断响应,分别修改USART1_IRQHandler和USART3_IRQHandler.当接收DMA接收完成时,依次触发DMA接收中断和USART全局中断.\n/* USER CODE BEGIN USART1_IRQn 0 */ // 局部变量 uint32_t tmp_flag = 0; uint32_t temp; // 空闲状态 tmp_flag = __HAL_UART_GET_FLAG(\u0026amp;huart1, UART_FLAG_IDLE); if((tmp_flag != RESET)) { // 关闭空闲状态 __HAL_UART_CLEAR_IDLEFLAG(\u0026amp;huart1); // 清空寄存器 temp = huart1.Instance-\u0026gt;SR; temp = huart1.Instance-\u0026gt;DR; HAL_UART_DMAStop(\u0026amp;huart1); // 获取未传输比特数 用于计算已传输比特数 temp = hdma_usart1_rx.Instance-\u0026gt;CNDTR; usart1_rx_len = BUFFER_SIZE - temp; // 开始标志位 usart1_recv_end_flag = 1; } /* USER CODE END USART1_IRQn 0 */ 在main.c的循环部分添加中断处理部分\n// PC传输中断 if(usart1_recv_end_flag == 1) { // 发送到ESP8266 HAL_UART_Transmit(\u0026amp;huart3, usart1_rx_buffer, usart1_rx_len, 0xFF); // 清空缓冲和标志位 memset(usart3_rx_buffer, 0, BUFFER_SIZE); usart1_rx_len = 0; usart1_recv_end_flag = 0; // 开启接收中断 HAL_UART_Receive_DMA(\u0026amp;huart1, usart1_rx_buffer, BUFFER_SIZE); } // ESP8266传输中断 if(usart3_recv_end_flag == 1) { // 发送到PC显示 HAL_UART_Transmit(\u0026amp;huart1, usart3_rx_buffer, usart3_rx_len, 0xFF); // 清空缓存和标志位 memset(usart3_rx_buffer, 0, BUFFER_SIZE); usart3_rx_len = 0; usart3_recv_end_flag = 0; // 开启接收中断 HAL_UART_Receive_DMA(\u0026amp;huart3, usart3_rx_buffer, BUFFER_SIZE); } /* USER CODE END WHILE */ 从而实现STM32转发PC和ESP8266的串口通信,接下来就可以通过ESP8266的AT指令进行设置和操作.同时在PC的串口调试工具上检测到回复的信息.\n我遇到的坑 ESP8266的使能引脚和复位引脚配置错误,导致ESP8266的通信出现一些问题. 代码中的发送指令使用HAL_UART_Transmit_DMA,导致发送/接收到的指令不全,因此改用HAL_UART_Transmit函数. 网上找到的代码和野火提供的代码大多都是基于STM32标准库和Keil开发环境,使用HAL库和CubeMX开发的代码不多,而且最开始学习STM32也是基于STM32标准库,因此会有一些不适应. ","date":1586315332,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586315332,"objectID":"3ff3a2e5fa4f76fd70962b0f9e70b484","permalink":"https://yangleisx.github.io/post/stm32-esp8266-hal/","publishdate":"2020-04-08T11:08:52+08:00","relpermalink":"/post/stm32-esp8266-hal/","section":"post","summary":"使用Clion+CubeMX开发，开发板为野火指南者，芯片为STM32F103ZET6.\n简单实现使用串口经过STM32与ESP8266通信。\n","tags":["STM32"],"title":"[HAL]STM32与ESP8266的交互","type":"post"},{"authors":["Lei Yang"],"categories":["代码学习"],"content":"使用Clion+CubeMX开发，开发板为野火指南者，芯片为STM32F103ZET6.\n简单实现使用定时器和按键中断点亮LED。\nCube MX设置 引脚设置 板载RGB-LED使用的引脚PB0，PB1，PB5设置为output push pull（推挽输出）。\n板载微动开关使用的引脚PA0，PC13设置为外部中断且下降沿触发。同时NVIC设置EXTI0和EXTI15-10的使能。\n时钟设置 选择TIM1，时钟源选择内部时钟（Internal Clock）。设置参数为预分频36000，计数为1000，此时频率为72MHz/36000/1000=2Hz。\nNVIC开启TIM1 update interrupt中断。\n其他设置 SYS中设置调试器模式.\nRCC中设置HSE使用外部晶振,在Clock Configuration中设置时钟.\n生成代码时选择根据外设生成对应的.C/.H文件.\nClion代码 在CubeMX设置时为GPIO指定user label。在生成的代码中就会自动定义对应的GPIO端口和引脚。\nLED宏定义 /* USER CODE BEGIN Private defines */ #define ON GPIO_PIN_RESET #define OFF GPIO_PIN_SET #define LED1(a) HAL_GPIO_WritePin(LED1_GPIO_Port, LED1_Pin, a) #define LED2(a) HAL_GPIO_WritePin(LED2_GPIO_Port, LED2_Pin, a) #define LED3(a) HAL_GPIO_WritePin(LED3_GPIO_Port, LED3_Pin, a) #define LED1_ON LED1(ON) #define LED1_OFF LED1(OFF) #define LED1_TOGGLE HAL_GPIO_TogglePin(LED1_GPIO_Port, LED1_Pin) #define LED2_ON LED2(ON) #define LED2_OFF LED2(OFF) #define LED2_TOGGLE HAL_GPIO_TogglePin(LED2_GPIO_Port, LED2_Pin) #define LED3_ON LED3(ON) #define LED3_OFF LED3(OFF) #define LED3_TOGGLE HAL_GPIO_TogglePin(LED3_GPIO_Port, LED3_Pin) #define LED_RED {LED1_ON;LED2_OFF;LED3_OFF;} #define LED_GREEN {LED1_OFF;LED2_ON;LED3_OFF;} #define LED_BLUE {LED1_OFF;LED2_OFF;LED3_ON;} #define LED_YELLOW {LED1_ON;LED2_ON;LED3_OFF;} #define LED_PURPLE {LED1_ON;LED2_OFF;LED3_ON;} #define LED_CYAN {LED1_OFF;LED2_ON;LED3_ON;} #define LED_WHITE {LED1_ON;LED2_ON;LED3_ON;} #define LED_BLACK {LED1_OFF;LED2_OFF;LED3_OFF;} /* USER CODE END Private defines */ 按键中断处理 在stm32f1xx_it.c文件中发现EXTI中断调用HAL_GPIO_EXTI_IRQHandler(void)函数，网上找到的资料说该函数调用弱定义的HAL_GPIO_EXTI_Callback()函数。（虽然我没找到在哪）\n因此在main.c函数中重复定义该函数用于中断处理.\n/* USER CODE BEGIN 4 */ /** * @brief EXTI Handler Callback: KEY Response * @retval None */ void HAL_GPIO_EXTI_Callback(uint16_t GPIO_Pin) { // select target GPIO switch (GPIO_Pin) { case KEY1_Pin:LED1_TOGGLE;break; case KEY2_Pin:LED2_TOGGLE;break; default:break; } } /* USER CODE END 4 */ 时钟中断处理 在stm32f1xx_it.c文件中发现TIM1中断调用HAL_TIM_IRQHandler(void)函数，网上找到的资料说该函数调用弱定义的HAL_TIM_PeriodElapsedCallback()函数。\n因此在main.c函数中重复定义该函数用于中断处理.\n/* USER CODE BEGIN 4 */ /** * @brief TIM Handler Callback: LED Blink * @retval None */ void HAL_TIM_PeriodElapsedCallback(TIM_HandleTypeDef *htim) { // TIM1: LED3 blink if (htim-\u0026gt;Instance == htim1.Instance) { LED3_TOGGLE; } } /* USER CODE END 4 */ ","date":1586315294,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586315294,"objectID":"23f94322bdf0abcc03b8cd554d6a2951","permalink":"https://yangleisx.github.io/post/stm32-interupt-hal/","publishdate":"2020-04-08T11:08:14+08:00","relpermalink":"/post/stm32-interupt-hal/","section":"post","summary":"使用Clion+CubeMX开发，开发板为野火指南者，芯片为STM32F103ZET6.\n简单实现使用定时器和按键中断点亮LED。\n","tags":["STM32"],"title":"[HAL]STM32定时器和按键中断的使用","type":"post"},{"authors":["Lei Yang"],"categories":["代码学习"],"content":"中断的概念是嵌入式开发和计算机系统中非常重要的部分。\n可以参考学堂在线的《ARM微控制器与嵌入式系统》的相关章节。\n两个概念：\nNVIC（嵌套向量中断控制器）：用于设置中断优先级和中断使能。位于芯片内部。 EXTI（外部中断/时间控制器）：用于设置外部中断和事件。位于APB2总线上。 注意：异常和中断清单在stm32f10x.h中的IRQn_Type中。\nNVIC相关的处理位于misc.h中，EXTI相关的处理位于stm32f10x_exti.h中。\n全流程：1. 初始化GPIO 2. 初始化EXTI 3. 配置NVIC使能中断 4. 编写中断服务函数\nNVIC的设置 STM32使用4bit表示中断优先级。通常首先设置优先级分组，共有五种优先级分组，分别使用0-4bit表示主优先级，剩下的表示子优先级。\nNVIC_PriorityGroupConfig(NVIC_PriorityGroup_1); 具体的设置方式使用对应的初始化结构体\nNVIC_InitTypeDef NVIC_InitStructure; NVIC_InitStructure.NVIC_IRQChannel = EXTI0_IRQn;// 中断编号 EXTI0_IRQn NVIC_InitStructure.NVIC_IRQChannelPreemptionPriority = 1; NVIC_InitStructure.NVIC_IRQChannelSubPriority = 1; NVIC_InitStructure.NVIC_IRQChannelCmd = ENABLE;// 中断使能 NVIC_Init(\u0026amp;NVIC_InitStructure); 同时还需要设置中断服务函数，其函数声明写在stm32f10x_it.h中,函数定义写在stm32f10x_it.c中。中断服务函数名在汇编启动文件中定义，与中断名相对应（例如EXTI0_IRQn和EXTI0_IRQHandler）。\n（考虑到相关的宏定义的有效性，也可以写在对应模块的C文件中）\nEXTI的设置 EXTI包括了20个外部中断/事件线。包括中断屏蔽寄存器、边沿选择寄存器、请求挂起寄存器、软件中断事件寄存器。可以从外设事件或者GPIO输入产生中断和事件。其中的中断线路信号传入NVIC内，事件线路信号得到一个脉冲（用于其他的外设使用）。\nGPIO线可以挂载到EXTI的0-15上（注意编号一一对应，例如GPIOA-3挂在EXTI3上），剩下的四根线用于特定的任务。注意这里的EXTI线的具体定义分别为EXTI0、EXTI1、EXTI2、EXTI3、EXTI4、EXTI9_5、 EXTI15_10。位于“stm32f10x_exti.h”中。\n具体的设置方式使用初始化结构体:\n// 先设置GPIO 注意打开AFIO时钟（用于EXTI设置） GPIO_InitTypeDef GPIO_InitStructure; RCC_APB2PeriphClockCmd((RCC_APB2Periph_GPIOA|RCC_APB2Periph_AFIO),ENABLE); GPIO_InitStructure.GPIO_Pin = GPIO_PIN_0 GPIO_InitStructure.GPIO_Mode = GPIO_Mode_IN_FLOATING; GPIO_Init(GPIOA, \u0026amp;GPIO_InitStructure); // 将GPIO挂载到EXTI上 GPIO_EXTILineConfig(GPIO_PortSourceGPIOA,\\ GPIO_PinSource0); // 再设置EXTI线 EXTI_InitTypeDef EXTI_InitStructure; EXTI_InitStructure.EXTI_Line = EXTI_LINE0;// 与GPIOpin对应 EXTI_InitStructure.EXTI_Mode = EXTI_Mode_Interrupt;// Interrupt或者Event EXTI_InitStructure.EXTI_Trigger = EXTI_Trigger_Rising;// Rising或Falling或RIsing_Falling EXTI_InitStructure.EXTI_LineCmd = ENABLE; EXTI_Init(\u0026amp;EXTI_InitStructure); 中断服务函数 中断号和终端服务函数在NVIC中设置，分别参见stm32f10x.h和汇编启动文件的定义。\n中断服务函数需要在stm32f10x_it.h中定义，在stm32f10x_it.c中实现，或者在对应的模块C文件中实现（考虑到宏定义的有效性）。\n中断服务函数中通过EXTI_GetITStatus()获得中断标志位为SET/RESET。处理结束后通过EXTI_ClearITPendingBit()清除中断标志位。\n","date":1585965676,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585965676,"objectID":"886a96d8bbc275ddcd29c85e7ec81610","permalink":"https://yangleisx.github.io/post/stm32-int/","publishdate":"2020-04-04T10:01:16+08:00","relpermalink":"/post/stm32-int/","section":"post","summary":"中断的概念是嵌入式开发和计算机系统中非常重要的部分。\n可以参考学堂在线的《ARM微控制器与嵌入式系统》的相关章节。\n","tags":["STM32"],"title":"STM32的中断操作","type":"post"},{"authors":["Lei Yang"],"categories":["代码学习"],"content":"STM32的时钟主要包括四个部分：系统时钟SYSCLK，AHB总线时钟HCLK，APB2总线时钟PCLK2，APB1总线时钟PCLK1。主要的时钟处理为设置各个时钟的频率和不同总线时钟和外设时钟的开启。\n通常的设置为PCLK2=HCLK=SYSCLK=PLLCLK=72MHz，PCLK1=HCLK/2=36MHz。\n库中自带了SetSysClockTo72()通过寄存器操作实现上述设置,也可以通过RCC库的函数进行具体的设置.\n系统时钟设置 时钟信号有三个来源：高速外部时钟HSE、高速内部时钟HSI(实际使用一半的频率HSI/2)、锁相环倍频输出时钟PLL。其中的PLL时钟的来源可以是HSE或HSI，但是HSI存在漂移，通常不使用。\n通常情况下HSE设置为8MHz, 因此PLL的倍频因子设置为9,从而得到72MHz的系统时钟.\n# 设置HSE或HSI的开启 RCC_HSEConfig(RCC_HSE_ON); RCC_HSICmd(ENABLE); # 设置PLL的输入为HSE或HSI/2 pllmul为倍频因子 RCC_PLLConfig(RCC_PLLSource_HSE_Div1, pllmul); RCC_PLLConfig(RCC_PLLSource_HSI_Div2, pllmul); RCC_PLLCmd(ENABLE); # 设置系统时钟为PLL的输出 RCC_SYSCLKConfig(RCC_SYSCLKSource_PLLCLK); 总线时钟设置 总线时钟通常是在系统时钟的基础上做分频.\nAHB总线时钟为HCLK,是系统时钟在AHB分频器按１分频得到,因此为72MHz.\nAPB2总线时钟为PCLK2 ,是AHB总线时钟在APB2分频器按1分频得到,因此为72MHz.\nAPB1总线时钟为PCLK1,是AHB总线时钟在APB1分频器二分频得到,因此为36MHz.\n外设时钟设置 具体使用外设时的时钟频率要根据需要具体设置.\nUSB时钟:通常令PLL时钟为72MHz,USB时钟为48MHz,通过USB分频器的１.５倍分频实现． Cortex时钟:通常为9MHz,通过HCLK经过8分频得到.用于驱动内核定时器SysTick. ADC时钟：最高为14MHz,具体根据使用情况选择.通过PCLK2分频得到. RTC时钟:可以通过HSE/128或LSE或HSI提供. 独立看门狗时钟:通过LSI提供. MCO信号输出:对外提供时钟信号,通过复用GPIO实现.时钟来源可以是PLLCLK/2,HSI,HSE,SYSCLK GPIO信号输出:使用RCC_APB2PeriphClockCmd(RCC_APB2Periph_GPIOx, ENABLE);开启 ","date":1585965673,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585965673,"objectID":"840845c8b1e194c3bb7dd435921aaace","permalink":"https://yangleisx.github.io/post/stm32-clock/","publishdate":"2020-04-04T10:01:13+08:00","relpermalink":"/post/stm32-clock/","section":"post","summary":"STM32的时钟主要包括四个部分：系统时钟SYSCLK，AHB总线时钟HCLK，APB2总线时钟PCLK2，APB1总线时钟PCLK1。主要的时钟处理为设置各个时钟的频率和不同总线时钟和外设时钟的开启。\n","tags":["STM32"],"title":"STM32的时钟处理","type":"post"},{"authors":["Lei Yang"],"categories":["实用工具"],"content":"Windows下使用CLion和CubeMX构建STM32开发环境。\n使用野火指南者开发版，芯片为STM32F103VET6。使用配套CMSIS-DAP调试器。\n下载安装\n下载STM32CubeMx 下载Clion 下载交叉编译工具链GNU Tools Arm Embedded，注意添加系统路径并在cmd测试“arm-none-eabi-gcc -v” 下载MinGW，注意至少安装gcc，g++，cmake 下载OpenOCD 设置Clion\nFile——Settings——Build，Excution，Deplotment——Toolchains，设置好mingw File——Settings——Plugin，搜索安装插件openocd File——Settings——Build，Excution，Deplotment——Embedded Deployment，设置路径 File——Settings——Build，Excution，Deplotment——OpenOCD support，设置路径 创建CubeMX工程\n选择芯片 选择功能及其对应的引脚 选择sys功能，选择使用串口下载或者使用调试器 时钟配置，使用HSE，9倍PLL，APB1选择2分频 选择保存路径，选择工具为SW4STM32 生成配置代码 Clion导入工程\n选择Cube MX生成的代码，默认选项导入\nTool——Update CMake to STM32 Projects（可以设为自动导入）\nBuild——编译Project或者编译“OCD+你创建的工程名“\nRun——Edit Configuration——OpenOCD——Board config file——选择一个stm32f10系列的板子（我选择stm32f103c8_blue_pill，之后修改）——点击Cope to Project\u0026amp;Use\n修改cfg文件，添加野火的调试器。\n# 选择对应调试器 source [find interface/cmsis-dap.cfg] # 选择模式，这里的swd对应Cube MX设置”5线JTAG“ 对应野火调试器直接插指南者的”SWD“ transport select swd # 选择片上FLASH大小 set FLASH_SiZE 0x80000 # 选择芯片 source [find target/stm32f1x.cfg] 运行\n在main.c的对应位置添加代码，注意需要添加在指定的user code部分，否则更新后可能被覆盖 Run——点击Run ”OCD+你创建的工程名“ 参考链接：紫色能量的博客\n","date":1585965406,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585965406,"objectID":"9a7d193f51f1ac4142783ad86527116c","permalink":"https://yangleisx.github.io/post/stm32-clion/","publishdate":"2020-04-04T09:56:46+08:00","relpermalink":"/post/stm32-clion/","section":"post","summary":"Windows下使用CLion和CubeMX构建STM32开发环境。\n使用野火指南者开发版，芯片为STM32F103VET6。使用配套CMSIS-DAP调试器。\n","tags":["STM32"],"title":"Clion开发STM32环境搭建","type":"post"},{"authors":[],"categories":["代码学习"],"content":"背景 之前使用过C++和QT开发具有GUI的小工具。考虑到人生苦短，决定转到使用PyQt，因此在mac上搭建PyQt工作环境。由于电脑上已经安装了QtCreator和Qt环境，网上也有很多教程因此不再赘述。\n环境搭建 为了干净我选择使用virtualenv构建用于PyQt的虚拟环境。\n$ virtualenv pyqtenv $ source pyquenv/bin/activate (pyqtenv)$ pip install PyQt5 似乎Qt Creator的python项目默认使用PySide2，但是在新建项目或者文件的时候有一个\u0026#34;Qt Module\u0026#34;的选项可以选择PyQt5或者PySide2。我选择PyQt5。\n需要注意执行前在Qt Creator的项目选项中选择Python解释器，即选择所安装的虚拟环境目录。通常情况下QtCreator会发现并自动生成“pyqtenv virtual environment”，如果没有自动生成则需要在manage选项中手动添加并选择执行路径\u0026#34;/path_to_your_env/pyqtenv/bin/python\u0026#34;。\n测试代码 由于人生苦短，我选择使用Qt Designer进行UI设计，如果是喜欢手撸代码的大佬请跳过以下内容。\n在Qt Creator中选择新建Qt Designer Form得到ui文件，并通过Qt Designer设计界面。得到mainwindow.ui界面文件。此时需要注意要将界面文件导入py项目需要使用PyQt5自带的一个工具pyuic5编译得到UI类。（如果有更好的方法欢迎告诉我，我也不想这么麻烦）\n$ source pyquenv/bin/activate (pyqtenv)$ pyuic5 -o ui_mainwindow.py mainwindow.ui 之后就可以在Qt Creator中添加ui编译得到的py文件，一种方法是使用UI类作为基类之一并使用self.setupUI(self)。还有一种方法是使用UI类作为成员，即self.ui = Ui_MainWindow()。我选择前者，代码如下。\nimport sys from PyQt5.QtWidgets import QApplication, QMainWindow from ui_mainwindow import Ui_MainWindow class MainWindow(QMainWindow, Ui_MainWindow): def __init__(self): super(MainWindow, self).__init__() self.setupUi(self) if __name__ == \u0026#34;__main__\u0026#34;: app = QApplication([]) window = MainWindow() window.show() sys.exit(app.exec_()) 可以正常实现自己设计的UI界面就表明没啥问题了。\n","date":1584241518,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1584241518,"objectID":"22b0c1f66b5b70ec608e86e07988e9d3","permalink":"https://yangleisx.github.io/post/pyqt-env/","publishdate":"2020-03-15T11:05:18+08:00","relpermalink":"/post/pyqt-env/","section":"post","summary":"背景 之前使用过C++和QT开发具有GUI的小工具。考虑到人生苦短，决定转到使用PyQt，因此在mac上搭建PyQt工作环境。由于电脑上已经安装了QtCreator和Qt环境，网上也有很多教程因此不再赘述。\n","tags":["Python","Qt"],"title":"PyQt 工作环境搭建","type":"post"},{"authors":["Lei Yang"],"categories":["代码学习"],"content":"概念 dlib可以检测图像中的人脸，并且可以检测出人脸上的68个关键点，其中后20个点表示了唇部的关键点，因此可以使用dlib检测人脸并通过嘴部关键点得到嘴部图像。\n代码 import dlib import cv2 import numpy as np from PIL import Image # 加载面部检测模型 predictor_path = \u0026#39;.\\\\shape_predictor_68_face_landmarks.dat\u0026#39; detector = dlib.get_frontal_face_detector() predictor = dlib.shape_predictor(predictor_path) # 检测面部并选择 faces = detector(img, 1) face = faces[0] # 检测关键点并选择唇部 points = predictor(img, face) mouth_points = [(point.x, point.y) for point in points.parts()[48:]] # 截取唇部图像 center = np.mean(mouth_points, axis=0).astype(int) rect = cv2.boundingRect(np.array(mouth_points)) ratio = rect[2] / rect[3] # 给定输出规模shape=[width, height] if shape[0] / shape[1] \u0026gt; ratio: shape[0], shape[1] = shape[0] / shape[1] * rect[3], rect[3] else: shape[0], shape[1] = rect[2], shape[1] / shape[0] * rect[2] mouth_img = img[int(center[1] - shape[1] / 2):int(center[1] + shape[1] / 2), int(center[0] - shape[0] / 2):int(center[0] + shape[0] / 2)] # 保存图像 Image.fromarray(mouth_img).save(\u0026#34;img_path\u0026#34;) 参考：张宏伦的知乎专栏\n","date":1584239496,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1584239496,"objectID":"46c75e96b9e9987677241a9abe7123c3","permalink":"https://yangleisx.github.io/post/python-dlib/","publishdate":"2020-03-15T10:31:36+08:00","relpermalink":"/post/python-dlib/","section":"post","summary":"概念 dlib可以检测图像中的人脸，并且可以检测出人脸上的68个关键点，其中后20个点表示了唇部的关键点，因此可以使用dlib检测人脸并通过嘴部关键点得到嘴部图像。\n","tags":["Python","Computer Vision"],"title":"使用dlib提取图像中人的嘴部","type":"post"},{"authors":["Lei Yang"],"categories":["代码学习"],"content":"以STM32F103VET6点亮LED为例简单记录一下STM32的GPIO如何控制。\nGPIO控制原理 片上外设挂载有三条总线，APB1、APB2、AHB。GPIO挂载在APB2总线上。共有七组GPIO（端口），每个GPIO有16个引脚（位）。\nGPIO的行为通过7个寄存器来控制，每个寄存器为32bit。\n七个寄存器分别为CRL（低八位的控制寄存器）、CRH（高八位的控制寄存器）、IDR（输入数据寄存器）、ODR（输出数据寄存器）、BSRR（端口位设置/清除寄存器）、BRR、LCKR。\nCRH和CRL：每四位为一组控制一位的IO。其中低两位控制运行模式（输入、2MHz输出、10MHz输出、50MHz输出），高两位控制IO配置（输入：模拟、浮空、上/下拉。输出：推挽、开漏）。使用宏定义的工作模式时，每一个宏使用8bit数字表示，实际写入的时候写入的是bit[3:2]。\nBSRR（端口位设置/清除寄存器）：低16位触发时表示ODR对应位置1，高16位触发时表示ODR对应位置0。\nBRR（端口位清除寄存器）：低16位触发时表示ODR对应的位置0。\nODR（输出数据寄存器）：对应的位置0或置1表示对应引脚高低电平。\nIDR（输入数据寄存器）：使用上下拉输入的时候保存输入引脚的值0或1。\n需要注意的是，GPIO使用前要进行时钟的使能，此时使用RCC_APB2ENR寄存器激活APB２总线上的对应外设。其中ｂｉｔｓ［８：２］表示七个GPIO。\n使用寄存器操作 开启GPIOB的0号引脚\n// 开启GPIOB的时钟 RCC_APB2ENR |= (1 \u0026lt;\u0026lt; 3); // GPIOB的0号引脚控制位全部置0 GPIOB_CRL \u0026amp;= ~(0x0F \u0026lt;\u0026lt; (4*0)); // GPIOB的0号引脚设置为10MHz推挽输出 GPIOB_CRL |= (1 \u0026lt;\u0026lt; (4*0)); // GPIOB的0号引脚拉低 GPIOB_ODR |= (0 \u0026lt;\u0026lt; 0); 使用标准库操作 使用标准库开启时钟并设置引脚\n// 初始化结构体 GPIO_InitTypeDef GPIO_InitStructure; // 开启时钟 RCC_ARB2PeriphClockCmd(RCC_APB2Periph_GPIOB, ENABLE); // 设置引脚和工作模式 GPIO_InitStructure.GPIO_Pin = GPIO_Pin_0; GPIO_InitStructure.GPIO_Mode = GPIO_Mode_Out_PP; GPIO_InitStructure.GPIO_Speed = GPIO_Speed_50MHz; // 写入工作模式 GPIO_Init(GPIOB, \u0026amp;GPIO_InitStructure); // 引脚置位 GPIO_SetBits(GPIOB, GPIO_Pin_0); GPIO_ResetBits(GPIOB, GPIO_Pin_0); // 或者使用BSRR、BRR、ODR设置 GPIOB-\u0026gt;BSRR |= 0x01; GPIOB-\u0026gt;BRR |= 0x01; GPIOB-\u0026gt;ODR |= 0x01; ","date":1583415424,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583415424,"objectID":"f52199c85ddc40642aa77f0159137e76","permalink":"https://yangleisx.github.io/post/stm32-gpio/","publishdate":"2020-03-05T21:37:04+08:00","relpermalink":"/post/stm32-gpio/","section":"post","summary":"以STM32F103VET6点亮LED为例简单记录一下STM32的GPIO如何控制。\n","tags":["STM32"],"title":"STM32的GPIO处理","type":"post"},{"authors":["Lei Yang"],"categories":["代码学习"],"content":"PyTorch学习笔记。基于《Deep Learning with PyTorch》，主要为相关语法的笔记。 用来自己写代码的时候参考。Dataset部分还需要进一步完善。\n环境 import torch import torch.optim as optim import torch.nn as nn import torch.nn.functional as F import torch.utils.data as data from torchvision import transforms torch.nn提供常见的神经网络结构\ntorch.util.data用于加载数据（使用Dataset和DataLoader）\ntorch.optim用于优化\ntorch.nn.DataParallel和torch.distributed用于特定平台的加速计算\ntorchvision.transforms提供常见图形格式的转换\nTensor Basic # 生成tensor \u0026gt;\u0026gt;\u0026gt; a = torch.Tensor([[1.,2.],[2.,3.],[3.,4.]]) \u0026gt;\u0026gt;\u0026gt; b = torch.FloatTensor([1.,2.,3.]) # 查看相关信息 \u0026gt;\u0026gt;\u0026gt; print(a.shape) torch.Size([3,2]) # tensor是按维度一次顺序储存（先行后列） \u0026gt;\u0026gt;\u0026gt; print(a.storage()) \u0026gt;\u0026gt;\u0026gt; print(a[0].stride) \u0026gt;\u0026gt;\u0026gt; print(a[0].storage_offset()) # 通常情况下 obj[i][j] = offset+stride[0]*i+stride[1]*j 使用下标得到的subtensor指向原数据，如果不希望更改原本的数据，需要使用.clone()得到数据的拷贝。\n二维向量使用.t()可以转置。实际上储存空间没有变，只更改了stride()高维向量使用.transpose(d_1,d_2)可以交换指定的两个维度值。\n使用.contiguous()重新排布张量的内部存储使其成为contiguous tensor可以提高运算效率。\n使用.dtype查看元素类型。包括int(8、16、32、64)，uint8，float(16、32、64)，即不同大小的整数和浮点数。默认的Tensor生成的是FloatTensor(float32)。可以在torch.tensor(…, dtype=float)直接指明tensor内部类型。或者使用.float()、.to(float)、.to(dtype=float)转换。\n索引方法和python的list差不多。\npytorch的tensor高度兼容numpy。可以使用.numpy()直接转换为numpy的array对象。或者使用torch.from_numpy(array)从numpy的array转化为tensor。\n使用torch.save(p,f)和p=torch.load(f)可以存取tensor。通常后缀名为.t\n部分pytorch函数支持in-place版本，即a = torch.sqrt(a)可以换成a.sqrt_()，减少空间成本。\nDevice 使用CUDA的环境中，可以将tensor保存在GPU中。建议在程序开始是检测系统环境。\ndev = \u0026#39;cuda\u0026#39; if torch.cuda.is_available() else \u0026#39;cpu\u0026#39; 用于GPU的tensor可以使用torch.tensor(…, device=‘cuda’)生成，或者.to(device=‘cuda’)将其转换为CUDA的格式。便于使用CUDA计算。\n在多GPU的环境中，使用’cuda:0’等来表示所使用的GPU。\n（或者os.enrivon[‘CUDA_VISIBLE_DEVICES’] = ‘0’ ? ）\nData 表格数据 可以使用csv.reader或者np.loadtxt处理\ncsv数据 path = \u0026#34;something.csv\u0026#34; data_numpy = np.loadtxt(path, dtype=np.float32, delimiter=\u0026#39;,\u0026#39;, skiprows=1) # 根据文件情况确定delimiter(, or ;) # skiprows跳过表头 col_list = next(csv.reader(open(path), delimiter=\u0026#39;,\u0026#39;)) # 读取到表头 data_tensor = torch.from_numpy(data_numpy) 数值型target可以看作是一个值，也可以转化为独热码。前者存在大小比较的涵义，后者更多用于分类，没有顺序关系。\n需要注意原本数据取值范围是基于1（1～max）还是基于0（0～max-1），前者需要减1（scatter是基于0的）\n# 独热码生成示例 # target是一个long类型的一维tensor,使用unsqueeze增一个维度 target_oneshot = torch.zeros(target.shape[0],10) target_oneshot.scatter_(1, target.unsqueeze(1), 1.0) # 第一个参数表示独热码维数 # 将第三个参数移动到第二个参数表示的位置上 使用zip()可以将多个可迭代数据（list等）打包成元组的list用于迭代。\n时间序列数据 在单个数据的基础上增加了时间维度，具有顺序特性。\npath = \u0026#34;something.csv\u0026#34; data_numpy = np.loadtxt(path, dtype=nnp.float32, delimiter=\u0026#39;,\u0026#39;, skiprows=1,converters={1: lambda x: float(x[8:10])}) # 这里converters表示对第1列用lambda处理 data_tensor = torch.from_numpy(data_numpy) 使用.view()可以改变数据维度，使用-1参数推测维度值\n使用cat((tensor_1, tensor_2), dim=1)可以将多个tensor按照目标维度连在一起(目标维度上长度为两者之和，其他维度长度不变)。\n数值型数据可以映射到0～1（(data-min)/(max-min)）或者-1～1或者转变为标准正态分布(data - mean)/std\n文本数据 两种方式，针对character的处理和针对word的处理。通常将其转换为独热码。\n对于读入的字符串使用.split(’\\n’)切成行。或者.replace(’\\n’,’ ‘).split()直接得到所有的字符。\n使用.lower()可以变为小写，便于分析。使用.strip()删去对应的字符，没有参数时删除首尾空格。\n针对character的处理可以按照其ASCII码的数值变为独热码。使用ord()可以得到ASCII数字（0～127）。\n针对word的处理可以按照字典文件转变为独热码。或者使用embedding。\n# 创建字典示例 with open(\u0026#39;path\u0026#39;) as f: text = f.read() punctuation = \u0026#39;.,;:\u0026#34;!?”“_-\u0026#39;\u0026#39; # 切分单词 word_list = text.lower().replace(\u0026#39;\\n\u0026#39;, \u0026#39; \u0026#39;).split() # 除去标点 word_list = [word.strip(punctuation) for word in word_list] # 除去重复单词并排序 word_list = sorted(set(word_list)) # 得到字典索引 word2index_dict = {word: i for (i, word) in enumerate(word_list)} 使用embedding可以将字典转化为固定长度的浮点数向量。比较理想的方式是将相近含义或距离比较小的单词映射到距离比较近的向量。通常情况理想的embedding是使用神经网络学习生成的。\n（torch.nn.Embedding(num, dim))\n图像数据 导入图像的方法很多，包括imageio.imread()，PIL.Image.open()，cv2.imread()等。\nimport imageio img_arr = imageio.imread(\u0026#39;path\u0026#39;) image_tensor = torch.tensor(img_arr) # image_tensor = torch.from_numpy(img_arr) from PIL import Image image = Image.open(\u0026#39;path\u0026#39;) iamge_tensor = torch.tensor(np.array(image)) import cv2 image = cv2.imread(\u0026#39;path\u0026#39;) image_tensor = torch.tensor(image) PyTorch处理的图像要求是C * H * W结构，默认图像为H * W * C因此需要torch.transpose()转换一下。如果是视频，应该得到N * C * H * W。\nTensorflow的图像要求是H * W * C\n读取多张图片时可以创建N*C*H*W的tensor再依次读取并存入。或者使用stack()创建。\n图像可以根据网络需求进行缩放，旋转和剪切。\n通常要进行适当的正规化。\n三维数据 例如CT扫描数据，具有三个空间维度。\n通常使用5D的tensor表示 N*C*D*H*W。D、H、W表示三个空间维度。C表示通道（通常为一维通道，类似灰度图像）\nModel 构建模型\nModel Basic 主要成分包括Model(前向传播)、Loss Function、Gradient(反向传播)。\npytorch的tensor提供了requires_grad=True可以自动求导/梯度。指定了自动求导的张量参与的计算会被记录（计算图中的叶子结点），便于求梯度反向传播。拥有.grad成员，默认为None。\n指定自动求导的张量参与计算得到的张量（计算图上层节点）拥有.backward()成员，之后原张量（叶子结点）的.grad成员为该张量（上层节点）对应的梯度。\n注意这里的.grad梯度值为累计得到，使用完毕需要使用.zero_()归零，防止过分累积。同时新的一次计算时使用.detach()将其从计算图中分离\n# 自动梯度举例 def training_loop(n_epochs, learning_rate, params, source, target): for epoch in range(1, n_epochs+1): if params.grad is not None: params.grad.zero_() predict = model(source, *params) loss = loss_fn(predict, target) loss.backward() params = (params - learning_rate * params.grad) \\ .detach().requires_grad_() return params 同样，显示输出结果等对结果进行操作时必须使用detach()从计算图中分离。\nOptim 模型的参数被传入优化器，每当给定输入后计算反向传播和梯度并按照优化器策略自动更新。\n优化器包括zero_grad和step成员，前者清空梯度，后者更新参数。\nimport torch.optim as optim # 创建优化器 params = torch.tensor([1.0,0.0], requires_grad=True) learning_rate = 1e-5 optimezer = optim.SGD([params], …","date":1581501937,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581501937,"objectID":"89d2eb400f24e8ddcd7889738117dfc8","permalink":"https://yangleisx.github.io/post/pytorch/","publishdate":"2020-02-12T18:05:37+08:00","relpermalink":"/post/pytorch/","section":"post","summary":"PyTorch学习笔记。基于《Deep Learning with PyTorch》，主要为相关语法的笔记。 用来自己写代码的时候参考。Dataset部分还需要进一步完善。\n","tags":["PyTorch","Deep Learning"],"title":"PyTorch学习笔记","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文题目: Attention is All You Need\n开源项目地址:github\n主要内容 文章实现了一种仅使用attention机制，完全去除卷积网络和循环网络的结构，称为Transformer网络。\n在实现比较高的准确性的基础上，具有较低的计算成本。\n背景 目前常用的序列处理模型通常使用一个编码器和一个解码器，在两者的连接中使用attention机制，而且编码器和解码器的实现使用复杂的CNN和RNN。\n由于RNN结构引入的时序逻辑不利于并行计算，引入比较高的计算成本。因此Transformer结构中除去了RNN而仅使用attention结构来学习序列前后的相关性。\n在transformer中仅使用self-attention机制来学习序列中不同元素之间的关系。\n实现 使用self-attention和full connect实现。\n编码器的实现中，使用若干个块，每个块包括一个multi-head attention层和一个全联接的feed foward层，其中每一层都引入了残差连接和正规化，构成$LayerNorm(x + Sublayer(x))$的结构。\n解码器的实现中，同样使用若干个块，每个块为编码器的基本块之前加上一个masked multi-head attention结构。同时将上一时刻的输出作为下一个时刻的输入，使得输出仅由之前的输入决定。\nScaled Dot-Product Attention的结构为将Q(uery)、K(ey)、V(alue)映射得到输出。输入为$d_k$维的Key向量和$d_v$维的Value向量，计算方法为矩阵相乘的结果缩放后再Softmax得到Value元素对应的权重，即$Attention(Q,K,V) = Softmax(\\frac{QK^T}{\\sqrt{d_k}})V$。使用矩阵乘法的实现计算更快。\nMulti-head Attnetion为多个Attention层组合得到。通过将V、K、Q线性投影到h个attention网络，将其结果通过concat组合之后再线性投影得到结果，即$MultiHead(Q,K,V) = Concat(head_1,hed_2…)W^O$，其中$head_i = Attention(QW^Q_i, KW^K_i, VW^V_i)$。\n注意解码器的Q来自解码器上一输出经过Masked Multi-Head Attention的结果，K、V来自编码器的输出。而编码器的Q、K、V来自上一层的输出。\n在Masked Multi-Head Attention中，SoftMax的输出被屏蔽（设置为$-\\infty$）。\n在Attention之后的Feed Forward网络中，使用两次ReLU得到$FFN(x) = max(0, xW_1+b_1)W_2+b_2$。\n对于输入，还需要进行embedding和positional encoding操作。使用learned embeddings将输入转化为向量。后者引入顺序和位置信息，使用$PE_{(pos,2i)} = sin(pos/10000^{2i/d_{model}})$和$PE_{(pos,2i+1)} = cos(pos/10000^{2i/d_{model}})$，其中pos为位置，i为维数。\n对于输出，使用线性转换（learned linear transformation）和softmax将输出转变为概率。这里的线性转换和输入的embeddings使用相同的权重（embedding中乘$\\sqrt{d_{model}}$,即向量规模的平方根）。\n评价 使用attention相比直接使用卷积或循环，计算复杂度比较低，同时更有利于并行计算。\n同时attention结构更有助于学习长句子，能学习到距离较远的信息。\n","date":1580805641,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580805641,"objectID":"5ebb063cc1b576d5dc5d5651be221bd3","permalink":"https://yangleisx.github.io/post/paper-transformer/","publishdate":"2020-02-04T16:40:41+08:00","relpermalink":"/post/paper-transformer/","section":"post","summary":"论文题目: Attention is All You Need\n开源项目地址:github\n","tags":["Deep Learning","Machine Translate"],"title":"【论文】Attention is All You Need","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"Deep Residual Learning for Image Recognition\n主要内容 构建了一种残差网络结构，有利于深度神经网络的训练，同时证明了该残差网络结构更容易优化并且在深度增加时仍能实现较高的准确率。同时训练了一个152层的网络用语图像识别。\n背景 传统的用于图像识别的DCNN通过增加深度可以提高识别性能。但是会出现梯度爆炸/消失的现象（vanishing/exploding gradient）。\n通过引入正则化等方法可以使深度网络实现收敛（SGD）。尽管可以收敛，但深度增加时会出现性能下降（degradation）。\n因此文中实现了一种残差网络deep residual learning，用来解决degradation问题。\n主要方式为：要学习得到H(x)，构造F(x)=H(x)-x并学习，最终得到F(x)+x即为所学习的目标。这里的+x可以使用短接（shortcut connection：跳过若干层的连接）来实现。这样的操作相当于恒等映射，没有引入新的参数或计算复杂度。\n实现 通过使用短接可以使得非线性的网络更好的拟合恒等映射，即令网络参数为0。\n因此构造的网络形如 $y = F(x,{W_i})+x$ 。使用两层网络和ReLU构造网络块得到 $F = W_2\\sigma(W_1x)$，其中 $\\sigma$表示ReLU，最终的输出为 $\\sigma{y}$。可以添加一个矩阵 $W_s$ 用于将F的输出和x的规模对齐。\n这里F的结构可以使用两层或三层网络，但是不能只有一层（实际上构成一个线性单元）。同时每一层的结构可以是全联接层也可以是卷积层。\n类比VGG-19网络，构造一个34层的深度卷积神经网络，以及其对应的深度残差网络。其中后河通过在前者的网络结构中每隔两层添加一个短路连接得到。\n评价 相对于普通的深度网络，深度残差网络更容易训练。\n相对于相同深度的网络，深度残差网络可以得到更高的准确度。\n当网络深度增加时，使用深度残差网络可以缓减错误率上升的情况。\n短路连接使用不同的方式（直接映射/规模不同时使用矩阵/全部使用矩阵）可以带来轻微的性能提升，但直接映射的复杂度比较低。\n","date":1580723174,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580723174,"objectID":"90e49ab48dbab06faaa8a4f22c4b1178","permalink":"https://yangleisx.github.io/post/paper-resnet/","publishdate":"2020-02-03T17:46:14+08:00","relpermalink":"/post/paper-resnet/","section":"post","summary":"Deep Residual Learning for Image Recognition\n","tags":["Deep Learning","Computer Vision"],"title":"【论文】Deep Residual Learning for Image Recognition","type":"post"},{"authors":["Lei Yang"],"categories":["实用工具"],"content":"TMUX 使用\n参考网上一些博客的教程1。同时参考了一些自主定制tmux功能的教程2。\n仅用于使用参考。\n关键概念 会话 session：用户和终端的交互。允许创建多个会话，关闭时内部进程不会终止，允许再次进入，直至被终止。\n窗口 window：每个会话可以创建多个窗口，可以相互切换。\n窗格 pane：每个窗口可以创建多个窗格，用于同时处理多个命令行界面。\n前缀：所有操作的快捷键要求以ctrl+b启动。\n安装和启动 使用对应平台的包管理工具直接安装\n# 启动第一个会话 $ tmux # 查看快捷键 $ tmux list-keys # 查看命令 $ tmux list-commands # 查看会话信息 $ tmux info 会话管理 功能 命令 快捷键 注意 创建会话 tmux new -s \u0026lt;name\u0026gt; 默认会话名为基于0的数字 分离会话 tmux detach ctrl+b d 会话和进程在后台运行 查看会话 tmux ls ctrl+b s 查看被分离的会话 接入会话 tmux attach -t \u0026lt;name\u0026gt; 杀死会话 tmux kill-session -t \u0026lt;name\u0026gt; 建议在会话内部使用exit 切换会话 tmux switch -t \u0026lt;name\u0026gt; 重命名会话 tmux rename-session -t \u0026lt;name\u0026gt; \u0026lt;new name\u0026gt; ctrl+b $ 窗格操作 功能 命令 快捷键 注意 上下划分 tmux split_window ctrl+b \u0026#34; 左右划分 tmux split_window -h ctrl+b % 移动光标 tmux select-pane -[UDLR] ctrl+b 方向键 参数表示上下左右移动 交换窗格位置 tmux swap-pane -[UDLR] ctrl+b [{ } ctrl+o alt+o] 参数表示上下左右移动交换 切换窗格 ctrl+b [o;] 参数表示按编号上下移动 关闭窗格 ctrl+b x 也可以在窗格内使用exit 窗格拆分为窗口 ctrl+b ！ 调整窗格大小 ctrl+b ctrl+方向键 查看窗格序号 ctrl+b q 窗口操作 功能 命令 快捷键 注意 创建窗口 tmux new-window -n \u0026lt;name\u0026gt; ctrl+b c 切换窗口 tmux select-window -t \u0026lt;name\u0026gt; 重命名窗口 tmux rename-window \u0026lt;name\u0026gt; ctrl+b , 为当前窗口重命名 切换窗口 ctrl+b [pn] 表示按编号上下切换 切换窗口 ctrl+b \u0026lt;number\u0026gt; 切换到指定窗口 选择窗口 ctrl+b w 阮一峰的日志 ↩︎\nTmux教程——打造完美的Linux终端 ↩︎\n","date":1580717096,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580717096,"objectID":"ed0245509242521de69530ded7047674","permalink":"https://yangleisx.github.io/post/tmux/","publishdate":"2020-02-03T16:04:56+08:00","relpermalink":"/post/tmux/","section":"post","summary":"TMUX 使用\n参考网上一些博客的教程1。同时参考了一些自主定制tmux功能的教程2。\n仅用于使用参考。\n","tags":["tmux"],"title":"TMUX 使用方式简单记录","type":"post"},{"authors":["Lei Yang"],"categories":["论文阅读"],"content":"论文笔记:Sequence to Sequence Learning with Neural Networks\n主要内容 使用一个深度LSTM网络将输入序列映射到固定长度的向量，再使用另一个深度LSTM网络将该向量映射（decode）到目标序列。\n背景 DNN在语音识别和视觉识别领域有非常好的效果，但是仅能用于输入和输出可以化为（encode）相同的固定规模（known and fixed）的向量。很多实际问题中输入和输出需要用未知长度的向量表示。\nLSTM可以在具有长期时间相关性（long range temporal dependencies）的数据中具有比较好的学习效果，因此用于在输入序列和相应的输出序列之间进行学习。\n同时通过在训练中反转输入序列引入短期依赖便于训练和优化。\n实现方式 原理 使用单个RNN由给定输入序列$(x_1,x_2,…,x_t)$计算输出序列$(y_1,y_2,…,y_t)$的方法如下：\n$h_t = sigm(W^{hx}x_t + W^{hh}h_{t-1})$、$y_t = W^{yh}h_t$。但是并不能用于不同长度的输入和输出序列。\n因此使用两个LSTM取代两个RNN来实现长期时间相关性的学习。\n在LSTM中使用条件概率的计算方法如下：\n$p(y_1,…,y_{T’}|x_1,…,x_T) = \\prod_{t=1}^{T’}p(y_t|v,y_1,…,y_{t-1})$，其中v是输入序列的一种表示。\n具体实现中，==使用两个深度LSTM网络，每个网络具有4层，用于训练的输入序列反转。==\n每个LSTM通过最大化对数几率进行训练，目标函数为$\\frac{1}{|S|}\\sum_{(T,S)\\in \\mathbb{S}} logp(T|S)$，其中$\\mathbb{S}$为训练集。\n预测时依据$\\hat{T} = arg max_{\\mathbf{T}} p(T|S)$，使用自左向右的Beam Search算法1得到翻译结果。\n输入序列反转后，训练的性能提高（原文使用“最小时滞 minimal time lag”加以解释：输入序列和输出序列的开头几个单词的距离减小）。可以认为输出序列的前半部分正确率较高而后半部分表现比较差。\n实现 使用WMT\u0026#39;14 英语-法语数据库进行训练。\n每个LSTM网络有4层，每层1000个单元，每个数据使用1000维张量表示。\n输入词汇量160000，输出词汇量80000。输出时使用8000输入的softmax。共有384M参数。\n为了防止梯度爆炸，每一个batch训练结束后对梯度正规化。\n评价 结果 训练结果使用BLEU打分，在WMT‘14数据库上得到37.0分\n结果评价 使用深度LSTM网络实现的sequence到sequence模型在机器翻译问题上取得了不错的效果。\n其在较长的句子上性能比较好。并且可以处理主动语态和被动语态。\n参考 Beam Search ↩︎\n","date":1580653573,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580653573,"objectID":"f86e2b6a0fa5443d1e142cb88535d2ef","permalink":"https://yangleisx.github.io/post/paper-seq2seq/","publishdate":"2020-02-02T22:26:13+08:00","relpermalink":"/post/paper-seq2seq/","section":"post","summary":"论文笔记:Sequence to Sequence Learning with Neural Networks\n","tags":["Deep Learning","Machine Translate"],"title":"【论文】Sequence to Sequence Learning with Neural Networks","type":"post"},{"authors":["Lei Yang"],"categories":["代码学习"],"content":"使用Verilo HDL设计FSM并在MacOS下仿真和生成状态图\nVerilog课程大作业有一个题要求设计FSM并生成状态图。按要求是使用ModelSIM，但是一方面配置Win7并使用ModelSIM太烦了，另一方面由于设计中为了更好的可读性，没有使用ModelSIM要求的可综合的编程规范（我猜大概是这个原因），所以使用ModelSIM的FSM View并不能生成想要的状态图，于是在MacOS中探索了FSM仿真和状态图的生成。\nFSM编写 使用FSM监测0110和1101序列，其中时钟下降沿触发，同步复位。代码如下\nmodule seq_detect(output reg flag, input din, clk, rst_n); reg [8:0] state; parameter IDLE = 9\u0026#39;b0_0000_0001, A0 = 9\u0026#39;b0_0000_0010, A1 = 9\u0026#39;b0_0000_0100, A2 = 9\u0026#39;b0_0000_1000, A3 = 9\u0026#39;b0_0001_0000, B0 = 9\u0026#39;b0_0010_0000, B1 = 9\u0026#39;b0_0100_0000, B2 = 9\u0026#39;b0_1000_0000, B3 = 9\u0026#39;b1_0000_0000; always @(negedge clk) begin if (!rst_n ) begin state \u0026lt;= IDLE; flag \u0026lt;= 1\u0026#39;b0; end else begin case(state) IDLE: if(din) begin state \u0026lt;= A0; flag \u0026lt;= 1\u0026#39;b0; end else begin state \u0026lt;= B0; flag \u0026lt;= 1\u0026#39;b0; end A0: if(din) begin state \u0026lt;= A1; flag \u0026lt;= 1\u0026#39;b0; end else begin state \u0026lt;= B0; flag \u0026lt;= 1\u0026#39;b0; end A1: if(din) begin state \u0026lt;= A1; flag \u0026lt;= 1\u0026#39;b0; end else begin state \u0026lt;= A2; flag \u0026lt;= 1\u0026#39;b0; end A2: if(din) begin state \u0026lt;= A3; flag \u0026lt;= 1\u0026#39;b1; end else begin state \u0026lt;= B0; flag \u0026lt;= 1\u0026#39;b0; end A3: if(din) begin state \u0026lt;= B2; flag \u0026lt;= 1\u0026#39;b0; end else begin state \u0026lt;= B0; flag \u0026lt;= 1\u0026#39;b0; end B0: if(din) begin state \u0026lt;= B1; flag \u0026lt;= 1\u0026#39;b0; end else begin state \u0026lt;= B0; flag \u0026lt;= 1\u0026#39;b0; end B1: if(din) begin state \u0026lt;= B2; flag \u0026lt;= 1\u0026#39;b0; end else begin state \u0026lt;= B0; flag \u0026lt;= 1\u0026#39;b0; end B2: if(din) begin state \u0026lt;= A1; flag \u0026lt;= 1\u0026#39;b0; end else begin state \u0026lt;= B3; flag \u0026lt;= 1\u0026#39;b1; end B3: if(din) begin state \u0026lt;= A3; flag \u0026lt;= 1\u0026#39;b1; end else begin state \u0026lt;= B0; flag \u0026lt;= 1\u0026#39;b0; end default: begin state \u0026lt;= IDLE;flag \u0026lt;= 1\u0026#39;b0; end endcase end end endmodule 仿真 在macOS使用icarus-Verilog仿真器和Scansion查看波形。测试台模块如下：\n`include \u0026#34;seq_detect.v\u0026#34; `timescale 10ns/ 1ns module tb_seq_detect(); wire p_flag; reg p_din, p_clk, p_rst_n; reg [35:0] data = 36\u0026#39;b0000_1100_0010_0110_1001_1011_0010_0001_1101; seq_detect dec(.flag(p_flag), .clk(p_clk), .din(p_din), .rst_n(p_rst_n)); initial begin p_clk = 1\u0026#39;b1; forever #5 p_clk = ~p_clk; end integer k; initial begin p_rst_n = 1\u0026#39;b0; p_din = 1\u0026#39;bx; #7 p_rst_n = 1\u0026#39;b1; for(k = 0; k \u0026lt; 36; k = k + 1) begin #10; p_din = data[35]; data = data \u0026lt;\u0026lt; 1; end #20 $finish; end initial begin $monitor($time, \u0026#34; rst = %b, din = %b, flag = %b\u0026#34;, p_rst_n, p_din, p_flag); $dumpfile(\u0026#34;tb_seq_detect.vcd\u0026#34;); $dumpvars(0, tb_seq_detect); end endmodule 仿真步骤如下，可以得到Monitor输出和vcd波形文件\niverilog tb_seq_detect.v vvp a.out open -a Scansion tb_seq_detect.vcd 生成状态图 可以使用Graphviz工具根据dot文件生成状态图。\ndot文件的基本格式如下，即定义图的边以及标签。\ndigraph fsm { \u0026#34;IDLE/flag=0\u0026#34; -\u0026gt; \u0026#34;A0=1/flag = 0\u0026#34; [ label = \u0026#34;0\u0026#34; ] \u0026#34;IDLE/flag=0\u0026#34; -\u0026gt; \u0026#34;B0=0/flag=0\u0026#34; [ label = \u0026#34;0\u0026#34; ] \u0026#34;A0=1/flag = 0\u0026#34; -\u0026gt; \u0026#34;A1=11/flag=0\u0026#34; [ label = \u0026#34;0\u0026#34; ] \u0026#34;A0=1/flag = 0\u0026#34; -\u0026gt; \u0026#34;B0=0/flag=0\u0026#34; [ label = \u0026#34;0\u0026#34; ] \u0026#34;A1=11/flag=0\u0026#34; -\u0026gt; \u0026#34;A1=11/flag=0\u0026#34; [ label = \u0026#34;0\u0026#34; ] \u0026#34;A1=11/flag=0\u0026#34; -\u0026gt; \u0026#34;A2=110/flag=0\u0026#34; [ label = \u0026#34;0\u0026#34; ] \u0026#34;A2=110/flag=0\u0026#34; -\u0026gt; \u0026#34;A3=1101/flag=1\u0026#34; [ label = \u0026#34;0\u0026#34; ] \u0026#34;A2=110/flag=0\u0026#34; -\u0026gt; \u0026#34;B0=0/flag=0\u0026#34; [ label = \u0026#34;0\u0026#34; ] \u0026#34;A3=1101/flag=1\u0026#34; -\u0026gt; \u0026#34;B2=011/flag=0\u0026#34; [ label = \u0026#34;0\u0026#34; ] \u0026#34;A3=1101/flag=1\u0026#34; -\u0026gt; \u0026#34;B0=0/flag=0\u0026#34; [ label = \u0026#34;0\u0026#34; ] \u0026#34;B0=0/flag=0\u0026#34; -\u0026gt; \u0026#34;B1=01/flag=0\u0026#34; [ label = \u0026#34;0\u0026#34; ] \u0026#34;B0=0/flag=0\u0026#34; -\u0026gt; \u0026#34;B0=0/flag=0\u0026#34; [ label = \u0026#34;0\u0026#34; ] \u0026#34;B1=01/flag=0\u0026#34; -\u0026gt; \u0026#34;B2=011/flag=0\u0026#34; [ label = \u0026#34;0\u0026#34; ] \u0026#34;B1=01/flag=0\u0026#34; -\u0026gt; \u0026#34;B0=0/flag=0\u0026#34; [ label = \u0026#34;0\u0026#34; ] \u0026#34;B2=011/flag=0\u0026#34; -\u0026gt; \u0026#34;A1=11/flag=0\u0026#34; [ label = \u0026#34;0\u0026#34; ] \u0026#34;B2=011/flag=0\u0026#34; -\u0026gt; \u0026#34;B3=0110/flag=1\u0026#34; [ label = \u0026#34;0\u0026#34; ] \u0026#34;B3=0110/flag=1\u0026#34; -\u0026gt; \u0026#34;A3=1101/flag=1\u0026#34; [ label = \u0026#34;0\u0026#34; ] \u0026#34;B3=0110/flag=1\u0026#34; -\u0026gt; \u0026#34;B0=0/flag=0\u0026#34; [ label = \u0026#34;0\u0026#34; ] } 使用Graphviz生成文件具体命令如下\ndot -Tpng fsm.dot \u0026gt; fsm.png circo -Tpdf fsm.dot \u0026gt; fsm.pdf 需要注意Graphviz的输出默认输出到stdcout，因此需要重定向写入到文件。其中-T可以指定输出文件的格式。而dot和circo分别为不同的状态图风格，具体的使用方法可以参见man dot。\n部分内容如下(详细内容自行查看)：\nNAME dot - filter for drawing directed graphs neato - filter for drawing undirected graphs twopi - filter for radial layouts of graphs circo - filter for circular layout of graphs fdp - filter for drawing undirected graphs sfdp - filter for drawing large undirected graphs patchwork - filter for squarified tree maps osage - filter for array-based layouts ... Traditionally, Graphviz supports the following: -Tdot (Dot format containing layout information), -Txdot (Dot format containing complete layout information), -Tps (PostScript), -Tpdf (PDF), -Tsvg -Tsvgz (Structured Vector Graphics), -Tfig (XFIG graphics), -Tpng (png bitmap graphics), -Tgif (gif bitmap graphics), -Tjpg -Tjpeg (jpeg bitmap graphics), -Tjson (xdot information encoded in JSON), ... ","date":1574565274,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574565274,"objectID":"78262099dc764c2caf41e2f00d0db0e6","permalink":"https://yangleisx.github.io/post/verilog-fsm/","publishdate":"2019-11-24T11:14:34+08:00","relpermalink":"/post/verilog-fsm/","section":"post","summary":"使用Verilo HDL设计FSM并在MacOS下仿真和生成状态图\n","tags":["Verilog HDL","Graphviz"],"title":"使用Verilog设计FSM并生成状态图","type":"post"},{"authors":["Lei Yang"],"categories":["代码学习"],"content":"使用Verilog设计电路的一些思路\n注意事项:\n时序逻辑电路使用非阻塞赋值\n组合逻辑电路使用阻塞赋值\n组合逻辑电路 概念：输出仅由当前的输入决定 注意：不能蕴含触发器的逻辑，即==不具有记忆功能==（case语句的default子句、连续赋值语句、电平敏感的always语句） 常见的组合逻辑电路：复用器、译码器、编码器、三态缓冲器、比较器、加法器、乘法器。 实现方法： 使用assign连续赋值语句（数据流级）和==电平敏感==的always行为语句（行为级） 使用always引导的语句块实现对于中间变量的逻辑运算 使用assign引导的连续赋值语句实现==简单变换和多路输出==（如果有的话） 注意：always的使用的中间变量为reg型，assign和子模块使用的中间变量为wire型 设计思路： 给定==电路原理图==：使用门原语和模块实例 给定布尔方程：使用连续赋值语句和==布尔运算==（真值表得到布尔方程） 给定模块功能/IO（==真值表==）：使用行为级描述（if/case配合真值表） 可采用的设计模式： assign连续赋值语句 + 条件表达式（？：） + 布尔运算 always语句块 + 条件表达式（？：） always语句块 + 条件语句（if/case） assign连续赋值语句 + 函数（function [automatic]）可以在数据流语句中引入行为级语句逻辑 always语句块 + 函数（function [automatic]） always语句块 + 任务（task [automatic]） 建议不直接修改输出变量，而是使用中间变量，在输出时使用assign实现（综合好像能得到一个buf） 时序电路 概念：输出由当前输入和内部的状态决定 注意：具有记忆功能，内部包含==锁存器latch（电平敏感）和触发器flip-flop（边沿敏感）==等储存器件，case语句的default子句可以为空 常见时序电路：锁存器latch、触发器flip-flop 实现方法： 使用always引导的语句块（电平敏感或边沿敏感）实现逻辑运算 使用assign引导的连续赋值语句实现简单变换和多路输出（例如assign qbar=～q） ==不能使用门原语==，门原语定义的时序电路不可综合（例如使用两个与非门实现的RS锁存器） 时序逻辑： 同步控制（复位/置位）： 只有在时钟信号的有效跳变沿状态才能改变 always的事件控制列表没有复位/置位信号 语句块中先检查复位/置位信号，然后执行其他逻辑。使用嵌套的if-else可以控制复位/置位/输入逻辑的优先级（==复位\u0026gt;置位\u0026gt;其他逻辑==） 异步控制（复位/置位）： 复位/置位信号激活时立即响应 always的控制列表中包括时钟边沿和复位/置位信号边沿 语句块中先检查是时钟触发的还是复位/置位信号触发的，并执行相应的逻辑。使用嵌套的if-else指定优先级（==复位\u0026gt;置位\u0026gt;其他逻辑==） 可综合电路 关键：使用Verilog HDL中的可综合子集 可综合的Verilog HDL结构 端口：input, inout, output 参数：parameter 模块定义：module 信号和变量：wire, reg, tri 允许向量 实例调用：module instance primitive gate instance 函数任务：function, task 不考虑时序结构 过程：always, if, then, else, case ==不支持initial== 过程块：begin, end, named block, disable 数据流：assign ==不考虑#延迟信息== 循环：for, while, forever 需要包含@(posedge clock)或@(negedge clock) 使用复位机制取代initial进行初始化 赋值 组合逻辑电路使用阻塞赋值= 时序电路使用非阻塞赋值\u0026lt;= 同时描述时序和组合逻辑使用非阻塞赋值\u0026lt;= 编码风格 有意义的信号和变量名 ==避免混合使用上升沿触发和下降沿触发== 使用圆括号而不是运算优先级 条件语句中说明所有的可能情况 不要多个always对同一变量赋值 常见改错题思路 变量类型错误 注意input和output的端口类型检查 变量位宽 赋值方式 阻塞赋值和非阻塞赋值 敏感量列表 always的敏感量列表是电平触发还是边沿触发 位运算/逻辑运算 ","date":1573913499,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573913499,"objectID":"c9f19ff5d2a029d117c07257fc6434c7","permalink":"https://yangleisx.github.io/post/verilog-design/","publishdate":"2019-11-16T22:11:39+08:00","relpermalink":"/post/verilog-design/","section":"post","summary":"使用Verilog设计电路的一些思路\n","tags":["Verilog HDL"],"title":"Verilog电路设计思路","type":"post"},{"authors":["Lei Yang"],"categories":["代码学习"],"content":"简单记录一下verilog的语法，用于日后复习或者参考。\n模块框架 module 模块名 (端口列表); // 端口声明 input input_port; output output_port; // 参数声明 parameter param; // 数据流语句 assign a = b \u0026amp; c; // 模块实例和门原语 subModule Mod1(port1, port2); subModule Mod2(.port1(PORT1),.port2(PORT2)); nand (out, in1, in2); // 过程语句块 always @(*) 过程语句 initial 过程语句 endmodule 基本概念 数字声明：\u0026lt;size\u0026gt;’\u0026lt;base format\u0026gt;\u0026lt;number\u0026gt;\n可以在’之后加s表示有符号数\n建议使用_分割为四个二进制数一组\n使用[begin:end]选择向量的部分位\n使用{a,b,c[3:0]}表示变量拼接\n位宽大的数向位宽小的数赋值：获得低位并截断\n位宽小的数向位宽大的数赋值：高位补0。例如reg[4:0]a;a = 2’bx;得到00xx。\n位扩展时根据最高位扩展x和z。例如4’bx0和4’bz1得到xxx0和zzz1。\n常用系统函数：\n$ time 返回仿真时间\n$ display 显示输出\n$ monitor 监控值的变化，通常第一个参数为$ time，格式类似printf\n$finish 结束仿真\n结构域描述 子模块连接 端口连接规则：\n输入：外界net或reg，内部net 输出：外界net，内部net或reg 双向：外界net，内部net 允许按端口列表顺序相连或者按名字相连 模块也可以定义成实例数组\n通常设计测试台包括四个部分：定义外部与端口相连的变量（通常输入用reg输出用wire），定义模块并相连，initial初始化并控制驱动信号，显示monitor信息等。\n门级建模 门原语属于模块一级，相当于并发语句。\n只能驱动wire型的变量。\nand/or门 包括and,nand,or,nor.xor,xnor六种\n一个输出端和多个输入端，第一个参数为输出端\n真值表中有x/z时，输出通常为x\nbuf/not门 包括buf,not两种\n一个输入端和多个输出端，最后一个参数为输入端\n三态门 包括bufif1,bufif0,notif1,notif0四种\n控制信号是最后一个参数，输入信号是倒数第二个参数\n***要求：***当控制信号关断时，输出信号必须为z。\n控制信号为x/z时，或者输入信号为x/z时，输出通常为x。\n延迟指定 门原语后使用#(上升 下降 关断)制定\n使用#(最小:典型:最大 最小:典型:最大 最小:典型:最大)指定延迟\n上升延迟指变为1，下降延迟指变为0，关断延迟指变为z\n行为域描述 数据流级 连续赋值 连续赋值语句assign，左值一定为net类型\n总是激活，时刻监控，描述组合逻辑\n普通延迟 在assign之后使用#指定延迟\n惯性延迟右端信号保持的持续时间必须大于延时宽度才能使左值改变\n线网延迟 声明wire变量时使用#指定线网延迟\n实际延迟为线网延迟和赋值语句延迟之和\n信号保持的时间要大于两者的最大值\n操作符 向量参与逻辑运算时，首先进行缩减或操作得到逻辑值，使用逻辑值运算\n逻辑等价(== !=)对于含有x/z的操作数结果为x。\ncase等价(=== !==)对于含有x/z的操作数严格的逐位比较。\n三目条件运算符（cond）？expr1:expr2；若cond为1或0，则分别执行expr1和expr2。若cond为x，则诸位比较expr1和expr2，相同的位得到该位的值，不同的位得到x。\n行为级 过程语句块中绝对不能出现连续赋值语句\n过程语句 主要有两种过程语句initial和always\n相互不能嵌套，都是模块级的语句\n要求：initial用于仿真，always用于设计\n不要在不同的语句块中对同一变量进行操作（过程语句的并发性）\ninitial 从时刻0开始执行，只执行一次 所有的initial语句块并发执行 可以使用initial foreveer实现always的功能 always 从时刻0开始执行，无限循环 可以定义局部变量，但是不能定义的同时赋初值 可以用always @(*)实现assign的功能 语句块 不建议两种块混合使用\n可以在begin/fork后用：为块命名\n可以使用disable禁止块的运行\n顺序块 begin-end 顺序执行，延迟是相对于上一语句结束时 并行块 fork-join 并发执行，延迟是相对于整个块 时序控制 基于延迟 常规延迟： #delay a = b; 遇到该语句时，等待delay时间后执行 内嵌延迟 a = #delay b+c 遇到该语句时计算右边，等待delay时间后赋值 零延迟： #0 表示在当前时间步结束时执行 基于事件 常规事件控制（边沿触发） @(posedge clock)、@(negedge clock)、@(clock) 表示正向跳变、反向跳变、值改变 数组中任意一个值变化 OR事件控制 @(cond1 or cond2 or cond3)三个条件满足其一 @(*)语句块中任意元素值改变 命名事件 定义一个事件event aEvent; 满足条件触发事件-\u0026gt; aEvent; 事件触发执行always @(aEvent) 电平敏感（电平触发） 等待条件为真时 wait(cond)\ncond为数组时，使用逻辑值判断\n过程控制 只能用在过程语句块中，不能用于模块一级\nif…else… 多条语句使用begin-end组成一块 case…cond1:…default…endcase 建议必须添加default 逐位比较 casex…cond1:..default…endcase 候选式使用x和z表示无关值 casez…cond1:..default…endcase 候选式使用z表示无关值 while(condition) for(count = 0; count \u0026lt; 128;count = count+1) repeat(times) 以上三种都要在外部声明reg型的循环变了 forever 遇到$finish停止 可以被disable关闭 赋值语句 仅能实现对寄存器的操作\n要求：时序逻辑电路使用非阻塞赋值，组合逻辑电路使用阻塞赋值\n严禁：在always块中混合使用阻塞和非阻塞\n顺序块中的非阻塞赋值和并行块中的阻塞赋值的效果类似，推荐前者。\n阻塞赋值 串行块中，按序执行，有延迟时停止 并行块中，并发执行 非阻塞赋值 串行块中，并发执行，不影响后面的语句 内嵌赋值语句被延迟到在目标时间步结束时执行赋值 并行块中，并发执行 任务和函数 定义在模块内部\n内部不能出现always或initial，只有行为语句\n函数（相当于同名的reg变量 要声明位宽） 可以调用函数，不可以调用任务，出现在assign、always、initial中 遇到即执行，一定不包含延迟和时序控制 返回一个值，不能有output 任务 可以调用函数和任务，出现在initial、always中 可以延迟或时序控制 不返回值，有多个output 行为级语句，处理reg型变量 生成块 在模块一级，使用if，case，while等过程控制来控制门原语、模块调用、数据流赋值等语句生成 使用临时变量genvar控制 使用generate和endgenerate表示开始和结束 循环生成时内部的begin-end块需要命名，以便使用层次命名访问 UDP用户定义原语 格式 primitive upd_and(output y, input a); table // a b : y 0 0 : 0; 0 1 : 0; 1 0 : 0; 1 1 : 1; endtable endprimitive 可以使用？表示无关匹配 ","date":1571754571,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571754571,"objectID":"a1006419e3015b69778e6d806a386a91","permalink":"https://yangleisx.github.io/post/verilog-grammar/","publishdate":"2019-10-22T22:29:31+08:00","relpermalink":"/post/verilog-grammar/","section":"post","summary":"简单记录一下verilog的语法，用于日后复习或者参考。\n","tags":["Verilog HDL"],"title":"Verilog HDL语法参考","type":"post"},{"authors":["Lei Yang"],"categories":["实用工具"],"content":"常见的服务的iptables规则设置\n注意：配置规则时注意协议的双向性\n在安全性更高的系统中可以为每一条命令具体指定双方的IP地址。\n基本设置 使用脚本配置规则时要首先清空所有规则\n同时建议将默认规则设置为DROP，即使用白名单\n# flush all rules iptables -F -t filter iptables -F -t mangle iptables -F -t nat # set default rules iptables -P INPUT DROP iptables -P OUTPUT DROP iptables -P FORWARD DROP HTTP服务 http服务默认使用tcp协议的80端口\n# I.open http port:80 iptables -t filter -A INPUT -p tcp --dport 80 -j ACCEPT iptables -t filter -A OUTPUT -p tcp --sport 80 -j ACCEPT ping命令 ping命令使用icmp协议\n发送方发送icmp-type=8，即icmp-request， 接收方发送icmp-type=0，即icmp-reply\n注意方向性，可以只放行一个方向的ping命令\n# II.open ping # 1. open outbound iptables -t filter -I INPUT -p icmp --icmp-type 0 -j ACCEPT iptables -t filter -I OUTPUT -p icmp --icmp-type 8 -j ACCEPT # 2. open inbound iptables -t filter -I INPUT -p icmp --icmp-type 8 -j ACCEPT iptables -t filter -I OUTPUT -p icmp --icmp-type 0 -j ACCEPT FTP服务 FTP可以按主动模式或者被动模式运行，客户端登录时指定运行模式\n统一使用TCP协议，使用21端口发送控制命令。\n抓包分析可以发现，FTP的连接和传输过程主要分为三部分：控制连接建立和命令传输，文件传输，控制端口释放。 因此在iptables规则的设计要根据FTP协议的工作方式确定。\n主动模式 使用20端口传输数据。\n# III.open ftp active # 1. open control port:21 iptables -t filter -A INPUT -p tcp --dport 21 -j ACCEPT iptables -t filter -A OUTPUT -p tcp --sport 21 -j ACCEPT # 2. open data port:20 iptables -t filter -A INPUT -p tcp --dport 20 -j ACCEPT iptables -t filter -A OUTPUT -p tcp --sport 20 -j ACCEPT 被动模式 使用随机生成的端口发送数据，端口范围可以在/etc/vsftpd.conf指定。\n因此要使用状态监测来放行相关的端口。\n# IV.open ftp passive # 1. open control port:21 iptables -A INPUT -p tcp --dport 21 -j ACCEPT iptables -A OUTPUT -p tcp --sport 21 -j ACCEPT # 2. open data port:random port\u0026gt;=1024 iptables -A INPUT -p tcp --sport 1024: --dport 1024: -m state --state NEW,RELATED,ESTABLISHED -j ACCEPT iptables -A OUTPUT -p tcp --sport 1024: --dport 1024: -m state --state RELATED,ESTABLISHED -j ACCEPT SSH连接 默认使用TCP协议的22端口。\n同样可以只放行一个方向的数据。\n# V. open ssh port:22 # 1. open ssh inbound iptables -A INPUT -p tcp --dport 22 -j ACCEPT iptables -A OUTPUT -p tcp --sport 22 -m state --state ESTABLISHED,RELATED -j ACCEPT # 2. open ssh outbound iptables -A OUTPUT -p tcp --dport 22 -j ACCEPT iptables -A INPUT -p tcp --sport 22 -m state --state ESTABLISHED,RELATED -j ACCEPT ","date":1571552692,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571552692,"objectID":"1b6cd8ee969ba564d1919fa8a62c9508","permalink":"https://yangleisx.github.io/post/iptables-rules/","publishdate":"2019-10-20T14:24:52+08:00","relpermalink":"/post/iptables-rules/","section":"post","summary":"常见的服务的iptables规则设置\n","tags":["Linux","iptables"],"title":"iptables常用规则","type":"post"},{"authors":["Lei Yang"],"categories":["实用工具"],"content":"使用较低配置的orange pi作为树莓派的替代品\n可以在内网搭建web服务器，ftp服务器等用于学习\n基本配置 下载镜像 最开始使用ubuntu core for orange pie 但是ubuntu SSO账号设置有问题 总是密码错误无法登陆\n后来下载armbian镜像 MacOS端使用软件Etcher写入内存卡中\n开机 插卡 上电 使用网线与路由器连接 等灯常亮 查看mac地址和IP地址\n连接 armbian默认的用户为root 密码为1234\n使用ssh连接 根据引导更改密码 创建新的用户 设置密码\n根据指示 使用armbian-config设置Wi-Fi\n更改/etc/sudoers文件为自己的用户设置管理员权限（可选）\n更新软件 apt update 和 apt upgrade\n在主机设置 ssh-copy-id username@address 并输入密码设置ssh公钥免密登陆\n基本软件安装 常用软件大多系统内置 例如vim，make，g++等\n还需要安装一些常用的软件(自选)：\n基本软件：ssh tree less vnc git\nweb服务器：apache2/nignx\nMySQL数据库：mysql-server mysql-client libmysqlclient-dev\nPHP支持：php\n项目编译：cmake make\nJAVA环境：default-jre default-jdk\nPython环境：python python3 python3-pip virtualenv\nNodeJS环境：npm\n…\nmysql需要切换至root登陆 然后添加新用户并发放权限\nCREATE USER ‘username’@’localhost’ IDENTIFIED BY ‘passwd’\nGRANT ALL ON *.* TO ‘username’@’localhost’\nSET PASSWORD FOR ‘username’@’localhost’ = PASSWORD(“passwd”)\nSET PASSWORD = PASSWORD(“passwd”)\n路由器设置 将Wi-Fi动态DHCP设置为静态IP地址分发 确定一个合适的IP地址\n设置端口转发 将路由器的22端口转发板子的22端口用于外网ssh连接\n将路由器的80端口转发板子的80端口用于外网对web服务器的访问\n或者直接使用路由器的DMZ功能\n","date":1571136416,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571136416,"objectID":"060ee18b01d4370b24de91379fc6aaef","permalink":"https://yangleisx.github.io/post/orange-pi/","publishdate":"2019-10-15T18:46:56+08:00","relpermalink":"/post/orange-pi/","section":"post","summary":"使用较低配置的orange pi作为树莓派的替代品\n可以在内网搭建web服务器，ftp服务器等用于学习\n","tags":["Linux","Orange Pi"],"title":"Orange Pi的使用","type":"post"},{"authors":["Lei Yang"],"categories":["实用工具"],"content":"iptables的使用方法简单记录.\n数据包的传递 发往本机 网卡接收 mangle的PREROUTING nat的PREROUTING（做DNAT转换） 路由判断本机/转发 mangle的INPUT filter的INPUT 到达应用程序 发往外部 生成数据，路由判断 mangle的OUTPUT nat的OUTPUT filter的OUTPUT mangle的POSTROUTING nat的POSTROUTING（SNAT转换） 转发 网卡接收 mangle的PREROUTING nat的PREROUTING 路由判断 mangle的FORWARD filter的FORWARD mangle的POSTROUTING nat的POSTROUTING（SNAT转换） 命令使用 命令格式\niptables -t TABLE [-operation] CHAIN [-matches ] -j TARGET 即主要内容五部分：表、操作、链、匹配、目标动作\nTABLE包括：filter，nat，mangle\nCHAIN包括：INPUT，OUTPUT，FORWARD，PREROUTING，POSTROUTING\nTARGET包括：ACCEPT、DROP、SNAT、DNAT\noperation包括：-A(ppend添加) -I(sert插入) -D(elete删除) -R(eplace替换) -L(ist显示所有) -P(默认策略) -X(删除链) -N(新建链) -F(清空规则) -Z(清空计数器)\nmatch包括：-p(rotocol协议) -s/d(源/目标IP) –s/dport(源/目标端口) -i/o(interface进出网络接口)\n","date":1570979497,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570979497,"objectID":"aa9a63ce348fc427e066cec293e355f9","permalink":"https://yangleisx.github.io/post/iptables/","publishdate":"2019-10-13T23:11:37+08:00","relpermalink":"/post/iptables/","section":"post","summary":"iptables的使用方法简单记录.\n","tags":["Linux","iptables"],"title":"iptables基础使用","type":"post"},{"authors":["Lei Yang"],"categories":["实用工具"],"content":"在MacOS上使用Icarus Verilog时实现编程语言接口PLI\n定义系统函数模块 // Icarus Verilog使用的头文件 # include \u0026lt;vpi_user.h\u0026gt; // 编译时函数 static int hello_compiletf(char* user_data) { return 0; } // 调用时函数 static int hello_calltf(char* user_data) { vpi_printf(\u0026#34;Hello, World!\\n\u0026#34;); return 0; } // 注册函数，注册编译时函数和调用时函数 void hello_register() { s_vpi_systf_data tf_data; tf_data.type = vpiSysTask; tf_data.tfname = \u0026#34;$hello\u0026#34;; tf_data.calltf = hello_calltf; tf_data.compiletf = hello_compiletf; tf_data.sizetf = 0; tf_data.user_data = 0; vpi_register_systf(\u0026amp;tf_data); } // 加载模块时运行函数 void (*vlog_startup_routines[])() = { hello_register, 0 }; 仿真加载PLI模块时，首先检查函数指针数组startup，用0作为数据结束符。\n接着运行startup中指定的函数，通常为register函数，注册对应的系统函数。\ncompiletf函数为vvp加载模块自动编译时执行，通常用于监测param参数状态。也可以留空。\ncalltf指函数为verilog中每次调用PLI执行的结果。\n注意 vpi_子程序是存取子程序(acc_)和实用子程序(tf_)的拓展集合。\n编译PLI模块 使用GCC编译 # 编译目标文件.o gcc -c -fpic hello.c # 编译得到模块文件.vpi gcc -shared -o hello.vpi hello.o -lvpi 前提：安装有vpi_user.h和vpi的动态链接库\n使用Icarus编译 # 编译得到.o和.vpi文件 iverilog-vpi hello.c 调用系统函数 在verilog中调用自定义系统函数\nmodule main; initial $hello; endmodule 运行系统仿真\n# 编译verilog文件得到仿真文件.vvp iverilog -ohello.vvp hello.v # 运行仿真 vvp -M. -mhello hello.vvp 参数-M指定搜索路径 在这里为当前文件夹\n参数-m指定系统函数模块名 在这里为hello\n","date":1570769786,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570769786,"objectID":"cba5cc301fc88d5f29193316e46ea6bf","permalink":"https://yangleisx.github.io/post/verilog-vpi/","publishdate":"2019-10-11T12:56:26+08:00","relpermalink":"/post/verilog-vpi/","section":"post","summary":"在MacOS上使用Icarus Verilog时实现编程语言接口PLI\n","tags":["Verilog HDL"],"title":"Verilog编程语言接口","type":"post"},{"authors":["Lei Yang"],"categories":["代码学习"],"content":"CSV是一种一行中使用逗号分隔的数据表格格式\n数据读取 直接读取 # 打开文件并读取 得到字符串 file = open(\u0026#34;name.csv\u0026#34;,\u0026#34;r\u0026#34;) data = file.read() # 切分成行 data_line = data.split(\u0026#34;\\n\u0026#34;) data_conp = [] # 每一行划分成list for line in data_line: data_conp.append(line.split(\u0026#34;,\u0026#34;)) 使用csv包读取 # 导入CSV库 import csv file = open(\u0026#34;name.csv\u0026#34;,\u0026#34;r\u0026#34;) # 获得reader对象 reader = csv.reader(file) # 每次调用返回一行数据 headline = next(reader) # 返回所有数据\u0026lt;list of list\u0026gt; data = list(reader) 通常情况下，数据表格中含有表头，需单独处理\n# 直接读取数据时要去掉表头 raw_data = list(reader) header = raw_data[0] data = raw_data[1:] for index, item in enumerate(header): print(index.item) ","date":1570258781,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1707032658,"objectID":"8de2a71dd86588ac0e613aeb3d51b45d","permalink":"https://yangleisx.github.io/post/python-csv/","publishdate":"2019-10-05T14:59:41+08:00","relpermalink":"/post/python-csv/","section":"post","summary":"CSV是一种一行中使用逗号分隔的数据表格格式\n","tags":["Python"],"title":"CSV数据处理","type":"post"},{"authors":["Lei Yang"],"categories":["代码学习"],"content":"使用方法类似于Matlab\n数据基于 class ’numpy.ndarray\u0026#39;\n也可以基于 class ’list\u0026#39;\n导入库 # 导入库 import matplotlib.pyplot as plt import numpy 数据的导入 # 基于ndarray的数据 x = np.array([1,2,3,4,5]) y = np.array([6,7,8,9,0]) # 基于list的数据 z = [1,4,3,5,6,7] 绘图 # 绘图函数的使用方法与Matlab相同 # 颜色/线型/标记的设置和Matlab相同 # 或者使用名值对指定绘图参数 # 折线图 plt.plot(x,y) # \u0026#39;r-x\u0026#39; # 红色 单实线 ‘x’标记 # linewidth = 5 # 线粗为5 # 条形图 plt.bar(x,y) # 火柴图 plt.stem(x,y) # 散点图 plt.scatter(x,y) # s = 40 # size # c = \u0026#39;red\u0026#39; # color # c = (0,0,0.87) # RGB color # c = y,cmap = plt.cm.Blues # 颜色映射 不同的值深度不同 # edgecolor=\u0026#39;none\u0026#39; # 数据点轮廓 图像设置 通常情况下可以理解为状态机参数的调整\n因此后面的语句会覆盖之前的代码\n坐标轴 # 设置x,y轴的显示范围 plt.xlim((-1,1)) plt.ylim((0,3)) # 也可以用axis设置 plt.axis([-1,1,0,3]) 图表标题 # 设置图表标题 pl.title(\u0026#34;title\u0026#34;) 坐标轴标签 plt.xlabel(\u0026#39;xname\u0026#39;) plt.ylabel(\u0026#39;yname\u0026#39;) # 设置字体 fontproperties=\u0026#39;SimHei\u0026#39; # 设置字号 fontsize=14 坐标轴刻度 # 设置坐标轴的刻度 # 使用numpy，设置-1到1，均分成5份 # 当范围大于xlim指定的范围时会扩展 plt.xticks(np.linespace(-1,1,5)) # 使用字符串list命名 plt.yticks([-5,0,5], [\u0026#34;negative\u0026#34;,\u0026#34;neutral\u0026#34;,\u0026#34;positive\u0026#34;]) # 可以设置标记刻度的样式 plt.tick_params(axis=\u0026#34;both\u0026#34;, labelsize=14) 四边边框设置 # 获得四边边框对象 ax = plt.gca() # 设置颜色，设置为none可以隐藏 ax.spines[\u0026#39;top\u0026#39;].set_color(\u0026#39;none\u0026#39;) # 设置坐标轴位置，可以设置横轴经过数据的0点 ax.spines[\u0026#39;bottom\u0026#39;].set_position((\u0026#39;data\u0026#39;,0)) # 设置坐标轴的位置，可以设置纵轴在最右端 ax.spines[\u0026#39;left\u0026#39;].set_position((\u0026#39;axes\u0026#39;,1)) # 设置坐标轴上标注的位置，可以设置在纵轴的右侧 ax.spines[\u0026#39;left\u0026#39;].set_ticks_position(\u0026#39;right\u0026#39;) 图例设置 # 方法一：在plot绘图时指定label的内容 lab_sin = \u0026#34;this is a sinesoidal wave\u0026#34; plt.plot(x,y,label = lab_sin) plt.legend() # 方法二：在plot绘图时获得句柄，在legend中指定内容 han1,=plt.plot(x,y) han2,=plt.plot(x,z) plt.legend(handles=[han1,han2], labels=[\u0026#34;y_values\u0026#34;,\u0026#34;z_values\u0026#34;]) # loc=\u0026#39;best\u0026#39; # 指定图例的位置,‘best’自动分配最佳位置 图像输出 # 显示图像 # 在plt.show()之前的部分会画在一张图里 没有plt.show()不画图 plt.show() # 修改图像的输出 plt.figure(figsize=(10,6)) # dpi = 128 # 屏幕分辨率 # 保存图像 plt.savefig(\u0026#34;file_name.png\u0026#34;) # bbox_inches=\u0026#39;tight\u0026#39; # 将图像边缘白边裁掉 ","date":1570244708,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570244708,"objectID":"54647862e78a79c2d5c24e1e256e710b","permalink":"https://yangleisx.github.io/post/python-matplotlib/","publishdate":"2019-10-05T11:05:08+08:00","relpermalink":"/post/python-matplotlib/","section":"post","summary":"使用方法类似于Matlab\n数据基于 class ’numpy.ndarray'\n也可以基于 class ’list'\n","tags":["Python","Matplotlib"],"title":"使用Matplotlib绘图","type":"post"},{"authors":["Lei Yang"],"categories":["实用工具"],"content":"这学期的Verilog课程要求使用ModelSim仿真软件。 实在不想再开一个win7的虚拟机了。 于是探索了一下如何在MacOS中进行Verilog的仿真和波形监测。\n环境搭建 仿真工具 # 使用icarus-verilog进行仿真 brew install icarus-verilog 波形工具 # 使用Scansion查看波形 brew cask install scansion 仿真过程 仿真 # 生成vvp仿真程序 # 默认生成a.out iverilog stimulus.v -o stimulus.vvp # 执行仿真 ./stimulus.vvp # 或者 vvp stimulus.vvp 波形观察 生成波形文件 需要在verilog文件中生成波形\ninitial begin // 指明文件名 $dumpfile(\u0026#34;stimulus.vcd\u0026#34;) // 指明监控的module，这里表示stimulus及下面的所有module $dumpvar(0,stimulus) /* * 如果stimulus只调用了一个counter模块 * $dumpvar(1, stimulus) * $dumpvar(0, stimulus.counter) * 两者等价 */ end 查看波形 使用命令行查看\n# 使用xCode的cmd-tools 在terminal中打开Scansion软件 open -a Scansion stimulus.vcd 或者直接在Scansion中打开vcd文件\n或者直接双击vcd文件\n","date":1570172298,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570172298,"objectID":"b9799477019a8873fe471b9071f73a7e","permalink":"https://yangleisx.github.io/post/verilog-macos/","publishdate":"2019-10-04T14:58:18+08:00","relpermalink":"/post/verilog-macos/","section":"post","summary":"这学期的Verilog课程要求使用ModelSim仿真软件。 实在不想再开一个win7的虚拟机了。 于是探索了一下如何在MacOS中进行Verilog的仿真和波形监测。\n","tags":["Verilog HDL"],"title":"Verilog on MacOSX","type":"post"},{"authors":["Lei Yang"],"categories":["实用工具"],"content":"简单了解了正则表达式在python和C++中的使用方法\n基本元素和规则 符号 含义 ^ 句首 $ 句尾 . 匹配单个字符 * 多次出现（$\\geq0$） + 多次出现（$\\geq1$) ? 零次或一次出现 {n,m} 表示匹配n-m次 \\ 匹配转义字符 () 匹配子串并获取 | 匹配两项之间的一个 / / 表示pattern匹配 [] 表示多个可选项 其中的^表示非 非打印字符的匹配 字符 含义 \\cx 控制字符control+x，这里的x必须是A-Z \\f 换页符号 \\n 换行符 \\r 回车键 \\s 空白字符 类似[\\f\\n\\r\\t\\v] \\S 非空白字符 \\t 制表符 \\v 垂直制表符 定位符 符号 含义 \\b 单词边界（单词和空格交界处） \\B 非单词边界 常用的匹配 匹配 含义 \\d 匹配一个数字 相当于[0-9] \\w 匹配一个字符 相当于[A-Za-z0-9_] 预查 符号 含义 (?:pattern) 匹配但是不获取（缓存） a(?=pattern) 匹配pattern之前的a a(?!pattern) 匹配后面没有pattern的a (?\u0026lt;=pattern)b 匹配前面有pattern的b (?\u0026lt;!pattern)b 匹配前面没有pattern的b 在各种环境中使用正则表达式 C++中使用正则表达式REGEX // 引入头文件 #include\u0026lt;regex\u0026gt; // 定义一个正则表达式 std::regex pattern(\u0026#34;([0-9]+)\u0026#34;); // 声明匹配结果变量,结果变量要和字符串形式相对应 std::match_results\u0026lt;const char*\u0026gt; cResult; // 简化定义std::cmatch std::match_results\u0026lt;std::string::const_iterator\u0026gt; sResult; // 简化定义std::smatch // 定义待匹配的字符串 char cStr[] = \u0026#34;hello\u0026#34;; std::string sStr = \u0026#34;123abc\u0026#34;; // 进行匹配 // regex_match(string, result, pattern) // 其中string可以是迭代器指明的区间 // result可以省略 bool cValid = regex_match(cStr, cResult, pattern); bool sValid = regex_match(sStr, sResult, pattern); // 返回匹配结果 cResult.size(); //返回匹配的子串个数 for(int i = 0; i \u0026lt; cResult.size();i++){ cResult[i]; cResult.str(i); //显示匹配的部分子串 } /* * 同样支持 * regex_search(string, result, pattern) * regex_replace(string, pattern, substr) * 可以用$1 $2 %3指括号匹配到的子串 */ Java中正则表达式的类库 import java.util.regex.* // 实际上包含了Pattern、Matcher、PatternSyntaxException三个类 javascript中使用正则表达式 var re = new RegExp(pattern, modifiers); python中使用正则表达式 # 引用正则表达式包 import re 正则表达式标志位\n标志 含义 re.I 忽略大小写 re.M 多行模式 re.L 特殊字符集依赖于当前环境 re.S 任意字符 re.U 特殊字符依赖于Unicode re.X 忽略空格和注释 匹配函数：match # 匹配函数 obj = re.match(pattern, string, flags=0) # 返回一个re匹配对象 # 匹配失败返回None obj.span() # 显示匹配到的子串的位置 obj.groups() # 显示括号匹配到的子串 obj.group(num=0) # 显示匹配到的整个字符串 obj.start() # 显示匹配到的子串的起始位置 obj.end() # 显示匹配到的子串的结束位置 # 可以使用?P\u0026lt;name\u0026gt;为子串命名并用group取出 pattern=\u0026#34;:(?P\u0026lt;port\u0026gt;[0-9]+)\u0026#34; obj.group(\u0026#34;port\u0026#34;) 查找函数：research re.search(pattern, string, flags=0) 区别：\nmatch()从头开始匹配，不满足返回None\nsearch()匹配整个字符串直到找到一个匹配\nfindall()匹配所有\nfinditer()返回迭代器（list？）\nsplit()按子串分割原字符串\n替换函数：sub # 查找并替换 re.sub(pattern, repl, string, count=0, flags=0) # 将满足pattern的部分换成repl，count指明替换的次数 注意：\n这里的repl可以是一个函数，函数参数为matched\nmatched匹配对象，可以使用group取出匹配到的子串并做相应的处理\n编译函数：compile 将pattern编译为一个对象，具有match和search的成员函数\n其他环境 C#中正则表达式的类库\nusing System.Text.RegularExpressions; ","date":1570172118,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570172118,"objectID":"0de98038a2157344e7881408fa554c06","permalink":"https://yangleisx.github.io/post/reg-exp/","publishdate":"2019-10-04T14:55:18+08:00","relpermalink":"/post/reg-exp/","section":"post","summary":"简单了解了正则表达式在python和C++中的使用方法\n","tags":["Regular Expression"],"title":"正则表达式的使用","type":"post"},{"authors":[],"categories":["代码学习"],"content":"C++已经实现了常见的各种数据结构\n每种数据结构的实现被称为容器，定义迭代器作为容器中对象的指针\n迭代器被定义为公有内嵌类，类名为iterator或const_iterator\n借助容器储存数据的容器称为容器适配器(栈和队列)\n查找表容器通常称为关联容器\n建议：直接查看头文件中的函数声明，使用关键字检索\n线性表容器 vector：用动态数组实现的线性表#include\u0026lt;vector\u0026gt;\nlist：用双链表实现的线性表#include\u0026lt;list\u0026gt;\ndeque：经过优化的线性表，兼具两者特点，用于实现栈和队列\n线性表变量声明 std::vector\u0026lt;int\u0026gt; vc; std::vector\u0026lt;int\u0026gt;::iterator itr; std::list\u0026lt;int\u0026gt; ls; std::list\u0026lt;int\u0026gt;::iterator its; 两者的共有操作 int size() const; //元素个数 void clear(); //清空元素 bool empty(); //判断是否为空 void push_back(const object \u0026amp;x); //添加到表尾 void pop_back(); //删除表尾元素 const object \u0026amp; front () const; //第一个元素 const object \u0026amp; back() const; //最后一个元素 特有操作 list可以在表头操作\nvoid push_front(const object \u0026amp;x); //表头添加元素 void pop_front(); //表头删除元素 vector可以实现类似数据的特征\nobject \u0026amp;opeator[](int idx); //下标运算符重载，无检查 object \u0026amp;at(int idx); //返回指定位置元素，有下标检查 int capacity(); //数组容量 void reseave(int newCapacity); //指定数组容量 迭代器相关操作 iterator begin(); //表头位置 const_iterator begin(); iterator end(); //表尾位置 const_iterator end(); iterator insert(iterator pos,const object \u0026amp;x); //插入元素 iterator erase(iterator pos); //删除元素 iterator erase(iterator start,iterator end); //删除区间[start,end-1) 迭代器操作 itr ++; //下一位置 * itr; //取出元素 //STL中定义了distance函数，可以确定两个iterator之间的距离 std::distance(exp.begin(),itr);//可以得到itr指向的元素的下标 其他操作 int max_size(); //vector的最大范围 void resize(size); //显式指定数组空间 void resize(size,fill); //显示指定扩大数组空间，并填充 iterator rbegin() const; //反转后的表头（实际的表尾） iterator rend() const; //反转后的表尾 void swap(vector \u0026amp;obj); //与另一个vector交换数据 vector减少空间的方法被称为“收缩到合适（shrink to fit）”\n使capacity收缩到size（capacity默认为2的指数）\nvector\u0026lt;int\u0026gt;(vc).swap(vc); //使用vector的拷贝构造函数，复制已有的数据，释放多余的空间 栈容器 stack栈容器，#include\u0026lt;stack\u0026gt;\n栈变量声明 stack\u0026lt;int,vector\u0026lt;int\u0026gt;\u0026gt; stack1;//借助vector储存数据 stack\u0026lt;int,list\u0026lt;int\u0026gt;\u0026gt; stack2;//借助list储存数据 栈基本操作 bool empty(); //检查栈是否为空 reference top(); //返回栈顶元素 void pop(); //出栈 void push(type \u0026amp;x); //压栈 void push(const type \u0026amp;x); //压栈 队列容器 queue队列容器，#include\u0026lt;queue\u0026gt;\n队列变量声明 queue\u0026lt;int\u0026gt; queue1; //使用deque实现的队列（默认） queue\u0026lt;int,deque\u0026lt;int\u0026gt;\u0026gt; queue2; //使用deque实现的队列（默认） queue\u0026lt;int,list\u0026lt;int\u0026gt;\u0026gt; queue3; //使用list实现的队列 队列基本操作 void push(type \u0026amp;x); //入队 void push(const type \u0026amp;x); //入队 void pop(); //出队 reference front(); //返回队头（下一出队元素） reference back(); //返回队尾（上一入队元素） bool empty() const ; //是否为空 size_type size() const; //队列规模 优先级队列容器 priority_queue优先级队列容器，#include\u0026lt;queue\u0026gt;\n（内部使用二叉树实现）\n变量声明 priority_queue\u0026lt;int,vector\u0026lt;int\u0026gt;,less\u0026lt;int\u0026gt;\u0026gt; pq1; //默认使用vector实现，内部降序排列，最大值出队 priority_queue\u0026lt;int,vector\u0026lt;int\u0026gt;,greater\u0026lt;int\u0026gt;\u0026gt; pq2;//vector实现，升序排列，最小值出队 priority_queue\u0026lt;int,deque\u0026lt;int\u0026gt;,less\u0026lt;int\u0026gt;\u0026gt; pq3;//使用deque实现 第三个参数为仿函数，即使用一个类，实际上完成一个函数的作用\n基本操作 void push(const type \u0026amp;x); //入队 const type \u0026amp; top() const; //返回队首值 void pop(); //出队 bool empty(); //检查是否为空 void clear(); //清空队列 查找表容器 set“集合”：数据只有一个字段键的查找表#include\u0026lt;set\u0026gt;\nmap“映射”：数据为键值对的查找表#include\u0026lt;map\u0026gt;\npair类型：键值对类型，map的元素#include\u0026lt;utility\u0026gt;\n注：set和map中不允许key出现重复，需要出现重复的key时可以使用multiset和multimap\n查找表变量声明 set\u0026lt;int\u0026gt; s; map\u0026lt;string,string\u0026gt; m; pair\u0026lt;string,string\u0026gt; p; 查找表基本操作 pair makr_pair(class1 obj1,class2 obj2); //生成pair变量，元素类型自动推断 p.first; p.second; //pair变量的内容 bool empty(); //判断是否为空 size_type size(); //容器规模 void clear(); //清空容器 size_type count(const key_type\u0026amp; key) const; //计数键出现的次数（判断键是否存在） iterator erase(iterator position); //删除某位置元素 iterator erase(iterator begin,iterator end); //删除一段元素 size_type erase(const key_type\u0026amp; key); //删除键为某值的元素 iterator find(const key_type\u0026amp; key); //查询键的位置（找不到时返回end） iterator insert(value_type\u0026amp; value); //插入（map中value_type为pair） mapped_type at(const key_type\u0026amp; key); //查找key对应的值 //map中可以直接使用下标运算，效果和at相同。但是如果目标不存在时会被创建并初始化 查找表迭代器相关操作 iterator begin(); //返回头部 iterator end(); //返回尾部 iterator lower_bound(key_value\u0026amp; key); //返回值不小于key的第一个迭代器 iterator upper_bound(key_value\u0026amp; key); //返回大于key的第一个迭代器 pair\u0026lt;iterator,iterator\u0026gt; equal_range(key_value\u0026amp; key); //返回等于key的范围 //找不到的时候返回end 特点：\nmap中的key是不可以修改的，但是每个key对应的value可以通过迭代器修改。\nset中只有key，因此不可以通过迭代器修改key的值\nmap中的元素默认按key升序排列\n","date":1570171945,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570171945,"objectID":"14a3cb7e853012cd9da95f2ad24318da","permalink":"https://yangleisx.github.io/post/cpp-stl/","publishdate":"2019-10-04T14:52:25+08:00","relpermalink":"/post/cpp-stl/","section":"post","summary":"C++已经实现了常见的各种数据结构\n每种数据结构的实现被称为容器，定义迭代器作为容器中对象的指针\n迭代器被定义为公有内嵌类，类名为iterator或const_iterator\n借助容器储存数据的容器称为容器适配器(栈和队列)\n查找表容器通常称为关联容器\n建议：直接查看头文件中的函数声明，使用关键字检索\n","tags":["C/C++"],"title":"C++中的STL数据结构","type":"post"},{"authors":[],"categories":["基础知识"],"content":"简单了解make的用法。\n格式 target(生成文件名): source(依赖文件名) command(指令) 步骤 步骤一：所有的目标文件和静态库文件连接成可执行文件\nmain : file1.o file2.o ... lib1.a lib2.a ... g++ file1.o file2.o...lib1.a lib2.a... -o main 步骤二：指定的目标文件打包为静态库文件\nlib.a : libfile1.o libfile2.o ... ar libfile1.o libfile2.o... -r lib.a 步骤三：所有的源码编译为目标文件\nfile.o : file.cpp g++ -c file.cpp 步骤四：指定clean内容\nclean: rm main file1.o ... libfile1.a ... 使用 make指令：依据makefile的要求进行编译\nmake clean指令：依据makefile的clean指令删除指定的文件\n[注意]\n不需要指定头文件(可写可不写)\n不过建议加在对应的依赖文件处 如main.o : main.cpp lib1.hpp\n编译预处理时#include “file.hpp”的含义为在本文件夹中寻找头文件并链接到该位置\n编译预处理时#include \u0026lt; iostream \u0026gt; 的含义为在C++标准库中寻找头文件并链接到该位置\n","date":1570110967,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570110967,"objectID":"5421293b94d1f364fdc94a8d81ccb49e","permalink":"https://yangleisx.github.io/post/makefile-base/","publishdate":"2019-10-03T21:56:07+08:00","relpermalink":"/post/makefile-base/","section":"post","summary":"简单了解make的用法。\n","tags":["C/C++","Make"],"title":"Make简单使用","type":"post"},{"authors":["Lei Yang"],"categories":["基础知识"],"content":"简单介绍C/C+静态库和动态库的编译方法。\n静态库 静态库的命名格式：libname.a\n即以lib为前缀，.a作为后缀\n生成 打包为库的工具为ar\nar -crv libtest.a test.o #或者 ar -cr libtest.a test.o 使用 g++编译时需要指明路径和名字\ng++ main.cpp -L . -l test -o main #静态库名不需要加前缀和后缀 动态库 linux的动态库的命名格式：libname.so\n即以lib为前缀，.so为后缀\n动态库生成 使用编译器创建动态库\ng++ -f PIC -c test.cpp#为了生成多程序共享的动态库 g++ -shared -o libtest.so test.o#创建链接 #或者合并为一句 g++ -f PIC -shared -o libtest.so test.cpp 动态库使用 具体使用方法与静态库一样\n但是需要注意 必须显式指明动态连接库的位置\n#查看库的位置 pwd #编辑ld配置文件 sudo vim /etc/ld.so.conf#在最后一行加入库目录 sudo ldconfig#重建库的位置文件 #使用动态连接库 g++ main.cpp -L . -l test -o main ./main #如果没有指明库的路径 编译时没有问题但是运行可执行文件会报错 ","date":1569840669,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569840669,"objectID":"bc8f98b5a1c68148b58fa556b78718b5","permalink":"https://yangleisx.github.io/post/cpp-build/","publishdate":"2019-09-30T18:51:09+08:00","relpermalink":"/post/cpp-build/","section":"post","summary":"简单介绍C/C+静态库和动态库的编译方法。\n","tags":["C/C++"],"title":"C++库的编译","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Hugo Blox Builder Hugo Blox Builder | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://yangleisx.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Hugo Blox Builder's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"e8f8d235e8e7f2efd912bfe865363fc3","permalink":"https://yangleisx.github.io/project/example/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/example/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Example Project","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"https://yangleisx.github.io/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"}]