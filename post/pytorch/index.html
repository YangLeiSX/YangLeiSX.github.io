<!DOCTYPE html>
<!-- This site was created with Hugo Blox. https://hugoblox.com -->
<!-- Last Published: April 2, 2024 --><html lang="en-us" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Hugo Blox Builder 5.9.6" />
  

  
  












  
  










  







  
  
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  

  
  
    
    <script src="/js/mathjax-config.js"></script>
  

  

  <link rel="stylesheet" href="/css/vendor-bundle.min.047268c6dd09ad74ba54a0ba71837064.css" media="print" onload="this.media='all'">

  
  
  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1.9.4/css/academicons.min.css" integrity="sha512-IW0nhlW5MgNydsXJO40En2EoCkTTjZhI3yuODrZIc8cQ4h1XcF53PsqDHa09NqnkXuIe0Oiyyj171BqZFwISBw==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    
    
    
    
      
      
    
    
    

    
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.css" integrity="" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.32e2e32cf1a4c1ea152e519f8b1fda79.css" />

  
  
  

  
  
  
  
  
  
  
    
    
    <link rel="stylesheet" href="/css/libs/chroma/github-light.min.css" title="hl-light" media="print" onload="this.media='all'" >
    <link rel="stylesheet" href="/css/libs/chroma/dracula.min.css" title="hl-dark" media="print" onload="this.media='all'" disabled>
  

  
  






<script async src="https://www.googletagmanager.com/gtag/js?id=G-N3HXE9037R"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
      dataLayer.push(arguments);
  }

  function trackOutboundLink(url, target) {
    gtag('event', 'click', {
         'event_category': 'outbound',
         'event_label': url,
         'transport_type': 'beacon',
         'event_callback': function () {
           if (target !== '_blank') {
             document.location = url;
           }
         }
    });
    console.debug("Outbound link clicked: " + url);
  }

  function onClickCallback(event) {
    if ((event.target.tagName !== 'A') || (event.target.host === window.location.host)) {
      return;
    }
    trackOutboundLink(event.target, event.target.getAttribute('target'));  
  }

  gtag('js', new Date());
  gtag('config', 'G-N3HXE9037R', {});
  gtag('set', {'cookie_flags': 'SameSite=None;Secure'});

  
  document.addEventListener('click', onClickCallback, false);
</script>







<script>
  (function(c,l,a,r,i,t,y){
      c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
      t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
      y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
  })(window, document, "clarity", "script", 'kxg0jok544');
</script>





  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?472e2f00a3cd94ec373babc3fbe8654f";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>














  
  
  






  <meta name="author" content="Lei Yang" />





  

<meta name="description" content="PyTorch学习笔记。基于《Deep Learning with PyTorch》，主要为相关语法的笔记。
用来自己写代码的时候参考。Dataset部分还需要进一步完善。" />



<link rel="alternate" hreflang="en-us" href="https://yangleisx.github.io/post/pytorch/" />
<link rel="canonical" href="https://yangleisx.github.io/post/pytorch/" />



  <link rel="manifest" href="/manifest.webmanifest" />



<link rel="icon" type="image/png" href="/media/icon_hu9d67daea6e408fd17d2331b8d809e90a_61652_32x32_fill_lanczos_center_3.png" />
<link rel="apple-touch-icon" type="image/png" href="/media/icon_hu9d67daea6e408fd17d2331b8d809e90a_61652_180x180_fill_lanczos_center_3.png" />

<meta name="theme-color" content="#1565c0" />










  
  






<meta property="twitter:card" content="summary" />

  <meta property="twitter:site" content="@GetResearchDev" />
  <meta property="twitter:creator" content="@GetResearchDev" />
<meta property="twitter:image" content="https://yangleisx.github.io/media/icon_hu9d67daea6e408fd17d2331b8d809e90a_61652_512x512_fill_lanczos_center_3.png" />



  

<meta property="og:type" content="article" />
<meta property="og:site_name" content="YangLeiSX" />
<meta property="og:url" content="https://yangleisx.github.io/post/pytorch/" />
<meta property="og:title" content="PyTorch学习笔记 | YangLeiSX" />
<meta property="og:description" content="PyTorch学习笔记。基于《Deep Learning with PyTorch》，主要为相关语法的笔记。
用来自己写代码的时候参考。Dataset部分还需要进一步完善。" /><meta property="og:image" content="https://yangleisx.github.io/media/icon_hu9d67daea6e408fd17d2331b8d809e90a_61652_512x512_fill_lanczos_center_3.png" /><meta property="og:locale" content="en-us" />

  
    <meta
      property="article:published_time"
      content="2020-02-12T18:05:37&#43;08:00"
    />
  
  
    <meta property="article:modified_time" content="2020-02-12T18:05:37&#43;08:00">
  






    






  




<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://yangleisx.github.io/post/pytorch/"
  },
  "headline": "PyTorch学习笔记",
  
  "datePublished": "2020-02-12T18:05:37+08:00",
  "dateModified": "2020-02-12T18:05:37+08:00",
  
  "author": {
    "@type": "Person",
    "name": "Lei Yang"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "YangLeiSX",
    "logo": {
      "@type": "ImageObject",
      "url": "https://yangleisx.github.io/media/icon_hu9d67daea6e408fd17d2331b8d809e90a_61652_192x192_fill_lanczos_center_3.png"
    }
  },
  "description": "\u003cp\u003ePyTorch学习笔记。基于《Deep Learning with PyTorch》，主要为相关语法的笔记。\n用来自己写代码的时候参考。Dataset部分还需要进一步完善。\u003c/p\u003e"
}
</script>

  

  




  
  
  

  
  

  


  
  <title>PyTorch学习笔记 | YangLeiSX</title>

  
  
  
  











</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="89d2eb400f24e8ddcd7889738117dfc8" >

  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.3a6bdbdff5d8a89d6e651adb3deec035.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header header--fixed">
  
  
  
  
  












<header>
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container-xl">

      
      <div class="d-none d-lg-inline-flex">
        <a class="navbar-brand" href="/">YangLeiSX</a>
      </div>
      

      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
      <span><i class="fas fa-bars"></i></span>
      </button>
      

      
      <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
        <a class="navbar-brand" href="/">YangLeiSX</a>
      </div>
      

      
      
      <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

        
        <ul class="navbar-nav d-md-inline-flex">
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#about"><span>Home</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#citation"><span>Publications</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link  active" href="/post/"><span>Posts</span></a>
          </li>

          
          

        

          
        </ul>
      </div>

      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

        
        
          
        

        
        
        
        <li class="nav-item">
          <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        
        
        
        <li class="nav-item dropdown theme-dropdown">
          <a href="#" class="nav-link" data-toggle="dropdown" aria-haspopup="true" aria-label="Display preferences">
            <i class="fas fa-moon" aria-hidden="true"></i>
          </a>
          <div class="dropdown-menu">
            <a href="#" class="dropdown-item js-set-theme-light">
              <span>Light</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-dark">
              <span>Dark</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-auto">
              <span>Automatic</span>
            </a>
          </div>
        </li>
        

        
        

      </ul>

    </div>
  </nav>
</header>


  </div>

  <div class="page-body">
    
    
    

    <article class="article">

  













  

  
  
  
<div class="article-container pt-3">
  <h1>PyTorch学习笔记</h1>

  

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span class="author-highlighted">
      Lei Yang</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    Feb 12, 2020
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    4 min read
  </span>
  

  
  
  
  

  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fas fa-folder mr-1"></i><a href="/category/%E4%BB%A3%E7%A0%81%E5%AD%A6%E4%B9%A0/">代码学习</a></span>
  

</div>

    





  
</div>



  <div class="article-container">

    <div class="article-style">
      <p>PyTorch学习笔记。基于《Deep Learning with PyTorch》，主要为相关语法的笔记。
用来自己写代码的时候参考。Dataset部分还需要进一步完善。</p>
<h2 id="环境">环境</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch.utils.data</span> <span class="k">as</span> <span class="nn">data</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>
</span></span></code></pre></div><p>torch.nn提供常见的神经网络结构</p>
<p>torch.util.data用于加载数据（使用Dataset和DataLoader）</p>
<p>torch.optim用于优化</p>
<p>torch.nn.DataParallel和torch.distributed用于特定平台的加速计算</p>
<p>torchvision.transforms提供常见图形格式的转换</p>
<h2 id="tensor">Tensor</h2>
<h3 id="basic">Basic</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 生成tensor</span>
</span></span><span class="line"><span class="cl"><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span><span class="mf">2.</span><span class="p">],[</span><span class="mf">2.</span><span class="p">,</span><span class="mf">3.</span><span class="p">],[</span><span class="mf">3.</span><span class="p">,</span><span class="mf">4.</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="o">&gt;&gt;&gt;</span> <span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span><span class="mf">2.</span><span class="p">,</span><span class="mf">3.</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 查看相关信息</span>
</span></span><span class="line"><span class="cl"><span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="c1"># tensor是按维度一次顺序储存（先行后列）</span>
</span></span><span class="line"><span class="cl"><span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">storage</span><span class="p">())</span>
</span></span><span class="line"><span class="cl"><span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">stride</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">storage_offset</span><span class="p">())</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 通常情况下 obj[i][j] = offset+stride[0]*i+stride[1]*j</span>
</span></span></code></pre></div><p><em><strong>使用下标得到的subtensor指向原数据，如果不希望更改原本的数据，需要使用.clone()得到数据的拷贝。</strong></em></p>
<p>二维向量使用.t()可以转置。实际上储存空间没有变，只更改了stride()高维向量使用.transpose(d_1,d_2)可以交换指定的两个维度值。</p>
<p>使用.contiguous()重新排布张量的内部存储使其成为contiguous tensor可以提高运算效率。</p>
<p>使用.dtype查看元素类型。包括int(8、16、32、64)，uint8，float(16、32、64)，即不同大小的整数和浮点数。默认的Tensor生成的是FloatTensor(float32)。可以在torch.tensor(&hellip;, dtype=float)直接指明tensor内部类型。或者使用.float()、.to(float)、.to(dtype=float)转换。</p>
<p>索引方法和python的list差不多。</p>
<p>pytorch的tensor高度兼容numpy。可以使用.numpy()直接转换为numpy的array对象。或者使用torch.from_numpy(array)从numpy的array转化为tensor。</p>
<p>使用torch.save(p,f)和p=torch.load(f)可以存取tensor。通常后缀名为.t</p>
<p>部分pytorch函数支持in-place版本，即a = torch.sqrt(a)可以换成a.sqrt_()，减少空间成本。</p>
<h3 id="device">Device</h3>
<p>使用CUDA的环境中，可以将tensor保存在GPU中。建议在程序开始是检测系统环境。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">dev</span> <span class="o">=</span> <span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span>
</span></span></code></pre></div><p>用于GPU的tensor可以使用torch.tensor(&hellip;, device=&lsquo;cuda&rsquo;)生成，或者.to(device=&lsquo;cuda&rsquo;)将其转换为CUDA的格式。便于使用CUDA计算。</p>
<p>在多GPU的环境中，使用&rsquo;cuda:0&rsquo;等来表示所使用的GPU。</p>
<p>（或者os.enrivon[&lsquo;CUDA_VISIBLE_DEVICES&rsquo;] = &lsquo;0&rsquo; ? ）</p>
<h2 id="data">Data</h2>
<h3 id="表格数据">表格数据</h3>
<p>可以使用csv.reader或者np.loadtxt处理</p>
<h4 id="csv数据">csv数据</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">path</span> <span class="o">=</span> <span class="s2">&#34;something.csv&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">data_numpy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">,</span> <span class="n">skiprows</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 根据文件情况确定delimiter(, or ;)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># skiprows跳过表头</span>
</span></span><span class="line"><span class="cl"><span class="n">col_list</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">csv</span><span class="o">.</span><span class="n">reader</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">),</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 读取到表头</span>
</span></span><span class="line"><span class="cl"><span class="n">data_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">data_numpy</span><span class="p">)</span>
</span></span></code></pre></div><p><em><strong>数值型target可以看作是一个值，也可以转化为独热码。前者存在大小比较的涵义，后者更多用于分类，没有顺序关系。</strong></em></p>
<p>需要注意原本数据取值范围是基于1（1～max）还是基于0（0～max-1），前者需要减1（scatter是基于0的）</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 独热码生成示例</span>
</span></span><span class="line"><span class="cl"><span class="c1"># target是一个long类型的一维tensor,使用unsqueeze增一个维度</span>
</span></span><span class="line"><span class="cl"><span class="n">target_oneshot</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">10</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">target_oneshot</span><span class="o">.</span><span class="n">scatter_</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">target</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="mf">1.0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 第一个参数表示独热码维数</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 将第三个参数移动到第二个参数表示的位置上</span>
</span></span></code></pre></div><p>使用zip()可以将多个可迭代数据（list等）打包成元组的list用于迭代。</p>
<h4 id="时间序列数据">时间序列数据</h4>
<p>在单个数据的基础上增加了时间维度，具有顺序特性。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">path</span> <span class="o">=</span> <span class="s2">&#34;something.csv&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">data_numpy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">nnp</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">,</span> <span class="n">skiprows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">converters</span><span class="o">=</span><span class="p">{</span><span class="mi">1</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">8</span><span class="p">:</span><span class="mi">10</span><span class="p">])})</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 这里converters表示对第1列用lambda处理</span>
</span></span><span class="line"><span class="cl"><span class="n">data_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">data_numpy</span><span class="p">)</span>
</span></span></code></pre></div><p>使用.view()可以改变数据维度，使用-1参数推测维度值</p>
<p>使用cat((tensor_1, tensor_2), dim=1)可以将多个tensor按照目标维度连在一起(目标维度上长度为两者之和，其他维度长度不变)。</p>
<p><em><strong>数值型数据可以映射到0～1（(data-min)/(max-min)）或者-1～1或者转变为标准正态分布(data - mean)/std</strong></em></p>
<h3 id="文本数据">文本数据</h3>
<p>两种方式，针对character的处理和针对word的处理。通常将其转换为独热码。</p>
<p>对于读入的字符串使用.split(&rsquo;\n&rsquo;)切成行。或者.replace(&rsquo;\n&rsquo;,&rsquo; &lsquo;).split()直接得到所有的字符。</p>
<p>使用.lower()可以变为小写，便于分析。使用.strip()删去对应的字符，没有参数时删除首尾空格。</p>
<p>针对character的处理可以按照其ASCII码的数值变为独热码。使用ord()可以得到ASCII数字（0～127）。</p>
<p>针对word的处理可以按照字典文件转变为独热码。或者使用embedding。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 创建字典示例</span>
</span></span><span class="line"><span class="cl"><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;path&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">  <span class="n">text</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">punctuation</span> <span class="o">=</span> <span class="s1">&#39;.,;:&#34;!?”“_-&#39;&#39;</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 切分单词</span>
</span></span><span class="line"><span class="cl"><span class="n">word_list</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 除去标点</span>
</span></span><span class="line"><span class="cl"><span class="n">word_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span><span class="o">.</span><span class="n">strip</span><span class="p">(</span><span class="n">punctuation</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">word_list</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 除去重复单词并排序</span>
</span></span><span class="line"><span class="cl"><span class="n">word_list</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">word_list</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 得到字典索引</span>
</span></span><span class="line"><span class="cl"><span class="n">word2index_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">word</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">word</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">word_list</span><span class="p">)}</span>
</span></span></code></pre></div><p>使用embedding可以将字典转化为固定长度的浮点数向量。比较理想的方式是将相近含义或距离比较小的单词映射到距离比较近的向量。通常情况理想的embedding是使用神经网络学习生成的。</p>
<p>（torch.nn.Embedding(num, dim))</p>
<h3 id="图像数据">图像数据</h3>
<p>导入图像的方法很多，包括imageio.imread()，PIL.Image.open()，cv2.imread()等。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">imageio</span>
</span></span><span class="line"><span class="cl"><span class="n">img_arr</span> <span class="o">=</span> <span class="n">imageio</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s1">&#39;path&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">image_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">img_arr</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># image_tensor = torch.from_numpy(img_arr)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
</span></span><span class="line"><span class="cl"><span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;path&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">iamge_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">image</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">cv2</span>
</span></span><span class="line"><span class="cl"><span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s1">&#39;path&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">image_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</span></span></code></pre></div><p>PyTorch处理的图像要求是C * H * W结构，默认图像为H * W * C因此需要torch.transpose()转换一下。如果是视频，应该得到N * C * H * W。</p>
<blockquote>
<p>Tensorflow的图像要求是H * W * C</p>
</blockquote>
<p>读取多张图片时可以创建N*C*H*W的tensor再依次读取并存入。或者使用stack()创建。</p>
<p>图像可以根据网络需求进行缩放，旋转和剪切。</p>
<p>通常要进行适当的正规化。</p>
<h3 id="三维数据">三维数据</h3>
<p>例如CT扫描数据，具有三个空间维度。</p>
<p>通常使用5D的tensor表示 N*C*D*H*W。D、H、W表示三个空间维度。C表示通道（通常为一维通道，类似灰度图像）</p>
<h2 id="model">Model</h2>
<p>构建模型</p>
<h3 id="model-basic">Model Basic</h3>
<p>主要成分包括Model(前向传播)、Loss Function、Gradient(反向传播)。</p>
<p>pytorch的tensor提供了requires_grad=True可以自动求导/梯度。指定了自动求导的张量参与的计算会被记录（计算图中的叶子结点），便于求梯度反向传播。拥有.grad成员，默认为None。</p>
<p>指定自动求导的张量参与计算得到的张量（计算图上层节点）拥有.backward()成员，之后原张量（叶子结点）的.grad成员为该张量（上层节点）对应的梯度。</p>
<p><em><strong>注意这里的.grad梯度值为累计得到，使用完毕需要使用.zero_()归零，防止过分累积。同时新的一次计算时使用.detach()将其从计算图中分离</strong></em></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 自动梯度举例</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">training_loop</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_epochs</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">params</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">      <span class="n">params</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">predict</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="o">*</span><span class="n">params</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">predict</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">params</span> <span class="o">=</span> <span class="p">(</span><span class="n">params</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">params</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span> \
</span></span><span class="line"><span class="cl">            <span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">  <span class="k">return</span> <span class="n">params</span>
</span></span></code></pre></div><p>同样，显示输出结果等对结果进行操作时必须使用detach()从计算图中分离。</p>
<h3 id="optim">Optim</h3>
<p>模型的参数被传入优化器，每当给定输入后计算反向传播和梯度并按照优化器策略自动更新。</p>
<p>优化器包括zero_grad和step成员，前者清空梯度，后者更新参数。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 创建优化器</span>
</span></span><span class="line"><span class="cl"><span class="n">params</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">0.0</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-5</span>
</span></span><span class="line"><span class="cl"><span class="n">optimezer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">([</span><span class="n">params</span><span class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 使用优化器</span>
</span></span><span class="line"><span class="cl"><span class="n">predict</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="o">*</span><span class="n">params</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">predict</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span></span></code></pre></div><h3 id="trainingvalidationoverfitting">Training、Validation、Overfitting</h3>
<ul>
<li>training loss停止下降，可能是网络结构不合适。</li>
<li>training loss和validation loss变化趋势相反，可能是过拟合。</li>
</ul>
<p>使用torch.randperm()可以得到随机排布的参数值用来选择验证集。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">n_samples</span> <span class="o">=</span> <span class="n">origin_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">n_val</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">0.2</span> <span class="o">*</span> <span class="n">n_samples</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">shuffled_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">train_data</span> <span class="o">=</span> <span class="n">origin_data</span><span class="p">[</span><span class="n">shuffled_indices</span><span class="p">[:</span><span class="o">-</span><span class="n">n_val</span><span class="p">]]</span>
</span></span><span class="line"><span class="cl"><span class="n">val_data</span> <span class="o">=</span> <span class="n">origin_data</span><span class="p">[</span><span class="n">shuffled_indices</span><span class="p">[</span><span class="o">-</span><span class="n">n_val</span><span class="p">:]]</span>
</span></span></code></pre></div><p>在计算验证集的损失函数时可以关闭自动梯度功能减轻系统负担</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">train_loop</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">train_s</span><span class="p">,</span> <span class="n">train_t</span><span class="p">,</span> <span class="n">val_s</span><span class="p">,</span> <span class="n">val_t</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_epochs_1</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">train_p</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">train_s</span><span class="p">,</span> <span class="o">*</span><span class="n">params</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">train_loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">train_p</span><span class="p">,</span> <span class="n">train_t</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">      <span class="n">val_p</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">val_s</span><span class="p">,</span> <span class="o">*</span><span class="n">params</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="n">val_loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">val_p</span><span class="p">,</span> <span class="n">val_t</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="k">assert</span> <span class="n">val</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">==</span> <span class="kc">False</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">ytain_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span></span></code></pre></div><p><em><strong>建议的做法是使用bool参数控制计算图是否开启反向传播和自动梯度</strong></em></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">calc_forward</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">is_train</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">set_grad_enabled</span><span class="p">(</span><span class="n">is_train</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">predict</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="o">*</span><span class="n">params</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">predict</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="k">return</span> <span class="n">loss</span>
</span></span></code></pre></div><h3 id="调参思路">调参思路</h3>
<ol>
<li>learning_rate过大，在极值点附近震荡或者发散。=&gt; 调节学习率。</li>
<li>梯度的不同分量差距太大，相同的学习率对于梯度的不同分量学习效果不同。=&gt; 尽量保证数量级相同。=&gt; 例如正规化到标准正态分布。</li>
<li>epoch数量不够，尚未达到稳定点。=&gt; 增大epoch次数。</li>
<li>优化器不合适。=&gt; 换用不同优化器。 =&gt; 对应更改学习率。</li>
</ol>
<h2 id="nn-module">NN Module</h2>
<p>构建神经网络</p>
<h3 id="nn-basic">NN Basic</h3>
<p>最简单的Neuron := Linear Transformation + Non-Linear Function(Activation) 简单来说$o = f(w * x + b)$。</p>
<p>网络必须是一个继承自nn.Module的类类型，而且不能是List或者Dict。如果需要的话使用nn.ModuleList或nn.ModuleDict。</p>
<p>数据通常为 N(umber)*C(hannel)*&hellip;结构。对应的nn中的模型参数通常为in_channels和out_channels。</p>
<p>单独使用nn中定义的module时使用optim的参数为model的parameters()成员。named_paramster()成员可以得到参数名。</p>
<p>nn中定义了很多Loss Function。例如nn.MSELoss()。</p>
<p>使用nn.Sequential()可以将多层捆绑为一个整体。使用OrderedDict()可以为每一层指定名称，默认使用0-based数字。使用.引导的层次命名访问每一层的数据成员。</p>
<h3 id="框架">框架</h3>
<p>使用nn.Module派生的子类，定义.forward()函数给定输入计算得到输出，动态建立计算图即可用于自动求导和优化。</p>
<p>nn包括的没有参数的网络结构，比如这里的Tanh()、ReLU()等可以使用nn.functional实现，减轻网络结构的复杂度。</p>
<p>实际上大部分的网络都可以在functional中找到对应的版本，计算输出时使用函数参数表示网络参数。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 代码中省略参数</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">Module</span><span class="p">,</span> <span class="n">Conv2d</span><span class="p">,</span> <span class="n">Dropout2d</span><span class="p">,</span> <span class="n">Linear</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">model_name</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># 使用pytorch声明网络结构</span>
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 使用torch.nn中的常见结构构建网络</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 声明网络的成分</span>
</span></span><span class="line"><span class="cl">    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">Conv2d</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">drop</span> <span class="o">=</span> <span class="n">Dropout2d</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">x</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 执行前向传播 指定了网络连接结构</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">)),</span> <span class="o">...</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="o">...</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">x</span>
</span></span></code></pre></div><p>可以直接声明比较复杂的结构，前向传播的时候比较简单</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 例如将卷积激活池化合在一起</span>
</span></span><span class="line"><span class="cl"><span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">  <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">...</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">  <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="o">...</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">  <span class="n">roech</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="o">...</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 前向传播可以是</span>
</span></span><span class="line"><span class="cl"><span class="n">conv_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span></code></pre></div><h2 id="dataset">Dataset</h2>
<h3 id="dataset-basic">Dataset Basic</h3>
<p>使用torch.utils.data的Dataset和DataLoader抽象类可以多线程数据预读取和批量加载。</p>
<p>常见的数据集和训练好的模型大多已经封装在torchvision.datasets之中。</p>
<p>数据正规化可以方便处理，根据数据的特性确定正规化参数。</p>
<p>使用softmax输出的结果选择最大值作为分类输出。</p>
<p>分类可以使用NLLLoss()作为损失函数。</p>
<h3 id="dataset--dataloader">Dataset &amp; DataLoader</h3>
<p>Dataset主要的两个成员函数__getitem__()和__len__()。</p>
<p>DataLoader提供对于Dataset的处理，包括batch_size、shuffle、num_workers（子线程数）。</p>
<p>DataLoader得到的是可迭代对象，可以使用next(loader)来获取下一批数据，或者使用for循环（for i, data in enumerate(loader)）的方法读取数据用于训练。</p>
<p>通常需要使用transforms来进行预处理，包括ToTensor()、Normalize()、RandomHorizontalFlip()、RandomRotationn()、Resize()等处理方式。</p>
<h3 id="hand-on">Hand-on</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch.utils.data</span> <span class="k">as</span> <span class="nn">data</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torchvision.transfroms</span> <span class="k">as</span> <span class="nn">transforms</span>
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">dataset_name</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># 创建数据集</span>
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="o">...</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">length</span> <span class="o">=</span> <span class="o">...</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="o">...</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
</span></span><span class="line"><span class="cl">      <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">      <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="o">...</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="o">...</span><span class="p">]),</span>
</span></span><span class="line"><span class="cl">      <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">([,,,])</span>
</span></span><span class="line"><span class="cl">    <span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">transforms</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">item</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">length</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 使用数据集</span>
</span></span><span class="line"><span class="cl"><span class="n">data_set</span> <span class="o">=</span> <span class="n">dataset_name</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">data_loader</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">Dataloader</span><span class="p">(</span><span class="n">data_set</span><span class="p">,</span><span class="o">...</span><span class="p">)</span>
</span></span></code></pre></div><h2 id="visualize">Visualize</h2>
<p>可以使用visdom工具进行pytorch的可视化。</p>
<p>也有使用tensorboardx的可视化方案，功能比较强大， 和tensorflow中的基本相同，<a href="https://github.com/zergtant/pytorch-handbook/blob/master/chapter4/4.2.2-tensorboardx.ipynb" target="_blank" rel="noopener">使用方法参见pytorch-handbook</a>。</p>
<h3 id="visual-hand-on">Visual Hand-on</h3>
<p>使用visdom监控loss或者accuracy的时候</p>
<p>可以使用visdom的追加值绘制曲线</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">visdom</span> <span class="kn">import</span> <span class="n">Visdom</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 创建一个Visdom的对象</span>
</span></span><span class="line"><span class="cl"><span class="n">env</span> <span class="o">=</span> <span class="n">Visdom</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 初始点</span>
</span></span><span class="line"><span class="cl"><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span>
</span></span><span class="line"><span class="cl"><span class="n">pane</span><span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">line</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">X</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x</span><span class="p">]),</span>
</span></span><span class="line"><span class="cl">    <span class="n">Y</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">y</span><span class="p">]),</span>
</span></span><span class="line"><span class="cl">    <span class="n">opts</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;dynamic data&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 追加新的数据点</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># 每隔一秒钟打印一次数据</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span><span class="o">+=</span><span class="n">i</span>
</span></span><span class="line"><span class="cl">    <span class="n">y</span><span class="o">=</span><span class="p">(</span><span class="n">y</span><span class="o">+</span><span class="n">i</span><span class="p">)</span><span class="o">*</span><span class="mf">1.5</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">env</span><span class="o">.</span><span class="n">line</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">X</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x</span><span class="p">]),</span>
</span></span><span class="line"><span class="cl">        <span class="n">Y</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">y</span><span class="p">]),</span>
</span></span><span class="line"><span class="cl">        <span class="n">win</span><span class="o">=</span><span class="n">pane</span><span class="p">,</span> <span class="c1"># win参数确认使用哪一个pane</span>
</span></span><span class="line"><span class="cl">        <span class="n">update</span><span class="o">=</span><span class="s1">&#39;append&#39;</span><span class="p">)</span> <span class="c1"># 增加一个数据点</span>
</span></span></code></pre></div>
    </div>

    





<div class="article-tags">
  
  <a class="badge badge-light" href="/tag/pytorch/">PyTorch</a>
  
  <a class="badge badge-light" href="/tag/deep-learning/">Deep Learning</a>
  
</div>



<div class="share-box">
  <ul class="share">
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fyangleisx.github.io%2Fpost%2Fpytorch%2F&amp;text=PyTorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0" target="_blank" rel="noopener" class="share-btn-twitter" aria-label="twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=https%3A%2F%2Fyangleisx.github.io%2Fpost%2Fpytorch%2F&amp;t=PyTorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0" target="_blank" rel="noopener" class="share-btn-facebook" aria-label="facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
        
      
      <li>
        <a href="mailto:?subject=PyTorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0&amp;body=https%3A%2F%2Fyangleisx.github.io%2Fpost%2Fpytorch%2F" target="_blank" rel="noopener" class="share-btn-email" aria-label="envelope">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fyangleisx.github.io%2Fpost%2Fpytorch%2F&amp;title=PyTorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0" target="_blank" rel="noopener" class="share-btn-linkedin" aria-label="linkedin-in">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="whatsapp://send?text=PyTorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%20https%3A%2F%2Fyangleisx.github.io%2Fpost%2Fpytorch%2F" target="_blank" rel="noopener" class="share-btn-whatsapp" aria-label="whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=https%3A%2F%2Fyangleisx.github.io%2Fpost%2Fpytorch%2F&amp;title=PyTorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0" target="_blank" rel="noopener" class="share-btn-weibo" aria-label="weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>











  
  
    



  
  
  
    
  
  
  
  <div class="media author-card content-widget-hr">
    
      
      <a href="https://yangleisx.github.io/"><img class="avatar mr-3 avatar-circle" src="/authors/admin/avatar_hufa4b711d7d766ab1064b8274b75ac233_742651_270x270_fill_lanczos_center_1.gif" alt="Lei Yang"></a>
    

    <div class="media-body">
      <h5 class="card-title"><a href="https://yangleisx.github.io/">Lei Yang</a></h5>
      <h6 class="card-subtitle">PhD candidate</h6>
      <p class="card-text">My research interests include visual speech recognition and semantics segmentation.</p>
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="/#contact" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://scholar.google.com/citations?user=YsaBzN4AAAAJ" target="_blank" rel="noopener">
        <i class="ai ai-google-scholar"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/yangleisx" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>


  
















  </div>
</article>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  












  
  
  
  
  













  
  
  

  
  
    
  
  
    
  

  

  
  <p class="powered-by copyright-license-text">
    © 2024 Me. This work is licensed under <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank">CC BY NC ND 4.0</a>
  </p>
  

  <p class="powered-by footer-license-icons">
    <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank" aria-label="Creative Commons">
      <i class="fab fa-creative-commons fa-2x" aria-hidden="true"></i>
      <i class="fab fa-creative-commons-by fa-2x" aria-hidden="true"></i>
      
        <i class="fab fa-creative-commons-nc fa-2x" aria-hidden="true"></i>
      
      
        <i class="fab fa-creative-commons-nd fa-2x" aria-hidden="true"></i>
      
    </a>
  </p>





  <p class="powered-by">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://hugoblox.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Hugo Blox Builder</a> — the free, <a href="https://github.com/HugoBlox/hugo-blox-builder" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>
</footer>

    </div>
    
  </div>

  


<script src="/js/vendor-bundle.min.938a3a7554cd9f6602290411f64d2617.js"></script>




  

  
  

  






  <script src="https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.js" integrity="" crossorigin="anonymous"></script>








  
  <script id="search-hit-fuse-template" type="text/x-template">
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script>
  
    <script src="https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js" integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js" integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin="anonymous"></script>
  












  
  
  
  
  
  
  

















<script id="page-data" type="application/json">{"use_headroom":true}</script>


  <script src="/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js" type="module"></script>









  
  


<script src="/en/js/wowchemy.min.62586ca65ca61821fe707eb9fa6268b7.js"></script>



  <script src="/js/wowchemy-map.a26e9d2f7238ba5b868384f1c5bc6477.js" type="module"></script>




  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        
        <pre><code></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>


  <script src="/js/wowchemy-publication.9137013a66774049159934c29c3f0205.js" type="module"></script>


















</body>
</html>
