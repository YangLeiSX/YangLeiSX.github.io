<!DOCTYPE html>
<!-- This site was created with Hugo Blox. https://hugoblox.com -->
<!-- Last Published: February 25, 2024 --><html lang="en-us" >


<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  
  
  
    <meta name="generator" content="Hugo Blox Builder 5.9.6" />
  

  
  












  
  










  







  
  
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  

  
  
  
    
      
      <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media="print" onload="this.media='all'">
    
  

  
  

  
  
    
    <script src="/js/mathjax-config.js"></script>
  

  

  <link rel="stylesheet" href="/css/vendor-bundle.min.047268c6dd09ad74ba54a0ba71837064.css" media="print" onload="this.media='all'">

  
  
  
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1.9.4/css/academicons.min.css" integrity="sha512-IW0nhlW5MgNydsXJO40En2EoCkTTjZhI3yuODrZIc8cQ4h1XcF53PsqDHa09NqnkXuIe0Oiyyj171BqZFwISBw==" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    
    
    
    
      
      
    
    
    

    
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.css" integrity="" crossorigin="anonymous" media="print" onload="this.media='all'">
    

    

    
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
    
      
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      
      

      
      

      
    
      
      

      
      

      
    
  

  
  
  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.32e2e32cf1a4c1ea152e519f8b1fda79.css" />

  
  
  

  
  
  
  
  
  
  
    
    
    <link rel="stylesheet" href="/css/libs/chroma/github-light.min.css" title="hl-light" media="print" onload="this.media='all'" >
    <link rel="stylesheet" href="/css/libs/chroma/dracula.min.css" title="hl-dark" media="print" onload="this.media='all'" disabled>
  

  
  






<script async src="https://www.googletagmanager.com/gtag/js?id=G-N3HXE9037R"></script>
<script>
  window.dataLayer = window.dataLayer || [];

  function gtag() {
      dataLayer.push(arguments);
  }

  function trackOutboundLink(url, target) {
    gtag('event', 'click', {
         'event_category': 'outbound',
         'event_label': url,
         'transport_type': 'beacon',
         'event_callback': function () {
           if (target !== '_blank') {
             document.location = url;
           }
         }
    });
    console.debug("Outbound link clicked: " + url);
  }

  function onClickCallback(event) {
    if ((event.target.tagName !== 'A') || (event.target.host === window.location.host)) {
      return;
    }
    trackOutboundLink(event.target, event.target.getAttribute('target'));  
  }

  gtag('js', new Date());
  gtag('config', 'G-N3HXE9037R', {});
  gtag('set', {'cookie_flags': 'SameSite=None;Secure'});

  
  document.addEventListener('click', onClickCallback, false);
</script>







<script>
  (function(c,l,a,r,i,t,y){
      c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
      t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
      y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
  })(window, document, "clarity", "script", 'kxg0jok544');
</script>





  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?472e2f00a3cd94ec373babc3fbe8654f";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>














  
  
  






  <meta name="author" content="Lei Yang" />





  

<meta name="description" content="论文笔记:Effective Approaches to Attention-based Neural Machine Translation" />



<link rel="alternate" hreflang="en-us" href="https://yangleisx.github.io/post/paper-attention/" />
<link rel="canonical" href="https://yangleisx.github.io/post/paper-attention/" />



  <link rel="manifest" href="/manifest.webmanifest" />



<link rel="icon" type="image/png" href="/media/icon_hu9d67daea6e408fd17d2331b8d809e90a_61652_32x32_fill_lanczos_center_3.png" />
<link rel="apple-touch-icon" type="image/png" href="/media/icon_hu9d67daea6e408fd17d2331b8d809e90a_61652_180x180_fill_lanczos_center_3.png" />

<meta name="theme-color" content="#1565c0" />










  
  






<meta property="twitter:card" content="summary" />

  <meta property="twitter:site" content="@GetResearchDev" />
  <meta property="twitter:creator" content="@GetResearchDev" />
<meta property="twitter:image" content="https://yangleisx.github.io/media/icon_hu9d67daea6e408fd17d2331b8d809e90a_61652_512x512_fill_lanczos_center_3.png" />



  

<meta property="og:type" content="article" />
<meta property="og:site_name" content="YangLeiSX" />
<meta property="og:url" content="https://yangleisx.github.io/post/paper-attention/" />
<meta property="og:title" content="【论文】Effective Approaches to Attention-based Neural Machine Translation | YangLeiSX" />
<meta property="og:description" content="论文笔记:Effective Approaches to Attention-based Neural Machine Translation" /><meta property="og:image" content="https://yangleisx.github.io/media/icon_hu9d67daea6e408fd17d2331b8d809e90a_61652_512x512_fill_lanczos_center_3.png" /><meta property="og:locale" content="en-us" />

  
    <meta
      property="article:published_time"
      content="2020-02-02T22:29:36&#43;08:00"
    />
  
  
    <meta property="article:modified_time" content="2020-02-02T22:29:36&#43;08:00">
  






    






  




<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://yangleisx.github.io/post/paper-attention/"
  },
  "headline": "【论文】Effective Approaches to Attention-based Neural Machine Translation",
  
  "datePublished": "2020-02-02T22:29:36+08:00",
  "dateModified": "2020-02-02T22:29:36+08:00",
  
  "author": {
    "@type": "Person",
    "name": "Lei Yang"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "YangLeiSX",
    "logo": {
      "@type": "ImageObject",
      "url": "https://yangleisx.github.io/media/icon_hu9d67daea6e408fd17d2331b8d809e90a_61652_192x192_fill_lanczos_center_3.png"
    }
  },
  "description": "\u003cp\u003e论文笔记:Effective Approaches to Attention-based Neural Machine Translation\u003c/p\u003e"
}
</script>

  

  




  
  
  

  
  

  


  
  <title>【论文】Effective Approaches to Attention-based Neural Machine Translation | YangLeiSX</title>

  
  
  
  











</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class="page-wrapper   " data-wc-page-id="d9c300df1810c8d2a803047306d986e3" >

  
  
  
  
  
  
  
  
  
  <script src="/js/wowchemy-init.min.3a6bdbdff5d8a89d6e651adb3deec035.js"></script>

  


<aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#" aria-label="Close"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control"
        aria-label="Search...">
        
      </div>

      
      

      

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>



  <div class="page-header header--fixed">
  
  
  
  
  












<header>
  <nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
    <div class="container-xl">

      
      <div class="d-none d-lg-inline-flex">
        <a class="navbar-brand" href="/">YangLeiSX</a>
      </div>
      

      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
      <span><i class="fas fa-bars"></i></span>
      </button>
      

      
      <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
        <a class="navbar-brand" href="/">YangLeiSX</a>
      </div>
      

      
      
      <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

        
        <ul class="navbar-nav d-md-inline-flex">
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#about"><span>Home</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
              
              
              
                
              
              
            
          

          <li class="nav-item">
            <a class="nav-link " href="/#citation"><span>Publications</span></a>
          </li>

          
          

          

          
          
          
            
          

          

          
          
          
          

          
            
              
              
            
            
          

          <li class="nav-item">
            <a class="nav-link  active" href="/post/"><span>Posts</span></a>
          </li>

          
          

        

          
        </ul>
      </div>

      <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">

        
        
          
        

        
        
        
        <li class="nav-item">
          <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        
        
        
        <li class="nav-item dropdown theme-dropdown">
          <a href="#" class="nav-link" data-toggle="dropdown" aria-haspopup="true" aria-label="Display preferences">
            <i class="fas fa-moon" aria-hidden="true"></i>
          </a>
          <div class="dropdown-menu">
            <a href="#" class="dropdown-item js-set-theme-light">
              <span>Light</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-dark">
              <span>Dark</span>
            </a>
            <a href="#" class="dropdown-item js-set-theme-auto">
              <span>Automatic</span>
            </a>
          </div>
        </li>
        

        
        

      </ul>

    </div>
  </nav>
</header>


  </div>

  <div class="page-body">
    
    
    

    <article class="article">

  













  

  
  
  
<div class="article-container pt-3">
  <h1>【论文】Effective Approaches to Attention-based Neural Machine Translation</h1>

  

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    

  <span class="author-highlighted">
      Lei Yang</span>
  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    Feb 2, 2020
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    1 min read
  </span>
  

  
  
  
  

  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fas fa-folder mr-1"></i><a href="/category/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a></span>
  

</div>

    





  
</div>



  <div class="article-container">

    <div class="article-style">
      <p>论文笔记:Effective Approaches to Attention-based Neural Machine Translation</p>
<p>开源项目地址：<a href="http://nlp.stanford.edu/projects/nmt" target="_blank" rel="noopener">stanford.edu</a>或者<a href="https://github.com/tensorflow/nmt" target="_blank" rel="noopener">github</a></p>
<h2 id="主要内容">主要内容</h2>
<p>NMT使用RNN的架构来实现序列到序列的学习。Attention机制被广泛用于训练神经网络并提升其性能。</p>
<p>因此可以使用attention机制通过聚焦于输入序列的某一部分来提高NMT的性能。</p>
<p>文中构建了两种使用attention的NMT模型：global模型和locol模型。前者注意输入序列全体，后者每次针对输入序列的一个子集。两种模型的结构都很简单，而且后者的计算成本更低。</p>
<h2 id="背景">背景</h2>
<p>传统NMT模型包括一个编码器和一个解码器，前者将输入映射到固定长度的向量$\mathbf{S}$，后者将向量映射到输出序列。</p>
<p>其具体实现有CNN-RNN结构，也有RNN-RNN结构（包括LSTM-LSTM，GRU-GRU等）。</p>
<p>其他的实现中使用$\mathbf{S}$作为初始化解码器的工具，而使用attention机制的模型在整个翻译过程中都将$\mathbf{S}$用做参考。</p>
<h2 id="实现">实现</h2>
<p>使用深度LSTM作为编码器和解码器。</p>
<p>目标函数为$J = \sum _{(x,y)\in \mathbb{D}}-logp(y|x)$其中$\mathbb{D}$为训练数据。</p>
<p>globel和locol两种不同的模型区别在于内容向量$c_t$的生成方式不同。当内容向量$c_t$生成后，即可计算输出。</p>
<p>即首先计算attentional hidden state:$\tilde{h}_t = tanh(W_c [c_t;h_t])$。</p>
<p>然后得到预测向量 $p(y_t|y_{&lt; t}, x) = softmax(W_s \tilde{h}_t)$ 。</p>
<h3 id="global-attention">global attention</h3>
<p>考虑到编码器的所有隐含状态，通过编码器状态$\bar{h}_s$和解码器状态$h_t$通过score()函数得到global align weights即$a_t$，这里的向量$a_t$为可变长度的。最终使用$a_t$对$\bar{h}_s$加权得到$c_t$从而得到$\hat{h}_t$.</p>
<p>具体score函数见文献原文。</p>
<p>global attention考虑到所有的输入符号，计算成本比较高，而且无法处理较长的序列。</p>
<h3 id="locol-attention">locol attention</h3>
<p>借鉴soft和hard attention的思想<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>，使用加窗的方式，考虑一部分的隐状态。</p>
<p>首先确定位置$p_t$，然后根据位于$[p_t-D,p_t+D]$的编码器状态使用相同的score()函数得到$a_t$。不同的是这里的$a_t$为固定长度($2D+1$)的向量。</p>
<p>关于位置$p_t$的确定有不同的方法。</p>
<p>locol-m方法：令$p_t = t$,使用前述方法计算$a_t$。</p>
<p>locol-p方法：通过学习到的参数预测，即令$p_t = S·sigmoid(v_p^Ttanh(W_p h_t))$，其中 $v_p$ 和 $W_p$为学习得到的参数，S为输入序列长度。同时计算$a_t = align(h_t,\bar{h}_s) exp(- \frac{(s-p_t)^2}{2\sigma^2})$，其中$\sigma = \frac{D}{2}$。</p>
<h3 id="input-feeding">input-feeding</h3>
<p>将上一输出作为输入传入网络用于产生下一输出。</p>
<h3 id="具体实现">具体实现</h3>
<p>使用WMT的英语-德语双向翻译任务，共4.5M句子，包括116M英语单词110M德语单词。</p>
<p>选择其中的50k单词作为训练的单词表。每个LSTM具有四层，每层1000单元，每个单元为1000维张量。</p>
<h2 id="评价">评价</h2>
<p>global attention和local attention相比其他人的实现<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>更加简单</p>
<p>通过input-feeding使得之前学习得到的结果得到充分利用，这一方法也可以用于非attention的其他RNN架构的网络中。</p>
<p>最终训练结果在WMT上得分23.0超过了最好的系统。</p>
<p>论文实现的系统具有更低的test cost。可以更好的处理长句子。</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p><a href="http://proceedings.mlr.press/v37/xuc15.pdf" target="_blank" rel="noopener">Show,Attend and Tell:Neural Image Caption Generation with Visual Attention</a>&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p><a href="https://arxiv.org/pdf/1409.0473" target="_blank" rel="noopener">Neural Machine Translation by Jointly Learning to Align and Translate</a>&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
    </div>

    





<div class="article-tags">
  
  <a class="badge badge-light" href="/tag/deep-learning/">Deep Learning</a>
  
  <a class="badge badge-light" href="/tag/machine-translate/">Machine Translate</a>
  
  <a class="badge badge-light" href="/tag/attention/">Attention</a>
  
</div>



<div class="share-box">
  <ul class="share">
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fyangleisx.github.io%2Fpost%2Fpaper-attention%2F&amp;text=%E3%80%90%E8%AE%BA%E6%96%87%E3%80%91Effective&#43;Approaches&#43;to&#43;Attention-based&#43;Neural&#43;Machine&#43;Translation" target="_blank" rel="noopener" class="share-btn-twitter" aria-label="twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=https%3A%2F%2Fyangleisx.github.io%2Fpost%2Fpaper-attention%2F&amp;t=%E3%80%90%E8%AE%BA%E6%96%87%E3%80%91Effective&#43;Approaches&#43;to&#43;Attention-based&#43;Neural&#43;Machine&#43;Translation" target="_blank" rel="noopener" class="share-btn-facebook" aria-label="facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
        
      
      <li>
        <a href="mailto:?subject=%E3%80%90%E8%AE%BA%E6%96%87%E3%80%91Effective%20Approaches%20to%20Attention-based%20Neural%20Machine%20Translation&amp;body=https%3A%2F%2Fyangleisx.github.io%2Fpost%2Fpaper-attention%2F" target="_blank" rel="noopener" class="share-btn-email" aria-label="envelope">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fyangleisx.github.io%2Fpost%2Fpaper-attention%2F&amp;title=%E3%80%90%E8%AE%BA%E6%96%87%E3%80%91Effective&#43;Approaches&#43;to&#43;Attention-based&#43;Neural&#43;Machine&#43;Translation" target="_blank" rel="noopener" class="share-btn-linkedin" aria-label="linkedin-in">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="whatsapp://send?text=%E3%80%90%E8%AE%BA%E6%96%87%E3%80%91Effective&#43;Approaches&#43;to&#43;Attention-based&#43;Neural&#43;Machine&#43;Translation%20https%3A%2F%2Fyangleisx.github.io%2Fpost%2Fpaper-attention%2F" target="_blank" rel="noopener" class="share-btn-whatsapp" aria-label="whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=https%3A%2F%2Fyangleisx.github.io%2Fpost%2Fpaper-attention%2F&amp;title=%E3%80%90%E8%AE%BA%E6%96%87%E3%80%91Effective&#43;Approaches&#43;to&#43;Attention-based&#43;Neural&#43;Machine&#43;Translation" target="_blank" rel="noopener" class="share-btn-weibo" aria-label="weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>











  
  
    



  
  
  
    
  
  
  
  <div class="media author-card content-widget-hr">
    
      
      <a href="https://yangleisx.github.io/"><img class="avatar mr-3 avatar-circle" src="/authors/admin/avatar_hufa4b711d7d766ab1064b8274b75ac233_742651_270x270_fill_lanczos_center_1.gif" alt="Lei Yang"></a>
    

    <div class="media-body">
      <h5 class="card-title"><a href="https://yangleisx.github.io/">Lei Yang</a></h5>
      <h6 class="card-subtitle">PhD candidate</h6>
      <p class="card-text">My research interests include visual speech recognition and semantics segmentation.</p>
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="/#contact" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://scholar.google.com/citations?user=YsaBzN4AAAAJ" target="_blank" rel="noopener">
        <i class="ai ai-google-scholar"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/yangleisx" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>


  
















  </div>
</article>
  </div>

  <div class="page-footer">
    
    
    <div class="container">
      <footer class="site-footer">

  












  
  
  
  
  













  
  
  

  
  
    
  
  
    
  

  

  
  <p class="powered-by copyright-license-text">
    © 2024 Me. This work is licensed under <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank">CC BY NC ND 4.0</a>
  </p>
  

  <p class="powered-by footer-license-icons">
    <a href="https://creativecommons.org/licenses/by-nc-nd/4.0" rel="noopener noreferrer" target="_blank" aria-label="Creative Commons">
      <i class="fab fa-creative-commons fa-2x" aria-hidden="true"></i>
      <i class="fab fa-creative-commons-by fa-2x" aria-hidden="true"></i>
      
        <i class="fab fa-creative-commons-nc fa-2x" aria-hidden="true"></i>
      
      
        <i class="fab fa-creative-commons-nd fa-2x" aria-hidden="true"></i>
      
    </a>
  </p>





  <p class="powered-by">
    
    
    
      
      
      
      
      
      
      Published with <a href="https://hugoblox.com/?utm_campaign=poweredby" target="_blank" rel="noopener">Hugo Blox Builder</a> — the free, <a href="https://github.com/HugoBlox/hugo-blox-builder" target="_blank" rel="noopener">open source</a> website builder that empowers creators.
    
  </p>
</footer>

    </div>
    
  </div>

  


<script src="/js/vendor-bundle.min.938a3a7554cd9f6602290411f64d2617.js"></script>




  

  
  

  






  <script src="https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.js" integrity="" crossorigin="anonymous"></script>








  
  <script id="search-hit-fuse-template" type="text/x-template">
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script>
  
    <script src="https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js" integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js" integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin="anonymous"></script>
  












  
  
  
  
  
  
  

















<script id="page-data" type="application/json">{"use_headroom":true}</script>


  <script src="/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js" type="module"></script>









  
  


<script src="/en/js/wowchemy.min.62586ca65ca61821fe707eb9fa6268b7.js"></script>



  <script src="/js/wowchemy-map.a26e9d2f7238ba5b868384f1c5bc6477.js" type="module"></script>




  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        
        <pre><code></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>


  <script src="/js/wowchemy-publication.9137013a66774049159934c29c3f0205.js" type="module"></script>


















</body>
</html>
